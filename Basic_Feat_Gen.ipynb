{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOXvwEUE+HkywqvXZKftaWc",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ShadmanRohan/fsl-rsvae/blob/main/Basic_Feat_Gen.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Preliminaries**"
      ],
      "metadata": {
        "id": "0F1r6VXg0fZO"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9Fkr40LMo7uc",
        "outputId": "b6eb943f-d300-49c0-87cf-4bc88e2a2a12"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'fsl-rsvae'...\n",
            "remote: Enumerating objects: 427, done.\u001b[K\n",
            "remote: Counting objects: 100% (427/427), done.\u001b[K\n",
            "remote: Compressing objects: 100% (231/231), done.\u001b[K\n",
            "remote: Total 427 (delta 209), reused 402 (delta 195), pack-reused 0\u001b[K\n",
            "Receiving objects: 100% (427/427), 454.14 KiB | 17.47 MiB/s, done.\n",
            "Resolving deltas: 100% (209/209), done.\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/ShadmanRohan/fsl-rsvae.git"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4ktupjgODfja",
        "outputId": "91485535-6a24-46b4-e1af-2d45f351bbf4"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/gdrive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from distutils.dir_util import copy_tree\n",
        "copy_tree(\"/content/gdrive/MyDrive/PAMI/AWA1_AWA2_SUN/data/AWA1\", \"/content/fsl-rsvae/datasets/AWA1\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IEef9zeLD52b",
        "outputId": "8fd5ccef-ed3c-4770-ff71-9e0e4038a148"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['/content/fsl-rsvae/datasets/AWA1/seen_test.mat',\n",
              " '/content/fsl-rsvae/datasets/AWA1/seen_attribute.mat',\n",
              " '/content/fsl-rsvae/datasets/AWA1/seen_test_label.mat',\n",
              " '/content/fsl-rsvae/datasets/AWA1/seen_train.mat',\n",
              " '/content/fsl-rsvae/datasets/AWA1/unseen_attribute.mat',\n",
              " '/content/fsl-rsvae/datasets/AWA1/seen_train_label.mat',\n",
              " '/content/fsl-rsvae/datasets/AWA1/unseen_test.mat',\n",
              " '/content/fsl-rsvae/datasets/AWA1/unseen_test_label.mat']"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import argparse\n",
        "import numpy as np\n",
        "from torch.autograd import Variable\n",
        "#from torchvision.datasets.folder import DatasetFolder\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torch.distributions import uniform, normal\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from matplotlib import pyplot as plt\n",
        "import torch.optim\n",
        "import json\n",
        "import torch.utils.data.sampler\n",
        "import os\n",
        "import glob\n",
        "import random\n",
        "import time\n",
        "import pdb\n",
        "import yaml\n",
        "#import datasets.feature_loader as feat_loader\n",
        "from sklearn.manifold import TSNE\n",
        "import h5py\n",
        "from scipy.stats import multivariate_normal\n",
        "import scipy"
      ],
      "metadata": {
        "id": "k8kzzG1xpNSE"
      },
      "execution_count": 92,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Dataloader**"
      ],
      "metadata": {
        "id": "ALmNYwLE0koN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import scipy.io\n",
        "#features\n",
        "data_train = scipy.io.loadmat('/content/fsl-rsvae/datasets/AWA1/seen_train.mat')\n",
        "data_train = data_train['feature']\n",
        "#data_train = np.transpose(data_train)\n",
        "\n",
        "\n",
        "# labels\n",
        "label_train = scipy.io.loadmat('/content/fsl-rsvae/datasets/AWA1/seen_train_label.mat')\n",
        "data_train_label = label_train['label'][0]\n",
        "\n",
        "\n",
        "# attr\n",
        "tmp = scipy.io.loadmat('/content/fsl-rsvae/datasets/AWA1/seen_attribute.mat')\n",
        "attr = tmp['seen_attribute']\n",
        "#attr = np.transpose(attr)"
      ],
      "metadata": {
        "id": "KWmLvTptFmf9"
      },
      "execution_count": 93,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class FeatureDataset(Dataset):\n",
        "\n",
        "    def __init__(self, features, labels, attr):\n",
        "        self.labels = labels\n",
        "        self.features = features\n",
        "        self.attr = attr\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(data_train)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        return self.features[idx], self.labels[idx]\n",
        "\n",
        "feature_dataset = FeatureDataset(data_train, data_train_label, attr)\n",
        "feature_loader = torch.utils.data.DataLoader(feature_dataset, shuffle=True, pin_memory=True, drop_last=False, batch_size=256) "
      ],
      "metadata": {
        "id": "OiH7f_bqFb3i"
      },
      "execution_count": 94,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Model**"
      ],
      "metadata": {
        "id": "foS4BJaI0poO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class FeatsVAE(nn.Module):\n",
        "    def __init__(self, x_dim, latent_dim, bottle_neck):\n",
        "        super(FeatsVAE, self).__init__()\n",
        "\n",
        "        self.x_dim = x_dim\n",
        "        self.latent_dim = latent_dim\n",
        "        self.bn1 = nn.BatchNorm1d(x_dim)\n",
        "        self.relu = nn.ReLU(inplace=True)\n",
        "        self.z_dist = normal.Normal(0, 1)\n",
        "        self.init_weights()\n",
        "\n",
        "        self.linear = nn.Sequential(\n",
        "            nn.Linear(self.x_dim+self.latent_dim, bottle_neck),\n",
        "            #nn.LeakyReLU(),\n",
        "            #nn.Linear(1096, 2096),\n",
        "            nn.LeakyReLU())\n",
        "        self.linear_mu =  nn.Sequential(\n",
        "            nn.Linear(bottle_neck, latent_dim),\n",
        "            nn.ReLU())\n",
        "        self.linear_logvar =  nn.Sequential(\n",
        "            nn.Linear(bottle_neck, latent_dim),\n",
        "            nn.ReLU())\n",
        "        self.model = nn.Sequential(\n",
        "            nn.Linear(2*latent_dim, bottle_neck),\n",
        "            nn.LeakyReLU(),\n",
        "            #nn.Linear(4096, 4096),\n",
        "            #nn.LeakyReLU(),\n",
        "            nn.Linear(bottle_neck, x_dim),\n",
        "            #nn.Sigmoid(),\n",
        "        )\n",
        "        \n",
        "\n",
        "\n",
        "\n",
        "    def reparameterize(self, mu, logvar):\n",
        "        std = torch.exp(0.5*logvar)  \n",
        "        eps = torch.randn_like(std)\n",
        "        # remove abnormal points\n",
        "        return mu + eps*std\n",
        "\n",
        "    def init_weights(self):\n",
        "        for m in self.modules():\n",
        "          if isinstance(m, nn.Linear):\n",
        "              m.weight.data.normal_(0, 0.02)\n",
        "              m.bias.data.normal_(0, 0.02)\n",
        "\n",
        "    def forward(self, x, attr):\n",
        "        #print(x.size())\n",
        "        #print(attr.size())\n",
        "\n",
        "        x = torch.cat((x, attr), dim=1).to(torch.float32)\n",
        "        #print(x.size())\n",
        "        #print(self.x_dim+self.latent_dim)\n",
        "        \n",
        "        x = self.linear(x)\n",
        "        #print(x.size())\n",
        "        mu = self.linear_mu(x)\n",
        "        #print(x)\n",
        "        logvar = self.linear_logvar(x)\n",
        "        #print(logvar)\n",
        "        latent_feats = self.reparameterize(mu, logvar)\n",
        "        #Z = self.z_dist.sample(attr.shape).cuda() \n",
        "        concat_feats = torch.cat((latent_feats, attr), dim=1)\n",
        "        recon_feats = self.model(concat_feats)\n",
        "        recon_feats = self.relu(self.bn1(recon_feats))\n",
        "        return mu, logvar, recon_feats\n",
        "\n",
        "feats_vae = FeatsVAE(x_dim=2048, latent_dim=85, bottle_neck=96) # latent dim = attribute dim"
      ],
      "metadata": {
        "id": "QR8I-FHnK1gq"
      },
      "execution_count": 95,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Train**"
      ],
      "metadata": {
        "id": "M7OEf2vy0thp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def train_vae(feature_loader, feats_vae, attributes):\n",
        "    optimizer = torch.optim.Adam(feats_vae.parameters(), lr=0.001)\n",
        "    feats_vae.train()\n",
        "    feats_vae.cuda()\n",
        "    #for ep in range(1000):\n",
        "    for ep in range(10):\n",
        "      loss_recon_all = 0\n",
        "      loss_kl_all = 0\n",
        "      for idx, (data, label) in enumerate(feature_loader):\n",
        "        print(\"training loop...\")\n",
        "        data = data\n",
        "        \n",
        "        #weight = weight.cuda() / torch.sum(weight)\n",
        "        attr = torch.from_numpy(attributes[label]).float().cuda()\n",
        "        data = data.cuda()\n",
        "        #print(attr.device)\n",
        "        #print(data.device)\n",
        "        mu, logvar, recon_feats = feats_vae(data, attr)\n",
        "        recon_loss = ((recon_feats - data)**2).mean(1)\n",
        "        recon_loss = torch.mean(recon_loss)\n",
        "        #kl_loss = -0.5*torch.sum(1+logvar-logvar.exp()-mu.pow(2)) / data.shape[0]\n",
        "        kl_loss = (1+logvar-logvar.exp()-mu.pow(2)).sum(1)\n",
        "        kl_loss = -0.5*torch.mean(kl_loss)\n",
        "        L_vae = recon_loss+kl_loss\n",
        "        optimizer.zero_grad()\n",
        "        L_vae.backward()   \n",
        "        optimizer.step()\n",
        "        loss_recon_all += recon_loss.item()\n",
        "        loss_kl_all += kl_loss.item()\n",
        "        break\n",
        "      print('Ep: %d   Recon Loss: %f   KL Loss: %f'%(ep, loss_recon_all/(idx+1), loss_kl_all/(idx+1)))\n",
        "      print(recon_feats.shape)\n",
        "    return feats_vae\n",
        "    #torch.save({'state': feats_vae.state_dict()}, 'feats_vae_mini.pth') \n",
        "\n",
        "feats_vae = train_vae(feature_loader, feats_vae, attr)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JN9RRAsJNhzB",
        "outputId": "21bfb3f2-9b52-4b82-a57d-97f182b6b8e4"
      },
      "execution_count": 148,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "training loop...\n",
            "Ep: 0   Recon Loss: 0.398128   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 1   Recon Loss: 0.402707   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 2   Recon Loss: 0.385123   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3   Recon Loss: 0.407080   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 4   Recon Loss: 0.415261   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 5   Recon Loss: 0.400256   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 6   Recon Loss: 0.395987   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 7   Recon Loss: 0.402088   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 8   Recon Loss: 0.391435   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 9   Recon Loss: 0.388897   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Inference and Save: Unseen Set**"
      ],
      "metadata": {
        "id": "XKLK9fOVqNZ8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data_unseen_test = scipy.io.loadmat('/content/fsl-rsvae/datasets/AWA1/unseen_test.mat')\n",
        "data_unseen_test = data_unseen_test['feature']\n",
        "#data_train = np.transpose(data_train)\n",
        "\n",
        "# labels\n",
        "label_unseen_test = scipy.io.loadmat('/content/fsl-rsvae/datasets/AWA1/unseen_test_label.mat')\n",
        "label_unseen_test = label_unseen_test['label'][0]\n",
        "\n",
        "# attr\n",
        "unseen_attr = scipy.io.loadmat('/content/fsl-rsvae/datasets/AWA1/unseen_attribute.mat')\n",
        "unseen_attr = unseen_attr['unseen_attribute']\n",
        "\n",
        "#/content/fsl-rsvae/datasets/AWA1/unseen_attribute.mat"
      ],
      "metadata": {
        "id": "vWAa8HEplB2t"
      },
      "execution_count": 140,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "feature_un_dataset = FeatureDataset(data_unseen_test, label_unseen_test, unseen_attr)\n",
        "feature_un_loader = torch.utils.data.DataLoader(feature_dataset, shuffle=False, drop_last=False, batch_size=len(feature_un_dataset))  # len(feature_un_dataset)"
      ],
      "metadata": {
        "id": "jLAB7R1SqVqE"
      },
      "execution_count": 141,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_feats_with_noise(feats_vae, unseen_attr, samples_per_class=500):\n",
        "    feats_vae.eval()\n",
        "    #feats_vae.to()\n",
        "    feats_vae.to(torch.device('cuda:0'))\n",
        "    #z_dist = normal.Normal(0, 1)\n",
        "    ground_truths = list(range(len(unseen_attr)))*samples_per_class\n",
        "    uns_atr = torch.from_numpy(np.array(unseen_attr)[ground_truths]).float().cuda() #to(torch.float32)\n",
        "    #attr = torch.from_numpy(attributes[label])\n",
        "    #attr = attr.repeat(ind_count, 1)\n",
        "\n",
        "    z_dist = normal.Normal(0, 1)\n",
        "    Z = z_dist.sample((samples_per_class*len(unseen_attr), 2048)).cuda()\n",
        "\n",
        "    mu, logvar, recon_feats = feats_vae(Z, uns_atr)\n",
        "    return ground_truths, recon_feats\n",
        "\n",
        "gt, rct = generate_feats_with_noise(feats_vae, unseen_attr)\n",
        "print(rct.size())\n",
        "print(np.shape(gt))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DU5ajTXEoE1i",
        "outputId": "f83aaa76-c4ee-403a-b155-60c8f853a8d3"
      },
      "execution_count": 142,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([5000, 2048])\n",
            "(5000,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "rcts = rct.cpu().detach().numpy()\n",
        "gt = np.array(gt)\n",
        "this = {\"reconstructed_noise\" : rcts, \"labels\" : gt}\n",
        "scipy.io.savemat(\"reconstructed_noise.mat\", this)"
      ],
      "metadata": {
        "id": "hMkp_2J03TAG"
      },
      "execution_count": 143,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_feats_with_image(feats_vae, unseen_attr,  samples_per_class=500):\n",
        "    feats_vae.eval()\n",
        "    #feats_vae.to()\n",
        "    feats_vae.to(torch.device('cuda:0'))\n",
        "    for idx, (data, label) in enumerate(feature_un_loader):\n",
        "        #print(idx)\n",
        "\n",
        "        ground_truths = label\n",
        "        #print(torch.from_numpy(np.array((attr)[label])).to(torch.float32)\n",
        "        #uns_atr = torch.from_numpy(np.array(attr)[label]).to(torch.float32)\n",
        "        uns_atr = torch.from_numpy(np.array((attr)[label])).to(torch.float32).cuda()\n",
        "        #print(uns_atr.shape)\n",
        "        #print(data.shape)\n",
        "        #print(uns_atr.shape)\n",
        "        mu, logvar, recon_feats = feats_vae(data.cuda(), uns_atr)\n",
        "        #print(recon_feats.shape)\n",
        "        ground_truths = ground_truths.cpu().detach().numpy()\n",
        "        recon_feats = recon_feats.cpu().detach().numpy()\n",
        "\n",
        "    return ground_truths, recon_feats\n",
        "\n",
        "gt, rct = generate_feats_with_image(feats_vae, unseen_attr)\n",
        "print(rct.shape)\n",
        "print(gt.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fNd_6dzVqsmH",
        "outputId": "999058ba-1a60-4b7e-afdd-0a3856179a39"
      },
      "execution_count": 144,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(19832, 2048)\n",
            "(19832,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "this = {\"reconstructed_image\" : rct, \"labels\" : gt}\n",
        "scipy.io.savemat(\"reconstructed_image.mat\", this)"
      ],
      "metadata": {
        "id": "wjkGgelx5UrV"
      },
      "execution_count": 145,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!cp /content/reconstructed_noise.mat /content/gdrive/MyDrive/generated_data"
      ],
      "metadata": {
        "id": "8yopX_sE68P8"
      },
      "execution_count": 146,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!cp /content/reconstructed_image.mat /content/gdrive/MyDrive/generated_data"
      ],
      "metadata": {
        "id": "9qFR09JF8alF"
      },
      "execution_count": 147,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "NyWDazqK8k5k"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}