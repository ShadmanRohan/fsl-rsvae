{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPMZ1o4vDX3QrdZBYgnXWNF",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ShadmanRohan/fsl-rsvae/blob/main/Basic_Feat_Gen.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Preliminaries**"
      ],
      "metadata": {
        "id": "0F1r6VXg0fZO"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9Fkr40LMo7uc",
        "outputId": "b6eb943f-d300-49c0-87cf-4bc88e2a2a12"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'fsl-rsvae'...\n",
            "remote: Enumerating objects: 427, done.\u001b[K\n",
            "remote: Counting objects: 100% (427/427), done.\u001b[K\n",
            "remote: Compressing objects: 100% (231/231), done.\u001b[K\n",
            "remote: Total 427 (delta 209), reused 402 (delta 195), pack-reused 0\u001b[K\n",
            "Receiving objects: 100% (427/427), 454.14 KiB | 17.47 MiB/s, done.\n",
            "Resolving deltas: 100% (209/209), done.\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/ShadmanRohan/fsl-rsvae.git"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4ktupjgODfja",
        "outputId": "91485535-6a24-46b4-e1af-2d45f351bbf4"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/gdrive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from distutils.dir_util import copy_tree\n",
        "copy_tree(\"/content/gdrive/MyDrive/PAMI/AWA1_AWA2_SUN/data/AWA1\", \"/content/fsl-rsvae/datasets/AWA1\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IEef9zeLD52b",
        "outputId": "8fd5ccef-ed3c-4770-ff71-9e0e4038a148"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['/content/fsl-rsvae/datasets/AWA1/seen_test.mat',\n",
              " '/content/fsl-rsvae/datasets/AWA1/seen_attribute.mat',\n",
              " '/content/fsl-rsvae/datasets/AWA1/seen_test_label.mat',\n",
              " '/content/fsl-rsvae/datasets/AWA1/seen_train.mat',\n",
              " '/content/fsl-rsvae/datasets/AWA1/unseen_attribute.mat',\n",
              " '/content/fsl-rsvae/datasets/AWA1/seen_train_label.mat',\n",
              " '/content/fsl-rsvae/datasets/AWA1/unseen_test.mat',\n",
              " '/content/fsl-rsvae/datasets/AWA1/unseen_test_label.mat']"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import argparse\n",
        "import numpy as np\n",
        "from torch.autograd import Variable\n",
        "#from torchvision.datasets.folder import DatasetFolder\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torch.distributions import uniform, normal\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from matplotlib import pyplot as plt\n",
        "import torch.optim\n",
        "import json\n",
        "import torch.utils.data.sampler\n",
        "import os\n",
        "import glob\n",
        "import random\n",
        "import time\n",
        "import pdb\n",
        "import yaml\n",
        "#import datasets.feature_loader as feat_loader\n",
        "from sklearn.manifold import TSNE\n",
        "import h5py\n",
        "from scipy.stats import multivariate_normal\n",
        "import scipy"
      ],
      "metadata": {
        "id": "k8kzzG1xpNSE"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Dataloader**"
      ],
      "metadata": {
        "id": "ALmNYwLE0koN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import scipy.io\n",
        "#features\n",
        "data_train = scipy.io.loadmat('/content/fsl-rsvae/datasets/AWA1/seen_train.mat')\n",
        "data_train = data_train['feature']\n",
        "#data_train = np.transpose(data_train)\n",
        "\n",
        "\n",
        "# labels\n",
        "label_train = scipy.io.loadmat('/content/fsl-rsvae/datasets/AWA1/seen_train_label.mat')\n",
        "data_train_label = label_train['label'][0]\n",
        "\n",
        "\n",
        "# attr\n",
        "tmp = scipy.io.loadmat('/content/fsl-rsvae/datasets/AWA1/seen_attribute.mat')\n",
        "attr = tmp['seen_attribute']\n",
        "#attr = np.transpose(attr)"
      ],
      "metadata": {
        "id": "KWmLvTptFmf9"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class FeatureDataset(Dataset):\n",
        "\n",
        "    def __init__(self, features, labels, attr):\n",
        "        self.labels = labels\n",
        "        self.features = features\n",
        "        self.attr = attr\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(data_train)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        return self.features[idx], self.labels[idx]\n",
        "\n",
        "feature_dataset = FeatureDataset(data_train, data_train_label, attr)\n",
        "feature_loader = torch.utils.data.DataLoader(feature_dataset, shuffle=True, pin_memory=True, drop_last=False, batch_size=256) "
      ],
      "metadata": {
        "id": "OiH7f_bqFb3i"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Model**"
      ],
      "metadata": {
        "id": "foS4BJaI0poO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class FeatsVAE(nn.Module):\n",
        "    def __init__(self, x_dim, latent_dim, bottle_neck):\n",
        "        super(FeatsVAE, self).__init__()\n",
        "\n",
        "        self.x_dim = x_dim\n",
        "        self.latent_dim = latent_dim\n",
        "        self.bn1 = nn.BatchNorm1d(x_dim)\n",
        "        self.relu = nn.ReLU(inplace=True)\n",
        "        self.z_dist = normal.Normal(0, 1)\n",
        "        self.init_weights()\n",
        "\n",
        "        self.linear = nn.Sequential(\n",
        "            nn.Linear(self.x_dim+self.latent_dim, bottle_neck),\n",
        "            #nn.LeakyReLU(),\n",
        "            #nn.Linear(1096, 2096),\n",
        "            nn.LeakyReLU())\n",
        "        self.linear_mu =  nn.Sequential(\n",
        "            nn.Linear(bottle_neck, latent_dim),\n",
        "            nn.ReLU())\n",
        "        self.linear_logvar =  nn.Sequential(\n",
        "            nn.Linear(bottle_neck, latent_dim),\n",
        "            nn.ReLU())\n",
        "        self.model = nn.Sequential(\n",
        "            nn.Linear(2*latent_dim, bottle_neck),\n",
        "            nn.LeakyReLU(),\n",
        "            #nn.Linear(4096, 4096),\n",
        "            #nn.LeakyReLU(),\n",
        "            nn.Linear(bottle_neck, x_dim),\n",
        "            #nn.Sigmoid(),\n",
        "        )\n",
        "        \n",
        "\n",
        "\n",
        "\n",
        "    def reparameterize(self, mu, logvar):\n",
        "        std = torch.exp(0.5*logvar)  \n",
        "        eps = torch.randn_like(std)\n",
        "        # remove abnormal points\n",
        "        return mu + eps*std\n",
        "\n",
        "    def init_weights(self):\n",
        "        for m in self.modules():\n",
        "          if isinstance(m, nn.Linear):\n",
        "              m.weight.data.normal_(0, 0.02)\n",
        "              m.bias.data.normal_(0, 0.02)\n",
        "\n",
        "    def forward(self, x, attr):\n",
        "        #print(x.size())\n",
        "        #print(attr.size())\n",
        "\n",
        "        x = torch.cat((x, attr), dim=1).to(torch.float32)\n",
        "        #print(x.size())\n",
        "        #print(self.x_dim+self.latent_dim)\n",
        "        \n",
        "        x = self.linear(x)\n",
        "        #print(x.size())\n",
        "        mu = self.linear_mu(x)\n",
        "        #print(x)\n",
        "        logvar = self.linear_logvar(x)\n",
        "        #print(logvar)\n",
        "        latent_feats = self.reparameterize(mu, logvar)\n",
        "        #Z = self.z_dist.sample(attr.shape).cuda() \n",
        "        concat_feats = torch.cat((latent_feats, attr), dim=1)\n",
        "        recon_feats = self.model(concat_feats)\n",
        "        recon_feats = self.relu(self.bn1(recon_feats))\n",
        "        return mu, logvar, recon_feats\n",
        "\n",
        "feats_vae = FeatsVAE(x_dim=2048, latent_dim=85, bottle_neck=96) # latent dim = attribute dim"
      ],
      "metadata": {
        "id": "QR8I-FHnK1gq"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Train**"
      ],
      "metadata": {
        "id": "M7OEf2vy0thp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def train_vae(feature_loader, feats_vae, attributes):\n",
        "    optimizer = torch.optim.Adam(feats_vae.parameters(), lr=0.001)\n",
        "    #feats_vae.cuda()\n",
        "    #for ep in range(10):\n",
        "    for ep in range(10):\n",
        "      loss_recon_all = 0\n",
        "      loss_kl_all = 0\n",
        "      for idx, (data, label) in enumerate(feature_loader):\n",
        "        print(\"training loop...\")\n",
        "        data = data\n",
        "        #weight = weight.cuda() / torch.sum(weight)\n",
        "        attr = torch.from_numpy(attributes[label]).float()\n",
        "        mu, logvar, recon_feats = feats_vae(data, attr)\n",
        "        recon_loss = ((recon_feats - data)**2).mean(1)\n",
        "        recon_loss = torch.mean(recon_loss)\n",
        "        #kl_loss = -0.5*torch.sum(1+logvar-logvar.exp()-mu.pow(2)) / data.shape[0]\n",
        "        kl_loss = (1+logvar-logvar.exp()-mu.pow(2)).sum(1)\n",
        "        kl_loss = -0.5*torch.mean(kl_loss)\n",
        "        L_vae = recon_loss+kl_loss\n",
        "        optimizer.zero_grad()\n",
        "        L_vae.backward()   \n",
        "        optimizer.step()\n",
        "        loss_recon_all += recon_loss.item()\n",
        "        loss_kl_all += kl_loss.item()\n",
        "        break\n",
        "      print('Ep: %d   Recon Loss: %f   KL Loss: %f'%(ep, loss_recon_all/(idx+1), loss_kl_all/(idx+1)))\n",
        "      print(recon_feats.shape)\n",
        "    return feats_vae\n",
        "    #torch.save({'state': feats_vae.state_dict()}, 'feats_vae_mini.pth') \n",
        "\n",
        "feats_vae = train_vae(feature_loader, feats_vae, attr)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 339
        },
        "id": "JN9RRAsJNhzB",
        "outputId": "735287f4-81f6-4c8d-adc8-fbf023e8b35f"
      },
      "execution_count": 91,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "training loop...\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-91-2909ff157cd3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     29\u001b[0m     \u001b[0;31m#torch.save({'state': feats_vae.state_dict()}, 'feats_vae_mini.pth')\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 31\u001b[0;31m \u001b[0mfeats_vae\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_vae\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeature_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeats_vae\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-91-2909ff157cd3>\u001b[0m in \u001b[0;36mtrain_vae\u001b[0;34m(feature_loader, feats_vae, attributes)\u001b[0m\n\u001b[1;32m     12\u001b[0m         \u001b[0mattr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_numpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mattributes\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlabel\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m         \u001b[0mmu\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogvar\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrecon_feats\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfeats_vae\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m         \u001b[0mrecon_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrecon_feats\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m         \u001b[0mrecon_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrecon_loss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m         \u001b[0;31m#kl_loss = -0.5*torch.sum(1+logvar-logvar.exp()-mu.pow(2)) / data.shape[0]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: Expected all tensors to be on the same device, but found at least two devices, cuda:0 and cpu!"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Inference and Save: Unseen Set**"
      ],
      "metadata": {
        "id": "XKLK9fOVqNZ8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data_unseen_test = scipy.io.loadmat('/content/fsl-rsvae/datasets/AWA1/unseen_test.mat')\n",
        "data_unseen_test = data_unseen_test['feature']\n",
        "#data_train = np.transpose(data_train)\n",
        "\n",
        "\n",
        "# labels\n",
        "label_unseen_test = scipy.io.loadmat('/content/fsl-rsvae/datasets/AWA1/unseen_test_label.mat')\n",
        "label_unseen_test = label_unseen_test['label'][0]\n",
        "\n",
        "\n",
        "# attr\n",
        "unseen_attr = scipy.io.loadmat('/content/fsl-rsvae/datasets/AWA1/unseen_attribute.mat')\n",
        "unseen_attr = unseen_attr['unseen_attribute']\n",
        "\n",
        "#/content/fsl-rsvae/datasets/AWA1/unseen_attribute.mat"
      ],
      "metadata": {
        "id": "vWAa8HEplB2t"
      },
      "execution_count": 67,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "feature_un_dataset = FeatureDataset(data_unseen_test, label_unseen_test, unseen_attr)\n",
        "feature_un_loader = torch.utils.data.DataLoader(feature_dataset, shuffle=False, pin_memory=True, drop_last=False, batch_size=len(feature_un_dataset))  # len(feature_un_dataset)"
      ],
      "metadata": {
        "id": "jLAB7R1SqVqE"
      },
      "execution_count": 68,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_feats_with_noise(feats_vae, unseen_attr, samples_per_class=500):\n",
        "    feats_vae.eval()\n",
        "    #feats_vae.to()\n",
        "    feats_vae.to(torch.device('cuda:0'))\n",
        "    #z_dist = normal.Normal(0, 1)\n",
        "    ground_truths = list(range(len(unseen_attr)))*samples_per_class\n",
        "    uns_atr = torch.from_numpy(np.array(unseen_attr)[ground_truths]).float().cuda() #to(torch.float32)\n",
        "    #attr = torch.from_numpy(attributes[label])\n",
        "    #attr = attr.repeat(ind_count, 1)\n",
        "\n",
        "    z_dist = normal.Normal(0, 1)\n",
        "    Z = z_dist.sample((samples_per_class*len(unseen_attr), 2048)).cuda()\n",
        "\n",
        "    mu, logvar, recon_feats = feats_vae(Z, uns_atr)\n",
        "    return ground_truths, recon_feats\n",
        "\n",
        "gt, rct = generate_feats_with_noise(feats_vae, unseen_attr)\n",
        "print(rct.size())\n",
        "print(np.shape(gt))"
      ],
      "metadata": {
        "id": "DU5ajTXEoE1i",
        "outputId": "e84148dc-abac-4d15-91a3-c8790cc96ddc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 86,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([5000, 2048])\n",
            "(5000,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_feats_with_image(feats_vae, unseen_attr,  samples_per_class=500):\n",
        "    feats_vae.eval()\n",
        "    #feats_vae.to()\n",
        "    feats_vae.to(torch.device('cuda:0'))\n",
        "    for idx, (data, label) in enumerate(feature_un_loader):\n",
        "        #print(idx)\n",
        "\n",
        "        ground_truths = label\n",
        "        #print(torch.from_numpy(np.array((attr)[label])).to(torch.float32)\n",
        "        #uns_atr = torch.from_numpy(np.array(attr)[label]).to(torch.float32)\n",
        "        uns_atr = torch.from_numpy(np.array((attr)[label])).to(torch.float32).cuda()\n",
        "        #print(uns_atr.shape)\n",
        "        #print(data.shape)\n",
        "        #print(uns_atr.shape)\n",
        "        mu, logvar, recon_feats = feats_vae(data.cuda(), uns_atr)\n",
        "        #print(recon_feats.shape)\n",
        "        \n",
        "    return ground_truths, recon_feats\n",
        "\n",
        "gt, rct = generate_feats_with_image(feats_vae, unseen_attr)\n",
        "print(rct.size())\n",
        "print(gt.size())"
      ],
      "metadata": {
        "id": "fNd_6dzVqsmH",
        "outputId": "0d7b4cdf-863c-437f-80cf-a695b2876bf1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 83,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([19832, 2048])\n",
            "torch.Size([19832])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#attr = torch.from_numpy(attr)\n",
        "feats_vae.eval()\n",
        "feats_vae.to(torch.device('cuda:0'))\n",
        "for idx, (data, label) in enumerate(feature_un_loader):\n",
        "    #print(idx)\n",
        "    print(data.size())\n",
        "    #print(label)\n",
        "    print(np.array(attr)[label].shape)\n",
        "    uns_atr = torch.from_numpy(np.array(attr)[label]).to(torch.float32)\n",
        "    mu, logvar, recon_feats = feats_vae(data.cuda(), uns_atr.cuda())\n",
        "    break"
      ],
      "metadata": {
        "id": "1Ofh8JLcKSMA",
        "outputId": "45ff85c8-dc7b-4059-da4c-5dca538fad57",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([19832, 2048])\n",
            "(19832, 85)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pickle\n",
        "\n",
        "recon_feats = recon_feats.cpu().detach().numpy()\n",
        "with open('new_feats.pickle', 'wb') as handle:\n",
        "    pickle.dump(recon_feats, handle, protocol=pickle.HIGHEST_PROTOCOL)"
      ],
      "metadata": {
        "id": "ak4bfxu6nDfO"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with open('new_feats.pickle', 'rb') as handle:\n",
        "    recon_feats2 = pickle.load(handle)"
      ],
      "metadata": {
        "id": "4D2Hqa_MnVTP"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "iter(feature_un_loader).next()"
      ],
      "metadata": {
        "id": "G1b3ZvkOrI7f",
        "outputId": "18569dc7-4394-404d-a2b9-0ac9af590bcb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[tensor([[0.9481, 0.3016, 1.5640,  ..., 0.1973, 0.0000, 0.8925],\n",
              "         [0.0279, 1.6711, 0.0000,  ..., 0.0000, 0.2870, 0.0278],\n",
              "         [0.0304, 2.1978, 0.2140,  ..., 0.5149, 0.0000, 0.0663],\n",
              "         ...,\n",
              "         [0.1767, 0.3275, 0.4538,  ..., 4.3562, 0.0113, 0.0000],\n",
              "         [0.1029, 0.6553, 0.0000,  ..., 3.5781, 1.2353, 0.0805],\n",
              "         [1.8800, 0.8376, 0.1417,  ..., 0.4653, 0.2352, 0.1469]],\n",
              "        dtype=torch.float64),\n",
              " tensor([ 0,  0,  0,  ..., 39, 39, 39], dtype=torch.uint8)]"
            ]
          },
          "metadata": {},
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "torch.from_numpy(np.array(attr)[label]).size()"
      ],
      "metadata": {
        "id": "aTm2aNj7osN0",
        "outputId": "4cc15cf1-a856-48e6-8488-95514c7fad94",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([19832, 85])"
            ]
          },
          "metadata": {},
          "execution_count": 56
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "2GCrnhsFp_7q"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}