{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPDLGw6/El0BFh+6gFy2mRi",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ShadmanRohan/fsl-rsvae/blob/main/Basic_Feat_Gen.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Preliminaries**"
      ],
      "metadata": {
        "id": "0F1r6VXg0fZO"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9Fkr40LMo7uc",
        "outputId": "aec9112b-9c23-43cc-9394-bac30560f324"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'fsl-rsvae'...\n",
            "remote: Enumerating objects: 439, done.\u001b[K\n",
            "remote: Counting objects: 100% (439/439), done.\u001b[K\n",
            "remote: Compressing objects: 100% (243/243), done.\u001b[K\n",
            "remote: Total 439 (delta 217), reused 402 (delta 195), pack-reused 0\u001b[K\n",
            "Receiving objects: 100% (439/439), 473.18 KiB | 17.52 MiB/s, done.\n",
            "Resolving deltas: 100% (217/217), done.\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/ShadmanRohan/fsl-rsvae.git"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4ktupjgODfja",
        "outputId": "4910d874-ebaa-4b49-ccbd-1892ae2263c8"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/gdrive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from distutils.dir_util import copy_tree\n",
        "copy_tree(\"/content/gdrive/MyDrive/PAMI/AWA1_AWA2_SUN/data/AWA1\", \"/content/fsl-rsvae/datasets/AWA1\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IEef9zeLD52b",
        "outputId": "3b3b19cb-3002-4251-d50c-b253355a85ae"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['/content/fsl-rsvae/datasets/AWA1/seen_test.mat',\n",
              " '/content/fsl-rsvae/datasets/AWA1/seen_attribute.mat',\n",
              " '/content/fsl-rsvae/datasets/AWA1/seen_test_label.mat',\n",
              " '/content/fsl-rsvae/datasets/AWA1/seen_train.mat',\n",
              " '/content/fsl-rsvae/datasets/AWA1/unseen_attribute.mat',\n",
              " '/content/fsl-rsvae/datasets/AWA1/seen_train_label.mat',\n",
              " '/content/fsl-rsvae/datasets/AWA1/unseen_test.mat',\n",
              " '/content/fsl-rsvae/datasets/AWA1/unseen_test_label.mat']"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import argparse\n",
        "import numpy as np\n",
        "from torch.autograd import Variable\n",
        "#from torchvision.datasets.folder import DatasetFolder\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torch.distributions import uniform, normal\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from matplotlib import pyplot as plt\n",
        "import torch.optim\n",
        "import json\n",
        "import torch.utils.data.sampler\n",
        "import os\n",
        "import glob\n",
        "import random\n",
        "import time\n",
        "import pdb\n",
        "import yaml\n",
        "#import datasets.feature_loader as feat_loader\n",
        "from sklearn.manifold import TSNE\n",
        "import h5py\n",
        "from scipy.stats import multivariate_normal\n",
        "import scipy"
      ],
      "metadata": {
        "id": "k8kzzG1xpNSE"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Dataloader**"
      ],
      "metadata": {
        "id": "ALmNYwLE0koN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import scipy.io\n",
        "#features\n",
        "data_train = scipy.io.loadmat('/content/fsl-rsvae/datasets/AWA1/seen_train.mat')\n",
        "data_train = data_train['feature']\n",
        "#data_train = np.transpose(data_train)\n",
        "\n",
        "\n",
        "# labels\n",
        "label_train = scipy.io.loadmat('/content/fsl-rsvae/datasets/AWA1/seen_train_label.mat')\n",
        "data_train_label = label_train['label'][0]\n",
        "\n",
        "\n",
        "# attr\n",
        "tmp = scipy.io.loadmat('/content/fsl-rsvae/datasets/AWA1/seen_attribute.mat')\n",
        "attr = tmp['seen_attribute']\n",
        "#attr = np.transpose(attr)"
      ],
      "metadata": {
        "id": "KWmLvTptFmf9"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class FeatureDataset(Dataset):\n",
        "\n",
        "    def __init__(self, features, labels, attr):\n",
        "        self.labels = labels\n",
        "        self.features = features\n",
        "        self.attr = attr\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(data_train)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        return self.features[idx], self.labels[idx]\n",
        "\n",
        "feature_dataset = FeatureDataset(data_train, data_train_label, attr)\n",
        "feature_loader = torch.utils.data.DataLoader(feature_dataset, shuffle=True, pin_memory=True, drop_last=False, batch_size=256) "
      ],
      "metadata": {
        "id": "OiH7f_bqFb3i"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Model**"
      ],
      "metadata": {
        "id": "foS4BJaI0poO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class FeatsVAE(nn.Module):\n",
        "    def __init__(self, x_dim, latent_dim, bottle_neck):\n",
        "        super(FeatsVAE, self).__init__()\n",
        "\n",
        "        self.x_dim = x_dim\n",
        "        self.latent_dim = latent_dim\n",
        "        self.bn1 = nn.BatchNorm1d(x_dim)\n",
        "        self.relu = nn.ReLU(inplace=True)\n",
        "        self.z_dist = normal.Normal(0, 1)\n",
        "        self.init_weights()\n",
        "\n",
        "        self.encoder = nn.Sequential(\n",
        "            nn.Linear(self.x_dim+self.latent_dim, 1096),\n",
        "            nn.LeakyReLU(),\n",
        "            nn.Linear(1096, bottle_neck),\n",
        "            nn.LeakyReLU())\n",
        "        \n",
        "        self.linear_mu =  nn.Sequential(\n",
        "            nn.Linear(bottle_neck, latent_dim),\n",
        "            nn.ReLU())\n",
        "        self.linear_logvar =  nn.Sequential(\n",
        "            nn.Linear(bottle_neck, latent_dim),\n",
        "            nn.ReLU())\n",
        "        \n",
        "        self.decoder = nn.Sequential(\n",
        "            nn.Linear(2*latent_dim, 512),  # 170\n",
        "            nn.LeakyReLU(),\n",
        "            nn.Linear(512, 1024),\n",
        "            nn.LeakyReLU(),\n",
        "            nn.Linear(1024, x_dim),  #2048\n",
        "            #nn.Sigmoid(),\n",
        "            nn.LeakyReLU(),\n",
        "        )\n",
        "        \n",
        "\n",
        "\n",
        "\n",
        "    def reparameterize(self, mu, logvar):\n",
        "        std = torch.exp(0.5*logvar)  \n",
        "        eps = torch.randn_like(std)\n",
        "        # remove abnormal points\n",
        "        return mu + eps*std\n",
        "\n",
        "    def init_weights(self):\n",
        "        for m in self.modules():\n",
        "          if isinstance(m, nn.Linear):\n",
        "              m.weight.data.normal_(0, 0.02)\n",
        "              m.bias.data.normal_(0, 0.02)\n",
        "\n",
        "    def forward(self, x, attr):\n",
        "        #print(x.size())\n",
        "        #print(attr.size())\n",
        "\n",
        "        x = torch.cat((x, attr), dim=1).to(torch.float32)   # 2048+85\n",
        "        #print(x.size())\n",
        "        #print(self.x_dim+self.latent_dim)\n",
        "        \n",
        "        x = self.encoder(x)    # 2048+85 -> 8\n",
        "        #print(x.size())\n",
        "        mu = self.linear_mu(x) # 8 -> 85\n",
        "        #print(x)\n",
        "        logvar = self.linear_logvar(x)  # 8 -> 85\n",
        "        #print(logvar)\n",
        "        latent_feats = self.reparameterize(mu, logvar)  # 85 (sample)\n",
        "        #Z = self.z_dist.sample(attr.shape).cuda() \n",
        "        concat_feats = torch.cat((latent_feats, attr), dim=1)  # 85+85 (predecoding concat)\n",
        "\n",
        "        recon_feats = self.decoder(concat_feats)  #85*2 -> 8\n",
        "        #recon_feats = self.relu(self.bn1(recon_feats))\n",
        "        recon_feats = self.relu(recon_feats)\n",
        "        return mu, logvar, recon_feats\n",
        "\n",
        "feats_vae = FeatsVAE(x_dim=2048, latent_dim=85, bottle_neck=128) # latent dim = attribute dim"
      ],
      "metadata": {
        "id": "QR8I-FHnK1gq"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Train**"
      ],
      "metadata": {
        "id": "M7OEf2vy0thp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def train_vae(feature_loader, feats_vae, attributes):\n",
        "    optimizer = torch.optim.Adam(feats_vae.parameters(), lr=0.001)\n",
        "    feats_vae.train()\n",
        "    feats_vae.cuda()\n",
        "    #for ep in range(1000):\n",
        "    for ep in range(4000):\n",
        "      loss_recon_all = 0\n",
        "      loss_kl_all = 0\n",
        "      for idx, (data, label) in enumerate(feature_loader):\n",
        "        print(\"training loop...\")\n",
        "        data = data\n",
        "        \n",
        "        #weight = weight.cuda() / torch.sum(weight)\n",
        "        attr = torch.from_numpy(attributes[label]).float().cuda()\n",
        "        data = data.cuda()\n",
        "        #print(attr.device)\n",
        "        #print(data.device)\n",
        "        mu, logvar, recon_feats = feats_vae(data, attr)\n",
        "        recon_loss = ((recon_feats - data)**2).mean(1)\n",
        "        recon_loss = torch.mean(recon_loss)\n",
        "        #kl_loss = -0.5*torch.sum(1+logvar-logvar.exp()-mu.pow(2)) / data.shape[0]\n",
        "        kl_loss = (1+logvar-logvar.exp()-mu.pow(2)).sum(1)\n",
        "        kl_loss = -0.5*torch.mean(kl_loss)\n",
        "        L_vae = recon_loss+kl_loss\n",
        "        optimizer.zero_grad()\n",
        "        L_vae.backward()   \n",
        "        optimizer.step()\n",
        "        loss_recon_all += recon_loss.item()\n",
        "        loss_kl_all += kl_loss.item()\n",
        "        break\n",
        "      print('Ep: %d   Recon Loss: %f   KL Loss: %f'%(ep, loss_recon_all/(idx+1), loss_kl_all/(idx+1)))\n",
        "      print(recon_feats.shape)\n",
        "    return feats_vae\n",
        "    #torch.save({'state': feats_vae.state_dict()}, 'feats_vae_mini.pth') \n",
        "\n",
        "feats_vae = train_vae(feature_loader, feats_vae, attr)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JN9RRAsJNhzB",
        "outputId": "a936aec8-9bae-47d0-f3ba-955a244ae944"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1;30;43mStreaming output truncated to the last 5000 lines.\u001b[0m\n",
            "Ep: 2333   Recon Loss: 0.387305   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 2334   Recon Loss: 0.370310   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 2335   Recon Loss: 0.349500   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 2336   Recon Loss: 0.365552   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 2337   Recon Loss: 0.372776   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 2338   Recon Loss: 0.391265   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 2339   Recon Loss: 0.364439   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 2340   Recon Loss: 0.372855   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 2341   Recon Loss: 0.366796   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 2342   Recon Loss: 0.355840   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 2343   Recon Loss: 0.386110   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 2344   Recon Loss: 0.360696   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 2345   Recon Loss: 0.379226   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 2346   Recon Loss: 0.382741   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 2347   Recon Loss: 0.359980   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 2348   Recon Loss: 0.378005   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 2349   Recon Loss: 0.357256   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 2350   Recon Loss: 0.371960   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 2351   Recon Loss: 0.364648   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 2352   Recon Loss: 0.376051   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 2353   Recon Loss: 0.371692   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 2354   Recon Loss: 0.356807   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 2355   Recon Loss: 0.365129   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 2356   Recon Loss: 0.371757   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 2357   Recon Loss: 0.370940   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 2358   Recon Loss: 0.360244   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 2359   Recon Loss: 0.366118   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 2360   Recon Loss: 0.377333   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 2361   Recon Loss: 0.373206   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 2362   Recon Loss: 0.378480   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 2363   Recon Loss: 0.361561   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 2364   Recon Loss: 0.346923   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 2365   Recon Loss: 0.354282   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 2366   Recon Loss: 0.379913   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 2367   Recon Loss: 0.354423   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 2368   Recon Loss: 0.381089   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 2369   Recon Loss: 0.357839   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 2370   Recon Loss: 0.377499   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 2371   Recon Loss: 0.362806   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 2372   Recon Loss: 0.359297   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 2373   Recon Loss: 0.391234   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 2374   Recon Loss: 0.365126   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 2375   Recon Loss: 0.362486   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 2376   Recon Loss: 0.369385   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 2377   Recon Loss: 0.369755   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 2378   Recon Loss: 0.386835   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 2379   Recon Loss: 0.381103   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 2380   Recon Loss: 0.351363   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 2381   Recon Loss: 0.363245   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 2382   Recon Loss: 0.373474   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 2383   Recon Loss: 0.378961   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 2384   Recon Loss: 0.382702   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 2385   Recon Loss: 0.337568   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 2386   Recon Loss: 0.349776   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 2387   Recon Loss: 0.351134   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 2388   Recon Loss: 0.353249   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 2389   Recon Loss: 0.368908   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 2390   Recon Loss: 0.385188   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 2391   Recon Loss: 0.350323   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 2392   Recon Loss: 0.375692   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 2393   Recon Loss: 0.357194   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 2394   Recon Loss: 0.358411   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 2395   Recon Loss: 0.373872   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 2396   Recon Loss: 0.350901   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 2397   Recon Loss: 0.353093   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 2398   Recon Loss: 0.365316   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 2399   Recon Loss: 0.341752   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 2400   Recon Loss: 0.344683   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 2401   Recon Loss: 0.353099   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 2402   Recon Loss: 0.380609   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 2403   Recon Loss: 0.364183   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 2404   Recon Loss: 0.365485   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 2405   Recon Loss: 0.372451   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 2406   Recon Loss: 0.380101   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 2407   Recon Loss: 0.373107   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 2408   Recon Loss: 0.365959   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 2409   Recon Loss: 0.368159   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 2410   Recon Loss: 0.359336   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 2411   Recon Loss: 0.372230   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 2412   Recon Loss: 0.380447   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 2413   Recon Loss: 0.363978   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 2414   Recon Loss: 0.369222   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 2415   Recon Loss: 0.353182   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 2416   Recon Loss: 0.377822   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 2417   Recon Loss: 0.379767   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 2418   Recon Loss: 0.364887   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 2419   Recon Loss: 0.359778   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 2420   Recon Loss: 0.372527   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 2421   Recon Loss: 0.380769   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 2422   Recon Loss: 0.366007   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 2423   Recon Loss: 0.363241   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 2424   Recon Loss: 0.370967   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 2425   Recon Loss: 0.372609   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 2426   Recon Loss: 0.354061   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 2427   Recon Loss: 0.378844   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 2428   Recon Loss: 0.358965   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 2429   Recon Loss: 0.388368   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 2430   Recon Loss: 0.367712   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 2431   Recon Loss: 0.347288   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 2432   Recon Loss: 0.376105   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 2433   Recon Loss: 0.392833   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 2434   Recon Loss: 0.372510   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 2435   Recon Loss: 0.357132   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 2436   Recon Loss: 0.363463   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 2437   Recon Loss: 0.363070   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 2438   Recon Loss: 0.349561   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 2439   Recon Loss: 0.367432   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 2440   Recon Loss: 0.365658   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 2441   Recon Loss: 0.345428   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 2442   Recon Loss: 0.359233   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 2443   Recon Loss: 0.335830   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 2444   Recon Loss: 0.345841   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 2445   Recon Loss: 0.362698   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 2446   Recon Loss: 0.379359   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 2447   Recon Loss: 0.363790   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 2448   Recon Loss: 0.368243   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 2449   Recon Loss: 0.380042   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 2450   Recon Loss: 0.364719   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 2451   Recon Loss: 0.351858   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 2452   Recon Loss: 0.362785   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 2453   Recon Loss: 0.368571   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 2454   Recon Loss: 0.371718   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 2455   Recon Loss: 0.385113   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 2456   Recon Loss: 0.344257   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 2457   Recon Loss: 0.359335   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 2458   Recon Loss: 0.355545   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 2459   Recon Loss: 0.384345   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 2460   Recon Loss: 0.379529   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 2461   Recon Loss: 0.368346   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 2462   Recon Loss: 0.380560   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 2463   Recon Loss: 0.373015   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 2464   Recon Loss: 0.356122   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 2465   Recon Loss: 0.362847   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 2466   Recon Loss: 0.361278   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 2467   Recon Loss: 0.373574   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 2468   Recon Loss: 0.364774   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 2469   Recon Loss: 0.374299   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 2470   Recon Loss: 0.391305   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 2471   Recon Loss: 0.382119   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 2472   Recon Loss: 0.357409   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 2473   Recon Loss: 0.385102   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 2474   Recon Loss: 0.374157   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 2475   Recon Loss: 0.361042   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 2476   Recon Loss: 0.374916   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 2477   Recon Loss: 0.355375   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 2478   Recon Loss: 0.373192   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 2479   Recon Loss: 0.382542   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 2480   Recon Loss: 0.363535   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 2481   Recon Loss: 0.364672   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 2482   Recon Loss: 0.365895   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 2483   Recon Loss: 0.381962   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 2484   Recon Loss: 0.361741   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 2485   Recon Loss: 0.394452   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 2486   Recon Loss: 0.366660   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 2487   Recon Loss: 0.363007   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 2488   Recon Loss: 0.357445   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 2489   Recon Loss: 0.375095   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 2490   Recon Loss: 0.370359   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 2491   Recon Loss: 0.369815   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 2492   Recon Loss: 0.349182   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 2493   Recon Loss: 0.361483   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 2494   Recon Loss: 0.372789   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 2495   Recon Loss: 0.369736   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 2496   Recon Loss: 0.360892   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 2497   Recon Loss: 0.368911   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 2498   Recon Loss: 0.393142   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 2499   Recon Loss: 0.375337   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 2500   Recon Loss: 0.373244   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 2501   Recon Loss: 0.350632   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 2502   Recon Loss: 0.365381   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 2503   Recon Loss: 0.351914   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 2504   Recon Loss: 0.355764   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 2505   Recon Loss: 0.370135   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 2506   Recon Loss: 0.356513   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 2507   Recon Loss: 0.344841   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 2508   Recon Loss: 0.356054   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 2509   Recon Loss: 0.371832   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 2510   Recon Loss: 0.377644   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 2511   Recon Loss: 0.358170   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 2512   Recon Loss: 0.352703   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 2513   Recon Loss: 0.381042   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 2514   Recon Loss: 0.353989   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 2515   Recon Loss: 0.363051   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 2516   Recon Loss: 0.362781   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 2517   Recon Loss: 0.345316   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 2518   Recon Loss: 0.369918   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 2519   Recon Loss: 0.360543   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 2520   Recon Loss: 0.393827   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 2521   Recon Loss: 0.372639   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 2522   Recon Loss: 0.352526   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 2523   Recon Loss: 0.382530   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 2524   Recon Loss: 0.379683   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 2525   Recon Loss: 0.362489   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 2526   Recon Loss: 0.344023   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 2527   Recon Loss: 0.351850   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 2528   Recon Loss: 0.355691   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 2529   Recon Loss: 0.369360   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 2530   Recon Loss: 0.373677   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 2531   Recon Loss: 0.368996   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 2532   Recon Loss: 0.376809   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 2533   Recon Loss: 0.368993   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 2534   Recon Loss: 0.369634   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 2535   Recon Loss: 0.365973   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 2536   Recon Loss: 0.367121   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 2537   Recon Loss: 0.374405   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 2538   Recon Loss: 0.375792   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 2539   Recon Loss: 0.369408   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 2540   Recon Loss: 0.361091   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 2541   Recon Loss: 0.355830   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 2542   Recon Loss: 0.377822   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 2543   Recon Loss: 0.362414   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 2544   Recon Loss: 0.387119   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 2545   Recon Loss: 0.366393   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 2546   Recon Loss: 0.369017   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 2547   Recon Loss: 0.359462   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 2548   Recon Loss: 0.355607   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 2549   Recon Loss: 0.358828   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 2550   Recon Loss: 0.355813   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 2551   Recon Loss: 0.351676   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 2552   Recon Loss: 0.366046   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 2553   Recon Loss: 0.372087   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 2554   Recon Loss: 0.360043   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 2555   Recon Loss: 0.367466   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 2556   Recon Loss: 0.399698   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 2557   Recon Loss: 0.348591   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 2558   Recon Loss: 0.369353   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 2559   Recon Loss: 0.342969   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 2560   Recon Loss: 0.360404   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 2561   Recon Loss: 0.365128   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 2562   Recon Loss: 0.367256   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 2563   Recon Loss: 0.356755   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 2564   Recon Loss: 0.367780   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 2565   Recon Loss: 0.372732   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 2566   Recon Loss: 0.366372   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 2567   Recon Loss: 0.348941   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 2568   Recon Loss: 0.356248   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 2569   Recon Loss: 0.365795   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 2570   Recon Loss: 0.388395   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 2571   Recon Loss: 0.381470   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 2572   Recon Loss: 0.366734   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 2573   Recon Loss: 0.357573   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 2574   Recon Loss: 0.365959   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 2575   Recon Loss: 0.392589   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 2576   Recon Loss: 0.387043   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 2577   Recon Loss: 0.378704   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 2578   Recon Loss: 0.367916   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 2579   Recon Loss: 0.357609   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 2580   Recon Loss: 0.379842   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 2581   Recon Loss: 0.355381   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 2582   Recon Loss: 0.342688   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 2583   Recon Loss: 0.372811   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 2584   Recon Loss: 0.384160   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 2585   Recon Loss: 0.365590   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 2586   Recon Loss: 0.365795   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 2587   Recon Loss: 0.356631   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 2588   Recon Loss: 0.376370   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 2589   Recon Loss: 0.371632   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 2590   Recon Loss: 0.359089   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 2591   Recon Loss: 0.356343   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 2592   Recon Loss: 0.363144   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 2593   Recon Loss: 0.366580   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 2594   Recon Loss: 0.356733   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 2595   Recon Loss: 0.373235   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 2596   Recon Loss: 0.358325   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 2597   Recon Loss: 0.371858   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 2598   Recon Loss: 0.355617   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 2599   Recon Loss: 0.364804   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 2600   Recon Loss: 0.373811   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 2601   Recon Loss: 0.371578   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 2602   Recon Loss: 0.384969   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 2603   Recon Loss: 0.359032   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 2604   Recon Loss: 0.362157   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 2605   Recon Loss: 0.369856   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 2606   Recon Loss: 0.383968   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 2607   Recon Loss: 0.373039   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 2608   Recon Loss: 0.354145   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 2609   Recon Loss: 0.354799   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 2610   Recon Loss: 0.374891   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 2611   Recon Loss: 0.362863   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 2612   Recon Loss: 0.368268   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 2613   Recon Loss: 0.360851   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 2614   Recon Loss: 0.357670   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 2615   Recon Loss: 0.359811   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 2616   Recon Loss: 0.341944   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 2617   Recon Loss: 0.359662   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 2618   Recon Loss: 0.365063   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 2619   Recon Loss: 0.362551   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 2620   Recon Loss: 0.352831   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 2621   Recon Loss: 0.371144   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 2622   Recon Loss: 0.382450   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 2623   Recon Loss: 0.364530   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 2624   Recon Loss: 0.369509   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 2625   Recon Loss: 0.367990   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 2626   Recon Loss: 0.352724   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 2627   Recon Loss: 0.361033   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 2628   Recon Loss: 0.347054   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 2629   Recon Loss: 0.357137   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 2630   Recon Loss: 0.356407   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 2631   Recon Loss: 0.373037   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 2632   Recon Loss: 0.383453   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 2633   Recon Loss: 0.357955   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 2634   Recon Loss: 0.365270   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 2635   Recon Loss: 0.376519   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 2636   Recon Loss: 0.360841   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 2637   Recon Loss: 0.376699   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 2638   Recon Loss: 0.356188   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 2639   Recon Loss: 0.384730   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 2640   Recon Loss: 0.339513   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 2641   Recon Loss: 0.369035   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 2642   Recon Loss: 0.365659   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 2643   Recon Loss: 0.364227   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 2644   Recon Loss: 0.351126   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 2645   Recon Loss: 0.371859   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 2646   Recon Loss: 0.344706   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 2647   Recon Loss: 0.366713   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 2648   Recon Loss: 0.383567   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 2649   Recon Loss: 0.370437   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 2650   Recon Loss: 0.378980   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 2651   Recon Loss: 0.379212   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 2652   Recon Loss: 0.377720   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 2653   Recon Loss: 0.357424   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 2654   Recon Loss: 0.369706   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 2655   Recon Loss: 0.365114   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 2656   Recon Loss: 0.373539   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 2657   Recon Loss: 0.372263   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 2658   Recon Loss: 0.396907   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 2659   Recon Loss: 0.370573   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 2660   Recon Loss: 0.352013   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 2661   Recon Loss: 0.374764   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 2662   Recon Loss: 0.382182   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 2663   Recon Loss: 0.347176   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 2664   Recon Loss: 0.381535   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 2665   Recon Loss: 0.347365   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 2666   Recon Loss: 0.368138   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 2667   Recon Loss: 0.355910   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 2668   Recon Loss: 0.377151   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 2669   Recon Loss: 0.381683   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 2670   Recon Loss: 0.361715   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 2671   Recon Loss: 0.380686   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 2672   Recon Loss: 0.369834   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 2673   Recon Loss: 0.387096   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 2674   Recon Loss: 0.370790   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 2675   Recon Loss: 0.355591   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 2676   Recon Loss: 0.361551   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 2677   Recon Loss: 0.374047   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 2678   Recon Loss: 0.378519   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 2679   Recon Loss: 0.353460   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 2680   Recon Loss: 0.359049   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 2681   Recon Loss: 0.361267   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 2682   Recon Loss: 0.384806   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 2683   Recon Loss: 0.363429   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 2684   Recon Loss: 0.371499   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 2685   Recon Loss: 0.378871   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 2686   Recon Loss: 0.406550   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 2687   Recon Loss: 0.378097   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 2688   Recon Loss: 0.362166   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 2689   Recon Loss: 0.357476   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 2690   Recon Loss: 0.388870   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 2691   Recon Loss: 0.363544   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 2692   Recon Loss: 0.361905   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 2693   Recon Loss: 0.374410   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 2694   Recon Loss: 0.358331   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 2695   Recon Loss: 0.366050   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 2696   Recon Loss: 0.367667   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 2697   Recon Loss: 0.367817   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 2698   Recon Loss: 0.354830   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 2699   Recon Loss: 0.355956   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 2700   Recon Loss: 0.387004   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 2701   Recon Loss: 0.337203   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 2702   Recon Loss: 0.354932   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 2703   Recon Loss: 0.356477   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 2704   Recon Loss: 0.364375   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 2705   Recon Loss: 0.370634   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 2706   Recon Loss: 0.375691   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 2707   Recon Loss: 0.361210   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 2708   Recon Loss: 0.339527   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 2709   Recon Loss: 0.342169   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 2710   Recon Loss: 0.384686   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 2711   Recon Loss: 0.374569   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 2712   Recon Loss: 0.353257   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 2713   Recon Loss: 0.377008   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 2714   Recon Loss: 0.363311   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 2715   Recon Loss: 0.368252   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 2716   Recon Loss: 0.361607   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 2717   Recon Loss: 0.387430   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 2718   Recon Loss: 0.366131   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 2719   Recon Loss: 0.390641   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 2720   Recon Loss: 0.335397   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 2721   Recon Loss: 0.349714   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 2722   Recon Loss: 0.366511   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 2723   Recon Loss: 0.370092   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 2724   Recon Loss: 0.362135   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 2725   Recon Loss: 0.371541   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 2726   Recon Loss: 0.356697   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 2727   Recon Loss: 0.358819   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 2728   Recon Loss: 0.370956   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 2729   Recon Loss: 0.352858   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 2730   Recon Loss: 0.367971   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 2731   Recon Loss: 0.375947   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 2732   Recon Loss: 0.372618   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 2733   Recon Loss: 0.363727   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 2734   Recon Loss: 0.362427   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 2735   Recon Loss: 0.375490   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 2736   Recon Loss: 0.354689   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 2737   Recon Loss: 0.365908   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 2738   Recon Loss: 0.386473   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 2739   Recon Loss: 0.362534   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 2740   Recon Loss: 0.347069   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 2741   Recon Loss: 0.392011   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 2742   Recon Loss: 0.360961   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 2743   Recon Loss: 0.354185   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 2744   Recon Loss: 0.372192   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 2745   Recon Loss: 0.376147   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 2746   Recon Loss: 0.358774   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 2747   Recon Loss: 0.377027   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 2748   Recon Loss: 0.385508   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 2749   Recon Loss: 0.374526   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 2750   Recon Loss: 0.374929   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 2751   Recon Loss: 0.382437   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 2752   Recon Loss: 0.359402   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 2753   Recon Loss: 0.342882   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 2754   Recon Loss: 0.362106   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 2755   Recon Loss: 0.374431   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 2756   Recon Loss: 0.348382   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 2757   Recon Loss: 0.355993   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 2758   Recon Loss: 0.364231   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 2759   Recon Loss: 0.348914   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 2760   Recon Loss: 0.360187   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 2761   Recon Loss: 0.364190   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 2762   Recon Loss: 0.359734   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 2763   Recon Loss: 0.363311   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 2764   Recon Loss: 0.357948   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 2765   Recon Loss: 0.362021   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 2766   Recon Loss: 0.368065   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 2767   Recon Loss: 0.378588   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 2768   Recon Loss: 0.357962   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 2769   Recon Loss: 0.377696   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 2770   Recon Loss: 0.367861   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 2771   Recon Loss: 0.367548   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 2772   Recon Loss: 0.357206   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 2773   Recon Loss: 0.375910   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 2774   Recon Loss: 0.345188   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 2775   Recon Loss: 0.342748   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 2776   Recon Loss: 0.350414   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 2777   Recon Loss: 0.359712   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 2778   Recon Loss: 0.360356   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 2779   Recon Loss: 0.368915   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 2780   Recon Loss: 0.382727   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 2781   Recon Loss: 0.363049   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 2782   Recon Loss: 0.350082   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 2783   Recon Loss: 0.368975   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 2784   Recon Loss: 0.377307   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 2785   Recon Loss: 0.366212   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 2786   Recon Loss: 0.386927   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 2787   Recon Loss: 0.370109   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 2788   Recon Loss: 0.395785   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 2789   Recon Loss: 0.390449   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 2790   Recon Loss: 0.336144   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 2791   Recon Loss: 0.371160   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 2792   Recon Loss: 0.357068   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 2793   Recon Loss: 0.358459   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 2794   Recon Loss: 0.363402   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 2795   Recon Loss: 0.378854   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 2796   Recon Loss: 0.376796   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 2797   Recon Loss: 0.375068   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 2798   Recon Loss: 0.368608   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 2799   Recon Loss: 0.367645   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 2800   Recon Loss: 0.375825   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 2801   Recon Loss: 0.362497   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 2802   Recon Loss: 0.364837   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 2803   Recon Loss: 0.335275   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 2804   Recon Loss: 0.351734   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 2805   Recon Loss: 0.356854   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 2806   Recon Loss: 0.353513   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 2807   Recon Loss: 0.361483   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 2808   Recon Loss: 0.345314   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 2809   Recon Loss: 0.352844   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 2810   Recon Loss: 0.350523   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 2811   Recon Loss: 0.377304   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 2812   Recon Loss: 0.359546   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 2813   Recon Loss: 0.370485   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 2814   Recon Loss: 0.382367   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 2815   Recon Loss: 0.371509   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 2816   Recon Loss: 0.359791   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 2817   Recon Loss: 0.370783   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 2818   Recon Loss: 0.368630   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 2819   Recon Loss: 0.369867   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 2820   Recon Loss: 0.369573   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 2821   Recon Loss: 0.349905   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 2822   Recon Loss: 0.378583   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 2823   Recon Loss: 0.353543   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 2824   Recon Loss: 0.387592   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 2825   Recon Loss: 0.382504   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 2826   Recon Loss: 0.371059   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 2827   Recon Loss: 0.381457   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 2828   Recon Loss: 0.361291   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 2829   Recon Loss: 0.378965   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 2830   Recon Loss: 0.348191   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 2831   Recon Loss: 0.360558   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 2832   Recon Loss: 0.382685   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 2833   Recon Loss: 0.365037   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 2834   Recon Loss: 0.376794   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 2835   Recon Loss: 0.364492   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 2836   Recon Loss: 0.378440   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 2837   Recon Loss: 0.351829   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 2838   Recon Loss: 0.379159   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 2839   Recon Loss: 0.364991   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 2840   Recon Loss: 0.397055   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 2841   Recon Loss: 0.390758   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 2842   Recon Loss: 0.374627   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 2843   Recon Loss: 0.352908   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 2844   Recon Loss: 0.359615   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 2845   Recon Loss: 0.362463   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 2846   Recon Loss: 0.345107   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 2847   Recon Loss: 0.353415   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 2848   Recon Loss: 0.370334   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 2849   Recon Loss: 0.366268   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 2850   Recon Loss: 0.375406   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 2851   Recon Loss: 0.385970   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 2852   Recon Loss: 0.388050   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 2853   Recon Loss: 0.410786   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 2854   Recon Loss: 0.374597   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 2855   Recon Loss: 0.379414   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 2856   Recon Loss: 0.383585   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 2857   Recon Loss: 0.357436   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 2858   Recon Loss: 0.343362   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 2859   Recon Loss: 0.359919   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 2860   Recon Loss: 0.374570   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 2861   Recon Loss: 0.386132   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 2862   Recon Loss: 0.369015   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 2863   Recon Loss: 0.371361   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 2864   Recon Loss: 0.352782   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 2865   Recon Loss: 0.362746   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 2866   Recon Loss: 0.358606   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 2867   Recon Loss: 0.376965   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 2868   Recon Loss: 0.363802   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 2869   Recon Loss: 0.359029   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 2870   Recon Loss: 0.343825   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 2871   Recon Loss: 0.367236   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 2872   Recon Loss: 0.374602   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 2873   Recon Loss: 0.364005   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 2874   Recon Loss: 0.392395   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 2875   Recon Loss: 0.377700   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 2876   Recon Loss: 0.367613   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 2877   Recon Loss: 0.352569   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 2878   Recon Loss: 0.370299   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 2879   Recon Loss: 0.360916   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 2880   Recon Loss: 0.354892   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 2881   Recon Loss: 0.368727   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 2882   Recon Loss: 0.376436   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 2883   Recon Loss: 0.372420   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 2884   Recon Loss: 0.366565   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 2885   Recon Loss: 0.354884   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 2886   Recon Loss: 0.367681   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 2887   Recon Loss: 0.349485   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 2888   Recon Loss: 0.372297   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 2889   Recon Loss: 0.349347   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 2890   Recon Loss: 0.384476   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 2891   Recon Loss: 0.365352   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 2892   Recon Loss: 0.393853   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 2893   Recon Loss: 0.377102   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 2894   Recon Loss: 0.370414   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 2895   Recon Loss: 0.344510   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 2896   Recon Loss: 0.366179   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 2897   Recon Loss: 0.366813   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 2898   Recon Loss: 0.358726   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 2899   Recon Loss: 0.362816   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 2900   Recon Loss: 0.361129   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 2901   Recon Loss: 0.363753   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 2902   Recon Loss: 0.368712   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 2903   Recon Loss: 0.357315   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 2904   Recon Loss: 0.367973   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 2905   Recon Loss: 0.384170   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 2906   Recon Loss: 0.380633   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 2907   Recon Loss: 0.382094   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 2908   Recon Loss: 0.377101   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 2909   Recon Loss: 0.362970   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 2910   Recon Loss: 0.380525   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 2911   Recon Loss: 0.369636   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 2912   Recon Loss: 0.360870   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 2913   Recon Loss: 0.360684   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 2914   Recon Loss: 0.371922   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 2915   Recon Loss: 0.395788   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 2916   Recon Loss: 0.349010   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 2917   Recon Loss: 0.374312   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 2918   Recon Loss: 0.357796   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 2919   Recon Loss: 0.353227   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 2920   Recon Loss: 0.362885   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 2921   Recon Loss: 0.349688   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 2922   Recon Loss: 0.362101   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 2923   Recon Loss: 0.362869   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 2924   Recon Loss: 0.375087   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 2925   Recon Loss: 0.363814   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 2926   Recon Loss: 0.370120   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 2927   Recon Loss: 0.363050   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 2928   Recon Loss: 0.352184   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 2929   Recon Loss: 0.372176   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 2930   Recon Loss: 0.353179   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 2931   Recon Loss: 0.343292   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 2932   Recon Loss: 0.369298   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 2933   Recon Loss: 0.362486   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 2934   Recon Loss: 0.370462   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 2935   Recon Loss: 0.359996   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 2936   Recon Loss: 0.376295   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 2937   Recon Loss: 0.342463   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 2938   Recon Loss: 0.369331   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 2939   Recon Loss: 0.376606   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 2940   Recon Loss: 0.356347   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 2941   Recon Loss: 0.360409   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 2942   Recon Loss: 0.369320   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 2943   Recon Loss: 0.346827   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 2944   Recon Loss: 0.375758   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 2945   Recon Loss: 0.374227   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 2946   Recon Loss: 0.377707   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 2947   Recon Loss: 0.361265   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 2948   Recon Loss: 0.378259   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 2949   Recon Loss: 0.384450   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 2950   Recon Loss: 0.371454   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 2951   Recon Loss: 0.374417   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 2952   Recon Loss: 0.394229   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 2953   Recon Loss: 0.349491   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 2954   Recon Loss: 0.368797   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 2955   Recon Loss: 0.365699   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 2956   Recon Loss: 0.362798   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 2957   Recon Loss: 0.367413   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 2958   Recon Loss: 0.370000   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 2959   Recon Loss: 0.370036   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 2960   Recon Loss: 0.372848   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 2961   Recon Loss: 0.351374   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 2962   Recon Loss: 0.358792   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 2963   Recon Loss: 0.378009   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 2964   Recon Loss: 0.371845   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 2965   Recon Loss: 0.363953   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 2966   Recon Loss: 0.367982   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 2967   Recon Loss: 0.363014   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 2968   Recon Loss: 0.389920   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 2969   Recon Loss: 0.371216   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 2970   Recon Loss: 0.366708   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 2971   Recon Loss: 0.358729   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 2972   Recon Loss: 0.382364   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 2973   Recon Loss: 0.368390   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 2974   Recon Loss: 0.378369   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 2975   Recon Loss: 0.371920   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 2976   Recon Loss: 0.356723   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 2977   Recon Loss: 0.353137   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 2978   Recon Loss: 0.355021   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 2979   Recon Loss: 0.377241   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 2980   Recon Loss: 0.372152   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 2981   Recon Loss: 0.390616   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 2982   Recon Loss: 0.362588   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 2983   Recon Loss: 0.352115   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 2984   Recon Loss: 0.374548   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 2985   Recon Loss: 0.372083   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 2986   Recon Loss: 0.376583   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 2987   Recon Loss: 0.347739   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 2988   Recon Loss: 0.361010   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 2989   Recon Loss: 0.387364   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 2990   Recon Loss: 0.348185   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 2991   Recon Loss: 0.357210   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 2992   Recon Loss: 0.380166   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 2993   Recon Loss: 0.373642   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 2994   Recon Loss: 0.358929   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 2995   Recon Loss: 0.364407   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 2996   Recon Loss: 0.361058   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 2997   Recon Loss: 0.357462   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 2998   Recon Loss: 0.366785   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 2999   Recon Loss: 0.370889   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3000   Recon Loss: 0.385416   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3001   Recon Loss: 0.360153   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3002   Recon Loss: 0.355060   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3003   Recon Loss: 0.371337   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3004   Recon Loss: 0.369047   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3005   Recon Loss: 0.378016   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3006   Recon Loss: 0.365458   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3007   Recon Loss: 0.352709   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3008   Recon Loss: 0.376513   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3009   Recon Loss: 0.377391   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3010   Recon Loss: 0.344678   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3011   Recon Loss: 0.361854   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3012   Recon Loss: 0.360974   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3013   Recon Loss: 0.391736   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3014   Recon Loss: 0.350913   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3015   Recon Loss: 0.384910   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3016   Recon Loss: 0.367203   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3017   Recon Loss: 0.368778   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3018   Recon Loss: 0.364430   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3019   Recon Loss: 0.349339   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3020   Recon Loss: 0.375960   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3021   Recon Loss: 0.357408   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3022   Recon Loss: 0.361859   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3023   Recon Loss: 0.389290   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3024   Recon Loss: 0.368065   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3025   Recon Loss: 0.364756   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3026   Recon Loss: 0.369183   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3027   Recon Loss: 0.359613   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3028   Recon Loss: 0.397477   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3029   Recon Loss: 0.386296   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3030   Recon Loss: 0.376391   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3031   Recon Loss: 0.361811   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3032   Recon Loss: 0.373910   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3033   Recon Loss: 0.375609   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3034   Recon Loss: 0.362355   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3035   Recon Loss: 0.387888   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3036   Recon Loss: 0.363980   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3037   Recon Loss: 0.359525   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3038   Recon Loss: 0.368549   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3039   Recon Loss: 0.371825   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3040   Recon Loss: 0.360634   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3041   Recon Loss: 0.371737   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3042   Recon Loss: 0.362378   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3043   Recon Loss: 0.369596   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3044   Recon Loss: 0.374676   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3045   Recon Loss: 0.358301   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3046   Recon Loss: 0.362598   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3047   Recon Loss: 0.380781   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3048   Recon Loss: 0.367920   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3049   Recon Loss: 0.379964   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3050   Recon Loss: 0.382814   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3051   Recon Loss: 0.391713   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3052   Recon Loss: 0.372043   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3053   Recon Loss: 0.373794   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3054   Recon Loss: 0.361135   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3055   Recon Loss: 0.371745   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3056   Recon Loss: 0.373669   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3057   Recon Loss: 0.376604   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3058   Recon Loss: 0.370929   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3059   Recon Loss: 0.371333   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3060   Recon Loss: 0.359325   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3061   Recon Loss: 0.346907   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3062   Recon Loss: 0.382218   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3063   Recon Loss: 0.376421   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3064   Recon Loss: 0.346724   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3065   Recon Loss: 0.364958   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3066   Recon Loss: 0.370190   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3067   Recon Loss: 0.359023   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3068   Recon Loss: 0.384635   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3069   Recon Loss: 0.371548   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3070   Recon Loss: 0.367590   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3071   Recon Loss: 0.361981   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3072   Recon Loss: 0.364745   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3073   Recon Loss: 0.362403   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3074   Recon Loss: 0.367438   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3075   Recon Loss: 0.382465   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3076   Recon Loss: 0.366894   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3077   Recon Loss: 0.364211   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3078   Recon Loss: 0.372025   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3079   Recon Loss: 0.346496   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3080   Recon Loss: 0.372295   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3081   Recon Loss: 0.337536   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3082   Recon Loss: 0.342307   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3083   Recon Loss: 0.362047   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3084   Recon Loss: 0.351106   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3085   Recon Loss: 0.376153   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3086   Recon Loss: 0.355275   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3087   Recon Loss: 0.370470   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3088   Recon Loss: 0.359572   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3089   Recon Loss: 0.389385   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3090   Recon Loss: 0.359445   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3091   Recon Loss: 0.344207   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3092   Recon Loss: 0.359805   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3093   Recon Loss: 0.370141   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3094   Recon Loss: 0.345054   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3095   Recon Loss: 0.360155   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3096   Recon Loss: 0.340857   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3097   Recon Loss: 0.393567   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3098   Recon Loss: 0.363243   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3099   Recon Loss: 0.358856   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3100   Recon Loss: 0.363329   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3101   Recon Loss: 0.371261   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3102   Recon Loss: 0.385146   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3103   Recon Loss: 0.379089   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3104   Recon Loss: 0.365148   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3105   Recon Loss: 0.351401   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3106   Recon Loss: 0.378843   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3107   Recon Loss: 0.380738   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3108   Recon Loss: 0.368407   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3109   Recon Loss: 0.370830   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3110   Recon Loss: 0.370748   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3111   Recon Loss: 0.362877   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3112   Recon Loss: 0.355830   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3113   Recon Loss: 0.364535   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3114   Recon Loss: 0.357279   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3115   Recon Loss: 0.383160   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3116   Recon Loss: 0.359497   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3117   Recon Loss: 0.379365   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3118   Recon Loss: 0.372834   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3119   Recon Loss: 0.384333   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3120   Recon Loss: 0.379748   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3121   Recon Loss: 0.356918   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3122   Recon Loss: 0.384923   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3123   Recon Loss: 0.358754   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3124   Recon Loss: 0.375818   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3125   Recon Loss: 0.368595   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3126   Recon Loss: 0.370493   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3127   Recon Loss: 0.372065   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3128   Recon Loss: 0.354028   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3129   Recon Loss: 0.362659   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3130   Recon Loss: 0.360232   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3131   Recon Loss: 0.393457   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3132   Recon Loss: 0.375503   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3133   Recon Loss: 0.370959   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3134   Recon Loss: 0.373719   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3135   Recon Loss: 0.366211   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3136   Recon Loss: 0.395999   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3137   Recon Loss: 0.382233   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3138   Recon Loss: 0.372079   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3139   Recon Loss: 0.365274   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3140   Recon Loss: 0.376329   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3141   Recon Loss: 0.363794   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3142   Recon Loss: 0.380119   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3143   Recon Loss: 0.355565   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3144   Recon Loss: 0.380460   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3145   Recon Loss: 0.384075   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3146   Recon Loss: 0.360782   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3147   Recon Loss: 0.368247   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3148   Recon Loss: 0.366549   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3149   Recon Loss: 0.349873   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3150   Recon Loss: 0.374647   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3151   Recon Loss: 0.357093   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3152   Recon Loss: 0.362451   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3153   Recon Loss: 0.364724   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3154   Recon Loss: 0.371060   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3155   Recon Loss: 0.348883   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3156   Recon Loss: 0.354175   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3157   Recon Loss: 0.381453   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3158   Recon Loss: 0.355123   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3159   Recon Loss: 0.369134   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3160   Recon Loss: 0.375910   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3161   Recon Loss: 0.366836   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3162   Recon Loss: 0.376155   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3163   Recon Loss: 0.368429   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3164   Recon Loss: 0.377638   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3165   Recon Loss: 0.376301   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3166   Recon Loss: 0.371084   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3167   Recon Loss: 0.387851   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3168   Recon Loss: 0.353098   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3169   Recon Loss: 0.377859   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3170   Recon Loss: 0.371923   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3171   Recon Loss: 0.358619   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3172   Recon Loss: 0.375015   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3173   Recon Loss: 0.370753   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3174   Recon Loss: 0.377336   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3175   Recon Loss: 0.356042   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3176   Recon Loss: 0.362520   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3177   Recon Loss: 0.369609   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3178   Recon Loss: 0.370850   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3179   Recon Loss: 0.368076   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3180   Recon Loss: 0.356802   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3181   Recon Loss: 0.356742   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3182   Recon Loss: 0.378545   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3183   Recon Loss: 0.364620   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3184   Recon Loss: 0.369436   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3185   Recon Loss: 0.361883   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3186   Recon Loss: 0.386397   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3187   Recon Loss: 0.365947   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3188   Recon Loss: 0.363967   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3189   Recon Loss: 0.371210   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3190   Recon Loss: 0.376708   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3191   Recon Loss: 0.366391   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3192   Recon Loss: 0.383391   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3193   Recon Loss: 0.371948   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3194   Recon Loss: 0.348719   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3195   Recon Loss: 0.373270   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3196   Recon Loss: 0.359869   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3197   Recon Loss: 0.361926   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3198   Recon Loss: 0.389869   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3199   Recon Loss: 0.376381   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3200   Recon Loss: 0.370113   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3201   Recon Loss: 0.371000   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3202   Recon Loss: 0.360174   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3203   Recon Loss: 0.369663   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3204   Recon Loss: 0.371617   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3205   Recon Loss: 0.370012   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3206   Recon Loss: 0.369005   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3207   Recon Loss: 0.381669   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3208   Recon Loss: 0.361494   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3209   Recon Loss: 0.370817   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3210   Recon Loss: 0.356545   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3211   Recon Loss: 0.363269   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3212   Recon Loss: 0.355396   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3213   Recon Loss: 0.372086   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3214   Recon Loss: 0.365048   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3215   Recon Loss: 0.374930   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3216   Recon Loss: 0.375322   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3217   Recon Loss: 0.373968   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3218   Recon Loss: 0.363948   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3219   Recon Loss: 0.371428   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3220   Recon Loss: 0.348935   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3221   Recon Loss: 0.368606   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3222   Recon Loss: 0.345387   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3223   Recon Loss: 0.377564   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3224   Recon Loss: 0.366287   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3225   Recon Loss: 0.343031   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3226   Recon Loss: 0.356223   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3227   Recon Loss: 0.359793   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3228   Recon Loss: 0.371498   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3229   Recon Loss: 0.360553   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3230   Recon Loss: 0.391955   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3231   Recon Loss: 0.348620   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3232   Recon Loss: 0.380591   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3233   Recon Loss: 0.380992   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3234   Recon Loss: 0.382363   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3235   Recon Loss: 0.374800   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3236   Recon Loss: 0.360573   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3237   Recon Loss: 0.366729   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3238   Recon Loss: 0.362653   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3239   Recon Loss: 0.372652   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3240   Recon Loss: 0.366612   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3241   Recon Loss: 0.373100   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3242   Recon Loss: 0.396263   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3243   Recon Loss: 0.354564   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3244   Recon Loss: 0.371924   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3245   Recon Loss: 0.380115   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3246   Recon Loss: 0.375308   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3247   Recon Loss: 0.357277   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3248   Recon Loss: 0.347144   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3249   Recon Loss: 0.375295   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3250   Recon Loss: 0.368157   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3251   Recon Loss: 0.367176   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3252   Recon Loss: 0.361814   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3253   Recon Loss: 0.365839   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3254   Recon Loss: 0.375950   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3255   Recon Loss: 0.395855   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3256   Recon Loss: 0.359539   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3257   Recon Loss: 0.368829   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3258   Recon Loss: 0.380800   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3259   Recon Loss: 0.366285   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3260   Recon Loss: 0.370290   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3261   Recon Loss: 0.351662   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3262   Recon Loss: 0.363826   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3263   Recon Loss: 0.369056   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3264   Recon Loss: 0.366523   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3265   Recon Loss: 0.374464   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3266   Recon Loss: 0.379035   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3267   Recon Loss: 0.360141   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3268   Recon Loss: 0.373608   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3269   Recon Loss: 0.356839   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3270   Recon Loss: 0.366342   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3271   Recon Loss: 0.378919   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3272   Recon Loss: 0.368285   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3273   Recon Loss: 0.375371   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3274   Recon Loss: 0.371880   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3275   Recon Loss: 0.356667   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3276   Recon Loss: 0.388943   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3277   Recon Loss: 0.354886   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3278   Recon Loss: 0.351655   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3279   Recon Loss: 0.366434   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3280   Recon Loss: 0.366809   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3281   Recon Loss: 0.358259   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3282   Recon Loss: 0.367382   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3283   Recon Loss: 0.377864   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3284   Recon Loss: 0.371061   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3285   Recon Loss: 0.341026   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3286   Recon Loss: 0.365326   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3287   Recon Loss: 0.383470   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3288   Recon Loss: 0.364104   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3289   Recon Loss: 0.365226   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3290   Recon Loss: 0.366831   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3291   Recon Loss: 0.357579   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3292   Recon Loss: 0.353354   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3293   Recon Loss: 0.369327   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3294   Recon Loss: 0.372406   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3295   Recon Loss: 0.373390   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3296   Recon Loss: 0.366903   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3297   Recon Loss: 0.353387   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3298   Recon Loss: 0.363350   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3299   Recon Loss: 0.353949   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3300   Recon Loss: 0.363213   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3301   Recon Loss: 0.354903   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3302   Recon Loss: 0.365714   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3303   Recon Loss: 0.369343   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3304   Recon Loss: 0.370225   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3305   Recon Loss: 0.376314   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3306   Recon Loss: 0.363310   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3307   Recon Loss: 0.390246   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3308   Recon Loss: 0.348708   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3309   Recon Loss: 0.376991   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3310   Recon Loss: 0.369313   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3311   Recon Loss: 0.347610   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3312   Recon Loss: 0.371678   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3313   Recon Loss: 0.358846   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3314   Recon Loss: 0.374129   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3315   Recon Loss: 0.369292   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3316   Recon Loss: 0.366362   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3317   Recon Loss: 0.408018   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3318   Recon Loss: 0.363060   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3319   Recon Loss: 0.360048   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3320   Recon Loss: 0.354817   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3321   Recon Loss: 0.365239   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3322   Recon Loss: 0.380100   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3323   Recon Loss: 0.377829   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3324   Recon Loss: 0.369396   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3325   Recon Loss: 0.356807   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3326   Recon Loss: 0.375335   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3327   Recon Loss: 0.375226   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3328   Recon Loss: 0.385757   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3329   Recon Loss: 0.360533   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3330   Recon Loss: 0.363622   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3331   Recon Loss: 0.369834   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3332   Recon Loss: 0.369729   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3333   Recon Loss: 0.359479   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3334   Recon Loss: 0.352364   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3335   Recon Loss: 0.373748   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3336   Recon Loss: 0.365663   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3337   Recon Loss: 0.376329   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3338   Recon Loss: 0.373023   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3339   Recon Loss: 0.372043   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3340   Recon Loss: 0.388068   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3341   Recon Loss: 0.356960   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3342   Recon Loss: 0.365168   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3343   Recon Loss: 0.360481   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3344   Recon Loss: 0.380445   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3345   Recon Loss: 0.375516   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3346   Recon Loss: 0.367743   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3347   Recon Loss: 0.339612   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3348   Recon Loss: 0.362966   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3349   Recon Loss: 0.367661   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3350   Recon Loss: 0.356880   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3351   Recon Loss: 0.366740   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3352   Recon Loss: 0.384113   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3353   Recon Loss: 0.359699   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3354   Recon Loss: 0.359164   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3355   Recon Loss: 0.352254   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3356   Recon Loss: 0.347632   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3357   Recon Loss: 0.344090   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3358   Recon Loss: 0.361068   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3359   Recon Loss: 0.357093   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3360   Recon Loss: 0.360030   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3361   Recon Loss: 0.351005   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3362   Recon Loss: 0.361002   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3363   Recon Loss: 0.387241   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3364   Recon Loss: 0.361778   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3365   Recon Loss: 0.357513   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3366   Recon Loss: 0.379094   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3367   Recon Loss: 0.380473   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3368   Recon Loss: 0.370658   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3369   Recon Loss: 0.384707   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3370   Recon Loss: 0.365255   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3371   Recon Loss: 0.375770   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3372   Recon Loss: 0.385204   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3373   Recon Loss: 0.351893   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3374   Recon Loss: 0.385235   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3375   Recon Loss: 0.370402   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3376   Recon Loss: 0.390336   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3377   Recon Loss: 0.402776   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3378   Recon Loss: 0.358124   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3379   Recon Loss: 0.390447   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3380   Recon Loss: 0.365656   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3381   Recon Loss: 0.360483   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3382   Recon Loss: 0.378637   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3383   Recon Loss: 0.374108   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3384   Recon Loss: 0.379491   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3385   Recon Loss: 0.358639   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3386   Recon Loss: 0.361884   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3387   Recon Loss: 0.365046   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3388   Recon Loss: 0.351712   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3389   Recon Loss: 0.391396   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3390   Recon Loss: 0.365039   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3391   Recon Loss: 0.361870   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3392   Recon Loss: 0.373636   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3393   Recon Loss: 0.370556   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3394   Recon Loss: 0.362384   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3395   Recon Loss: 0.365490   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3396   Recon Loss: 0.369515   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3397   Recon Loss: 0.366236   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3398   Recon Loss: 0.380624   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3399   Recon Loss: 0.375632   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3400   Recon Loss: 0.377912   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3401   Recon Loss: 0.353109   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3402   Recon Loss: 0.366195   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3403   Recon Loss: 0.374241   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3404   Recon Loss: 0.385063   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3405   Recon Loss: 0.342890   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3406   Recon Loss: 0.363795   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3407   Recon Loss: 0.382793   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3408   Recon Loss: 0.359219   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3409   Recon Loss: 0.377226   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3410   Recon Loss: 0.365143   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3411   Recon Loss: 0.374577   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3412   Recon Loss: 0.369516   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3413   Recon Loss: 0.363782   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3414   Recon Loss: 0.373883   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3415   Recon Loss: 0.367687   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3416   Recon Loss: 0.375612   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3417   Recon Loss: 0.370184   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3418   Recon Loss: 0.374313   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3419   Recon Loss: 0.370617   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3420   Recon Loss: 0.386751   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3421   Recon Loss: 0.375341   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3422   Recon Loss: 0.360965   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3423   Recon Loss: 0.358602   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3424   Recon Loss: 0.362704   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3425   Recon Loss: 0.375243   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3426   Recon Loss: 0.356866   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3427   Recon Loss: 0.368266   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3428   Recon Loss: 0.379046   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3429   Recon Loss: 0.385429   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3430   Recon Loss: 0.369757   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3431   Recon Loss: 0.367883   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3432   Recon Loss: 0.359540   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3433   Recon Loss: 0.358232   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3434   Recon Loss: 0.377823   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3435   Recon Loss: 0.361771   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3436   Recon Loss: 0.349476   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3437   Recon Loss: 0.360461   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3438   Recon Loss: 0.368588   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3439   Recon Loss: 0.382381   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3440   Recon Loss: 0.349287   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3441   Recon Loss: 0.370884   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3442   Recon Loss: 0.388555   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3443   Recon Loss: 0.368043   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3444   Recon Loss: 0.366754   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3445   Recon Loss: 0.389126   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3446   Recon Loss: 0.383581   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3447   Recon Loss: 0.380146   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3448   Recon Loss: 0.388703   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3449   Recon Loss: 0.368905   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3450   Recon Loss: 0.365559   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3451   Recon Loss: 0.355373   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3452   Recon Loss: 0.372966   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3453   Recon Loss: 0.368427   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3454   Recon Loss: 0.376967   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3455   Recon Loss: 0.363291   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3456   Recon Loss: 0.357172   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3457   Recon Loss: 0.358890   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3458   Recon Loss: 0.362147   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3459   Recon Loss: 0.382244   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3460   Recon Loss: 0.374548   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3461   Recon Loss: 0.355257   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3462   Recon Loss: 0.361180   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3463   Recon Loss: 0.335530   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3464   Recon Loss: 0.369697   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3465   Recon Loss: 0.380244   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3466   Recon Loss: 0.360765   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3467   Recon Loss: 0.382765   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3468   Recon Loss: 0.362079   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3469   Recon Loss: 0.374422   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3470   Recon Loss: 0.360703   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3471   Recon Loss: 0.362315   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3472   Recon Loss: 0.354431   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3473   Recon Loss: 0.382437   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3474   Recon Loss: 0.365569   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3475   Recon Loss: 0.368996   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3476   Recon Loss: 0.370010   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3477   Recon Loss: 0.354992   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3478   Recon Loss: 0.380844   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3479   Recon Loss: 0.358363   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3480   Recon Loss: 0.397434   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3481   Recon Loss: 0.367636   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3482   Recon Loss: 0.375400   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3483   Recon Loss: 0.369897   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3484   Recon Loss: 0.372374   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3485   Recon Loss: 0.362361   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3486   Recon Loss: 0.376327   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3487   Recon Loss: 0.375849   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3488   Recon Loss: 0.365865   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3489   Recon Loss: 0.367989   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3490   Recon Loss: 0.346965   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3491   Recon Loss: 0.348126   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3492   Recon Loss: 0.370741   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3493   Recon Loss: 0.342645   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3494   Recon Loss: 0.385183   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3495   Recon Loss: 0.361004   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3496   Recon Loss: 0.365368   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3497   Recon Loss: 0.378189   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3498   Recon Loss: 0.365808   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3499   Recon Loss: 0.370727   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3500   Recon Loss: 0.355719   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3501   Recon Loss: 0.379125   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3502   Recon Loss: 0.366023   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3503   Recon Loss: 0.350220   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3504   Recon Loss: 0.375045   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3505   Recon Loss: 0.383928   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3506   Recon Loss: 0.366262   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3507   Recon Loss: 0.364460   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3508   Recon Loss: 0.370242   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3509   Recon Loss: 0.366211   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3510   Recon Loss: 0.371403   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3511   Recon Loss: 0.388421   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3512   Recon Loss: 0.363185   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3513   Recon Loss: 0.375034   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3514   Recon Loss: 0.376436   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3515   Recon Loss: 0.378000   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3516   Recon Loss: 0.353343   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3517   Recon Loss: 0.349322   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3518   Recon Loss: 0.352071   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3519   Recon Loss: 0.371943   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3520   Recon Loss: 0.366369   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3521   Recon Loss: 0.363396   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3522   Recon Loss: 0.354311   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3523   Recon Loss: 0.356585   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3524   Recon Loss: 0.374781   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3525   Recon Loss: 0.355760   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3526   Recon Loss: 0.382151   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3527   Recon Loss: 0.354172   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3528   Recon Loss: 0.362022   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3529   Recon Loss: 0.393907   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3530   Recon Loss: 0.362480   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3531   Recon Loss: 0.376604   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3532   Recon Loss: 0.363877   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3533   Recon Loss: 0.381791   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3534   Recon Loss: 0.378495   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3535   Recon Loss: 0.345128   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3536   Recon Loss: 0.363226   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3537   Recon Loss: 0.357315   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3538   Recon Loss: 0.379810   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3539   Recon Loss: 0.369876   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3540   Recon Loss: 0.360863   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3541   Recon Loss: 0.349416   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3542   Recon Loss: 0.359099   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3543   Recon Loss: 0.356405   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3544   Recon Loss: 0.350149   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3545   Recon Loss: 0.372439   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3546   Recon Loss: 0.352081   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3547   Recon Loss: 0.375371   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3548   Recon Loss: 0.361449   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3549   Recon Loss: 0.373100   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3550   Recon Loss: 0.368180   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3551   Recon Loss: 0.368119   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3552   Recon Loss: 0.373073   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3553   Recon Loss: 0.359665   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3554   Recon Loss: 0.387520   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3555   Recon Loss: 0.368432   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3556   Recon Loss: 0.336217   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3557   Recon Loss: 0.365521   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3558   Recon Loss: 0.342810   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3559   Recon Loss: 0.376848   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3560   Recon Loss: 0.376945   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3561   Recon Loss: 0.360014   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3562   Recon Loss: 0.361786   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3563   Recon Loss: 0.378557   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3564   Recon Loss: 0.356639   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3565   Recon Loss: 0.374192   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3566   Recon Loss: 0.388999   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3567   Recon Loss: 0.360120   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3568   Recon Loss: 0.378706   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3569   Recon Loss: 0.354854   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3570   Recon Loss: 0.370573   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3571   Recon Loss: 0.365317   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3572   Recon Loss: 0.363945   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3573   Recon Loss: 0.371103   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3574   Recon Loss: 0.338658   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3575   Recon Loss: 0.393615   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3576   Recon Loss: 0.357579   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3577   Recon Loss: 0.374779   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3578   Recon Loss: 0.375129   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3579   Recon Loss: 0.383369   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3580   Recon Loss: 0.388271   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3581   Recon Loss: 0.367142   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3582   Recon Loss: 0.381349   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3583   Recon Loss: 0.364351   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3584   Recon Loss: 0.373225   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3585   Recon Loss: 0.344535   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3586   Recon Loss: 0.369451   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3587   Recon Loss: 0.379598   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3588   Recon Loss: 0.364614   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3589   Recon Loss: 0.372803   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3590   Recon Loss: 0.375715   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3591   Recon Loss: 0.351525   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3592   Recon Loss: 0.351606   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3593   Recon Loss: 0.372336   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3594   Recon Loss: 0.370926   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3595   Recon Loss: 0.356259   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3596   Recon Loss: 0.377058   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3597   Recon Loss: 0.356355   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3598   Recon Loss: 0.371891   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3599   Recon Loss: 0.360854   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3600   Recon Loss: 0.378088   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3601   Recon Loss: 0.357237   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3602   Recon Loss: 0.365105   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3603   Recon Loss: 0.357072   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3604   Recon Loss: 0.363749   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3605   Recon Loss: 0.363250   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3606   Recon Loss: 0.367657   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3607   Recon Loss: 0.363483   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3608   Recon Loss: 0.372633   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3609   Recon Loss: 0.367435   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3610   Recon Loss: 0.357597   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3611   Recon Loss: 0.366610   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3612   Recon Loss: 0.362658   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3613   Recon Loss: 0.342711   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3614   Recon Loss: 0.332160   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3615   Recon Loss: 0.397969   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3616   Recon Loss: 0.375115   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3617   Recon Loss: 0.381420   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3618   Recon Loss: 0.374409   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3619   Recon Loss: 0.361113   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3620   Recon Loss: 0.386047   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3621   Recon Loss: 0.375544   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3622   Recon Loss: 0.368766   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3623   Recon Loss: 0.374678   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3624   Recon Loss: 0.371149   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3625   Recon Loss: 0.364454   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3626   Recon Loss: 0.371584   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3627   Recon Loss: 0.373699   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3628   Recon Loss: 0.357681   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3629   Recon Loss: 0.364940   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3630   Recon Loss: 0.373528   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3631   Recon Loss: 0.382873   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3632   Recon Loss: 0.360312   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3633   Recon Loss: 0.360858   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3634   Recon Loss: 0.344035   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3635   Recon Loss: 0.346146   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3636   Recon Loss: 0.375448   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3637   Recon Loss: 0.363662   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3638   Recon Loss: 0.356380   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3639   Recon Loss: 0.372892   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3640   Recon Loss: 0.360933   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3641   Recon Loss: 0.393914   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3642   Recon Loss: 0.366619   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3643   Recon Loss: 0.373635   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3644   Recon Loss: 0.369844   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3645   Recon Loss: 0.375421   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3646   Recon Loss: 0.363003   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3647   Recon Loss: 0.363287   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3648   Recon Loss: 0.369072   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3649   Recon Loss: 0.377073   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3650   Recon Loss: 0.357780   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3651   Recon Loss: 0.377768   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3652   Recon Loss: 0.373440   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3653   Recon Loss: 0.366382   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3654   Recon Loss: 0.393828   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3655   Recon Loss: 0.382328   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3656   Recon Loss: 0.361554   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3657   Recon Loss: 0.364997   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3658   Recon Loss: 0.360585   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3659   Recon Loss: 0.378501   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3660   Recon Loss: 0.383906   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3661   Recon Loss: 0.352514   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3662   Recon Loss: 0.346582   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3663   Recon Loss: 0.364479   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3664   Recon Loss: 0.355081   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3665   Recon Loss: 0.354780   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3666   Recon Loss: 0.368576   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3667   Recon Loss: 0.375346   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3668   Recon Loss: 0.349427   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3669   Recon Loss: 0.357705   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3670   Recon Loss: 0.356894   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3671   Recon Loss: 0.351847   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3672   Recon Loss: 0.364440   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3673   Recon Loss: 0.371579   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3674   Recon Loss: 0.376794   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3675   Recon Loss: 0.360679   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3676   Recon Loss: 0.368684   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3677   Recon Loss: 0.374881   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3678   Recon Loss: 0.357751   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3679   Recon Loss: 0.352805   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3680   Recon Loss: 0.367361   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3681   Recon Loss: 0.373211   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3682   Recon Loss: 0.368184   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3683   Recon Loss: 0.365084   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3684   Recon Loss: 0.376752   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3685   Recon Loss: 0.369082   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3686   Recon Loss: 0.369357   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3687   Recon Loss: 0.381274   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3688   Recon Loss: 0.389196   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3689   Recon Loss: 0.354957   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3690   Recon Loss: 0.352629   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3691   Recon Loss: 0.373062   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3692   Recon Loss: 0.368256   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3693   Recon Loss: 0.357919   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3694   Recon Loss: 0.363857   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3695   Recon Loss: 0.347804   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3696   Recon Loss: 0.371082   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3697   Recon Loss: 0.391775   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3698   Recon Loss: 0.342477   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3699   Recon Loss: 0.361671   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3700   Recon Loss: 0.351617   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3701   Recon Loss: 0.401172   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3702   Recon Loss: 0.380165   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3703   Recon Loss: 0.373360   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3704   Recon Loss: 0.368540   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3705   Recon Loss: 0.368832   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3706   Recon Loss: 0.361865   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3707   Recon Loss: 0.356980   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3708   Recon Loss: 0.356255   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3709   Recon Loss: 0.358968   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3710   Recon Loss: 0.369311   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3711   Recon Loss: 0.373975   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3712   Recon Loss: 0.355351   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3713   Recon Loss: 0.351783   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3714   Recon Loss: 0.369772   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3715   Recon Loss: 0.355967   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3716   Recon Loss: 0.379157   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3717   Recon Loss: 0.367080   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3718   Recon Loss: 0.367497   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3719   Recon Loss: 0.388387   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3720   Recon Loss: 0.360859   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3721   Recon Loss: 0.372808   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3722   Recon Loss: 0.359249   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3723   Recon Loss: 0.336776   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3724   Recon Loss: 0.360273   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3725   Recon Loss: 0.361690   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3726   Recon Loss: 0.362996   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3727   Recon Loss: 0.348941   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3728   Recon Loss: 0.375378   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3729   Recon Loss: 0.360298   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3730   Recon Loss: 0.354544   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3731   Recon Loss: 0.362650   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3732   Recon Loss: 0.373047   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3733   Recon Loss: 0.368591   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3734   Recon Loss: 0.365377   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3735   Recon Loss: 0.347093   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3736   Recon Loss: 0.358103   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3737   Recon Loss: 0.365495   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3738   Recon Loss: 0.364776   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3739   Recon Loss: 0.356572   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3740   Recon Loss: 0.374967   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3741   Recon Loss: 0.360647   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3742   Recon Loss: 0.365740   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3743   Recon Loss: 0.367753   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3744   Recon Loss: 0.358130   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3745   Recon Loss: 0.368898   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3746   Recon Loss: 0.360447   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3747   Recon Loss: 0.342467   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3748   Recon Loss: 0.374048   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3749   Recon Loss: 0.352039   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3750   Recon Loss: 0.356220   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3751   Recon Loss: 0.364177   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3752   Recon Loss: 0.379066   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3753   Recon Loss: 0.361415   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3754   Recon Loss: 0.350670   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3755   Recon Loss: 0.350070   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3756   Recon Loss: 0.379059   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3757   Recon Loss: 0.359423   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3758   Recon Loss: 0.383590   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3759   Recon Loss: 0.377222   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3760   Recon Loss: 0.349283   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3761   Recon Loss: 0.378883   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3762   Recon Loss: 0.366154   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3763   Recon Loss: 0.374414   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3764   Recon Loss: 0.356181   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3765   Recon Loss: 0.380587   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3766   Recon Loss: 0.356580   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3767   Recon Loss: 0.384458   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3768   Recon Loss: 0.356476   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3769   Recon Loss: 0.364612   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3770   Recon Loss: 0.363823   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3771   Recon Loss: 0.385281   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3772   Recon Loss: 0.360998   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3773   Recon Loss: 0.370794   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3774   Recon Loss: 0.385922   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3775   Recon Loss: 0.361417   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3776   Recon Loss: 0.365835   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3777   Recon Loss: 0.376104   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3778   Recon Loss: 0.354488   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3779   Recon Loss: 0.362504   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3780   Recon Loss: 0.368013   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3781   Recon Loss: 0.362543   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3782   Recon Loss: 0.377950   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3783   Recon Loss: 0.378345   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3784   Recon Loss: 0.389912   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3785   Recon Loss: 0.357989   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3786   Recon Loss: 0.340487   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3787   Recon Loss: 0.388479   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3788   Recon Loss: 0.368565   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3789   Recon Loss: 0.374483   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3790   Recon Loss: 0.373604   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3791   Recon Loss: 0.377796   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3792   Recon Loss: 0.364538   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3793   Recon Loss: 0.358333   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3794   Recon Loss: 0.340668   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3795   Recon Loss: 0.378404   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3796   Recon Loss: 0.381548   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3797   Recon Loss: 0.376008   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3798   Recon Loss: 0.367041   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3799   Recon Loss: 0.361435   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3800   Recon Loss: 0.363109   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3801   Recon Loss: 0.362554   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3802   Recon Loss: 0.367398   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3803   Recon Loss: 0.368906   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3804   Recon Loss: 0.361670   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3805   Recon Loss: 0.377556   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3806   Recon Loss: 0.367966   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3807   Recon Loss: 0.367221   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3808   Recon Loss: 0.362057   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3809   Recon Loss: 0.361356   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3810   Recon Loss: 0.369787   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3811   Recon Loss: 0.356468   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3812   Recon Loss: 0.349232   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3813   Recon Loss: 0.361197   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3814   Recon Loss: 0.371672   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3815   Recon Loss: 0.382643   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3816   Recon Loss: 0.355269   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3817   Recon Loss: 0.376699   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3818   Recon Loss: 0.359243   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3819   Recon Loss: 0.380887   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3820   Recon Loss: 0.357624   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3821   Recon Loss: 0.389871   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3822   Recon Loss: 0.361114   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3823   Recon Loss: 0.343003   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3824   Recon Loss: 0.372497   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3825   Recon Loss: 0.357221   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3826   Recon Loss: 0.380055   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3827   Recon Loss: 0.341088   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3828   Recon Loss: 0.385068   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3829   Recon Loss: 0.381535   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3830   Recon Loss: 0.361951   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3831   Recon Loss: 0.363379   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3832   Recon Loss: 0.393674   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3833   Recon Loss: 0.353403   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3834   Recon Loss: 0.363254   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3835   Recon Loss: 0.384613   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3836   Recon Loss: 0.362712   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3837   Recon Loss: 0.370758   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3838   Recon Loss: 0.372432   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3839   Recon Loss: 0.351767   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3840   Recon Loss: 0.359532   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3841   Recon Loss: 0.354891   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3842   Recon Loss: 0.343700   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3843   Recon Loss: 0.372359   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3844   Recon Loss: 0.367586   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3845   Recon Loss: 0.377627   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3846   Recon Loss: 0.357463   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3847   Recon Loss: 0.341426   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3848   Recon Loss: 0.352112   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3849   Recon Loss: 0.366208   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3850   Recon Loss: 0.372783   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3851   Recon Loss: 0.386128   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3852   Recon Loss: 0.371230   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3853   Recon Loss: 0.367880   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3854   Recon Loss: 0.346361   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3855   Recon Loss: 0.370175   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3856   Recon Loss: 0.343616   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3857   Recon Loss: 0.387991   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3858   Recon Loss: 0.376532   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3859   Recon Loss: 0.381754   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3860   Recon Loss: 0.385142   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3861   Recon Loss: 0.378791   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3862   Recon Loss: 0.370050   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3863   Recon Loss: 0.386035   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3864   Recon Loss: 0.365296   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3865   Recon Loss: 0.366935   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3866   Recon Loss: 0.361361   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3867   Recon Loss: 0.361205   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3868   Recon Loss: 0.365906   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3869   Recon Loss: 0.370104   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3870   Recon Loss: 0.368893   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3871   Recon Loss: 0.398774   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3872   Recon Loss: 0.371609   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3873   Recon Loss: 0.368175   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3874   Recon Loss: 0.366646   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3875   Recon Loss: 0.371909   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3876   Recon Loss: 0.364647   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3877   Recon Loss: 0.361062   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3878   Recon Loss: 0.382068   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3879   Recon Loss: 0.382977   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3880   Recon Loss: 0.365221   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3881   Recon Loss: 0.354995   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3882   Recon Loss: 0.352779   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3883   Recon Loss: 0.367200   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3884   Recon Loss: 0.376091   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3885   Recon Loss: 0.351747   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3886   Recon Loss: 0.352518   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3887   Recon Loss: 0.364932   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3888   Recon Loss: 0.374843   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3889   Recon Loss: 0.365058   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3890   Recon Loss: 0.368162   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3891   Recon Loss: 0.390568   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3892   Recon Loss: 0.384543   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3893   Recon Loss: 0.371444   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3894   Recon Loss: 0.356593   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3895   Recon Loss: 0.352458   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3896   Recon Loss: 0.381573   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3897   Recon Loss: 0.381122   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3898   Recon Loss: 0.369752   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3899   Recon Loss: 0.382552   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3900   Recon Loss: 0.369562   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3901   Recon Loss: 0.371383   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3902   Recon Loss: 0.379225   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3903   Recon Loss: 0.369205   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3904   Recon Loss: 0.367021   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3905   Recon Loss: 0.350071   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3906   Recon Loss: 0.347611   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3907   Recon Loss: 0.357108   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3908   Recon Loss: 0.359958   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3909   Recon Loss: 0.363150   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3910   Recon Loss: 0.366256   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3911   Recon Loss: 0.360358   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3912   Recon Loss: 0.374703   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3913   Recon Loss: 0.369931   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3914   Recon Loss: 0.384220   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3915   Recon Loss: 0.344384   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3916   Recon Loss: 0.368200   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3917   Recon Loss: 0.358168   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3918   Recon Loss: 0.380805   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3919   Recon Loss: 0.366818   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3920   Recon Loss: 0.377852   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3921   Recon Loss: 0.372897   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3922   Recon Loss: 0.361564   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3923   Recon Loss: 0.378134   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3924   Recon Loss: 0.372693   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3925   Recon Loss: 0.388271   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3926   Recon Loss: 0.368030   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3927   Recon Loss: 0.377212   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3928   Recon Loss: 0.358610   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3929   Recon Loss: 0.356411   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3930   Recon Loss: 0.352499   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3931   Recon Loss: 0.343910   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3932   Recon Loss: 0.355467   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3933   Recon Loss: 0.374815   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3934   Recon Loss: 0.354579   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3935   Recon Loss: 0.364182   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3936   Recon Loss: 0.362521   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3937   Recon Loss: 0.370065   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3938   Recon Loss: 0.348199   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3939   Recon Loss: 0.387578   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3940   Recon Loss: 0.359277   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3941   Recon Loss: 0.373358   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3942   Recon Loss: 0.352809   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3943   Recon Loss: 0.382978   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3944   Recon Loss: 0.367243   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3945   Recon Loss: 0.377500   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3946   Recon Loss: 0.373420   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3947   Recon Loss: 0.353688   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3948   Recon Loss: 0.353088   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3949   Recon Loss: 0.356815   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3950   Recon Loss: 0.353690   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3951   Recon Loss: 0.350974   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3952   Recon Loss: 0.364322   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3953   Recon Loss: 0.373522   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3954   Recon Loss: 0.359302   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3955   Recon Loss: 0.355570   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3956   Recon Loss: 0.368321   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3957   Recon Loss: 0.354687   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3958   Recon Loss: 0.361266   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3959   Recon Loss: 0.356218   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3960   Recon Loss: 0.367166   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3961   Recon Loss: 0.350290   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3962   Recon Loss: 0.373076   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3963   Recon Loss: 0.377710   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3964   Recon Loss: 0.365983   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3965   Recon Loss: 0.344159   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3966   Recon Loss: 0.370046   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3967   Recon Loss: 0.351353   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3968   Recon Loss: 0.388482   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3969   Recon Loss: 0.362456   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3970   Recon Loss: 0.377947   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3971   Recon Loss: 0.361800   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3972   Recon Loss: 0.364384   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3973   Recon Loss: 0.370714   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3974   Recon Loss: 0.353797   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3975   Recon Loss: 0.365606   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3976   Recon Loss: 0.362941   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3977   Recon Loss: 0.343707   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3978   Recon Loss: 0.366967   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3979   Recon Loss: 0.370107   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3980   Recon Loss: 0.373787   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3981   Recon Loss: 0.379722   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3982   Recon Loss: 0.362775   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3983   Recon Loss: 0.378242   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3984   Recon Loss: 0.351820   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3985   Recon Loss: 0.365362   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3986   Recon Loss: 0.383414   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3987   Recon Loss: 0.375226   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3988   Recon Loss: 0.364576   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3989   Recon Loss: 0.350495   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3990   Recon Loss: 0.365879   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3991   Recon Loss: 0.376634   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3992   Recon Loss: 0.355028   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3993   Recon Loss: 0.369348   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3994   Recon Loss: 0.369124   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3995   Recon Loss: 0.361036   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3996   Recon Loss: 0.353199   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3997   Recon Loss: 0.353849   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3998   Recon Loss: 0.359400   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3999   Recon Loss: 0.367957   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Inference and Save: Unseen Set**"
      ],
      "metadata": {
        "id": "XKLK9fOVqNZ8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data_unseen_test = scipy.io.loadmat('/content/fsl-rsvae/datasets/AWA1/unseen_test.mat')\n",
        "data_unseen_test = data_unseen_test['feature']\n",
        "#data_train = np.transpose(data_train)\n",
        "\n",
        "# labels\n",
        "label_unseen_test = scipy.io.loadmat('/content/fsl-rsvae/datasets/AWA1/unseen_test_label.mat')\n",
        "label_unseen_test = label_unseen_test['label'][0]\n",
        "\n",
        "# attr\n",
        "unseen_attr = scipy.io.loadmat('/content/fsl-rsvae/datasets/AWA1/unseen_attribute.mat')\n",
        "unseen_attr = unseen_attr['unseen_attribute']\n",
        "\n",
        "#/content/fsl-rsvae/datasets/AWA1/unseen_attribute.mat"
      ],
      "metadata": {
        "id": "vWAa8HEplB2t"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "feature_un_dataset = FeatureDataset(data_unseen_test, label_unseen_test, unseen_attr)\n",
        "feature_un_loader = torch.utils.data.DataLoader(feature_dataset, shuffle=False, drop_last=False, batch_size=len(feature_un_dataset))  # len(feature_un_dataset)"
      ],
      "metadata": {
        "id": "jLAB7R1SqVqE"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_feats_with_noise(feats_vae, unseen_attr, samples_per_class=1000):\n",
        "    feats_vae.eval()\n",
        "    #feats_vae.to()\n",
        "    feats_vae.to(torch.device('cuda:0'))\n",
        "    #z_dist = normal.Normal(0, 1)\n",
        "    ground_truths = list(range(len(unseen_attr)))*samples_per_class\n",
        "    uns_atr = torch.from_numpy(np.array(unseen_attr)[ground_truths]).float().cuda() #to(torch.float32)\n",
        "    #attr = torch.from_numpy(attributes[label])\n",
        "    #attr = attr.repeat(ind_count, 1)\n",
        "\n",
        "    z_dist = normal.Normal(0, 1)\n",
        "    Z = z_dist.sample((samples_per_class*len(unseen_attr), 2048)).cuda()\n",
        "\n",
        "    mu, logvar, recon_feats = feats_vae(Z, uns_atr)\n",
        "    return ground_truths, recon_feats\n",
        "\n",
        "noise_gt, noise_feats = generate_feats_with_noise(feats_vae, attr)\n",
        "print(noise_feats.size())\n",
        "print(np.shape(noise_gt))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DU5ajTXEoE1i",
        "outputId": "cd24c36f-3d71-41c5-ec62-1be9f57b7627"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([40000, 2048])\n",
            "(40000,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "noise_feats"
      ],
      "metadata": {
        "id": "oVsFbrZMiCfy",
        "outputId": "0a2d51f4-acf8-403d-974c-aeaf4c3272f8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.1858129 , 1.6406716 , 0.6522571 , ..., 1.224933  , 0.04374265,\n",
              "        0.39283264],\n",
              "       [0.33058685, 0.8143091 , 0.84430003, ..., 0.68605655, 0.13983248,\n",
              "        0.3412093 ],\n",
              "       [0.21474569, 1.06694   , 0.76023734, ..., 0.6030567 , 0.29699108,\n",
              "        0.77962095],\n",
              "       ...,\n",
              "       [0.39806136, 0.33526358, 0.15155566, ..., 1.1911689 , 0.6312113 ,\n",
              "        0.17611521],\n",
              "       [0.222603  , 0.46811646, 1.158093  , ..., 0.43099707, 0.25155744,\n",
              "        0.480331  ],\n",
              "       [0.2061714 , 0.89824796, 0.23591685, ..., 1.7950795 , 0.22500364,\n",
              "        0.48830694]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "noise_feats = noise_feats.cpu().detach().numpy()\n",
        "noise_gt = np.array(noise_gt)\n",
        "recon_noise = {\"reconstructed_noise\" : noise_feats, \"labels\" : noise_gt}\n",
        "scipy.io.savemat(\"reconstructed_noise.mat\", recon_noise)"
      ],
      "metadata": {
        "id": "hMkp_2J03TAG"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#feature_loader = torch.utils.data.DataLoader(feature_dataset, shuffle=True, pin_memory=True, drop_last=False, batch_size=len(feature_un_dataset))\n",
        "\n",
        "def generate_feats_with_image(feats_vae, data, labels, attrib):\n",
        "    feats_vae.eval()\n",
        "    #feats_vae.to()\n",
        "    feats_vae.to(torch.device('cuda:0'))\n",
        "    ground_truths = labels\n",
        "    #print(torch.from_numpy(np.array((attr)[label])).to(torch.float32)\n",
        "    #uns_atr = torch.from_numpy(np.array(attr)[label]).to(torch.float32)\n",
        "    attrib = torch.from_numpy(np.array((attrib)[labels])).to(torch.float32).cuda()\n",
        "    #print(uns_atr.shape)\n",
        "    #print(data.shape)\n",
        "    #print(uns_atr.shape)\n",
        "    data = torch.from_numpy(data).cuda()\n",
        "    mu, logvar, recon_feats = feats_vae(data, attrib)\n",
        "    #print(recon_feats.shape)\n",
        "    #ground_truths = ground_truths.cpu().detach().numpy()\n",
        "    recon_feats = recon_feats.cpu().detach().numpy()\n",
        "\n",
        "    return ground_truths, recon_feats\n",
        "\n",
        "image_gt, image_feats = generate_feats_with_image(feats_vae, data_train, data_train_label, attr)\n",
        "print(image_feats.shape)\n",
        "print(image_gt.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fNd_6dzVqsmH",
        "outputId": "20a096c4-e38f-4fc6-d5ab-35d552902f4f"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(19832, 2048)\n",
            "(19832,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "recon_image = {\"reconstructed_image\" : image_feats, \"labels\" : image_gt}\n",
        "scipy.io.savemat(\"reconstructed_image.mat\", recon_image)"
      ],
      "metadata": {
        "id": "wjkGgelx5UrV"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "all_gt = len(np.concatenate([data_train_label, noise_gt, image_gt]))\n",
        "all_feats = len(np.concatenate([data_train, noise_feats, image_feats]))"
      ],
      "metadata": {
        "id": "m0gRhfSpjoo2"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "recon_all = {\"reconstructed_feats_all\" : all_feats, \"labels\" : all_gt}\n",
        "scipy.io.savemat(\"reconstructed_all.mat\", recon_image)"
      ],
      "metadata": {
        "id": "1U6ZPLTclK-r"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!cp /content/reconstructed_noise.mat /content/gdrive/MyDrive/generated_data"
      ],
      "metadata": {
        "id": "8yopX_sE68P8"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!cp /content/reconstructed_image.mat /content/gdrive/MyDrive/generated_data"
      ],
      "metadata": {
        "id": "9qFR09JF8alF"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!cp /content/reconstructed_all.mat /content/gdrive/MyDrive/generated_data"
      ],
      "metadata": {
        "id": "NHxcw62PSINk"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "tPAQ37yGmDN1"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}