{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPK2rGcvDpEmA+Q2HrVbAEq",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ShadmanRohan/fsl-rsvae/blob/main/Basic_Feat_Gen.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Preliminaries**"
      ],
      "metadata": {
        "id": "0F1r6VXg0fZO"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9Fkr40LMo7uc",
        "outputId": "55fd6ae9-245d-4856-ba9d-0d2ba086749c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'fsl-rsvae'...\n",
            "remote: Enumerating objects: 433, done.\u001b[K\n",
            "remote: Counting objects: 100% (433/433), done.\u001b[K\n",
            "remote: Compressing objects: 100% (237/237), done.\u001b[K\n",
            "remote: Total 433 (delta 213), reused 402 (delta 195), pack-reused 0\u001b[K\n",
            "Receiving objects: 100% (433/433), 457.79 KiB | 19.90 MiB/s, done.\n",
            "Resolving deltas: 100% (213/213), done.\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/ShadmanRohan/fsl-rsvae.git"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4ktupjgODfja",
        "outputId": "7ebeb1c9-22f8-4969-fc9b-6f541a91e92c"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/gdrive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from distutils.dir_util import copy_tree\n",
        "copy_tree(\"/content/gdrive/MyDrive/PAMI/AWA1_AWA2_SUN/data/AWA1\", \"/content/fsl-rsvae/datasets/AWA1\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IEef9zeLD52b",
        "outputId": "27ef0cab-a370-46b4-d485-86e1602870cc"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['/content/fsl-rsvae/datasets/AWA1/seen_test.mat',\n",
              " '/content/fsl-rsvae/datasets/AWA1/seen_attribute.mat',\n",
              " '/content/fsl-rsvae/datasets/AWA1/seen_test_label.mat',\n",
              " '/content/fsl-rsvae/datasets/AWA1/seen_train.mat',\n",
              " '/content/fsl-rsvae/datasets/AWA1/unseen_attribute.mat',\n",
              " '/content/fsl-rsvae/datasets/AWA1/seen_train_label.mat',\n",
              " '/content/fsl-rsvae/datasets/AWA1/unseen_test.mat',\n",
              " '/content/fsl-rsvae/datasets/AWA1/unseen_test_label.mat']"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import argparse\n",
        "import numpy as np\n",
        "from torch.autograd import Variable\n",
        "#from torchvision.datasets.folder import DatasetFolder\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torch.distributions import uniform, normal\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from matplotlib import pyplot as plt\n",
        "import torch.optim\n",
        "import json\n",
        "import torch.utils.data.sampler\n",
        "import os\n",
        "import glob\n",
        "import random\n",
        "import time\n",
        "import pdb\n",
        "import yaml\n",
        "#import datasets.feature_loader as feat_loader\n",
        "from sklearn.manifold import TSNE\n",
        "import h5py\n",
        "from scipy.stats import multivariate_normal\n",
        "import scipy"
      ],
      "metadata": {
        "id": "k8kzzG1xpNSE"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Dataloader**"
      ],
      "metadata": {
        "id": "ALmNYwLE0koN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import scipy.io\n",
        "#features\n",
        "data_train = scipy.io.loadmat('/content/fsl-rsvae/datasets/AWA1/seen_train.mat')\n",
        "data_train = data_train['feature']\n",
        "#data_train = np.transpose(data_train)\n",
        "\n",
        "\n",
        "# labels\n",
        "label_train = scipy.io.loadmat('/content/fsl-rsvae/datasets/AWA1/seen_train_label.mat')\n",
        "data_train_label = label_train['label'][0]\n",
        "\n",
        "\n",
        "# attr\n",
        "tmp = scipy.io.loadmat('/content/fsl-rsvae/datasets/AWA1/seen_attribute.mat')\n",
        "attr = tmp['seen_attribute']\n",
        "#attr = np.transpose(attr)"
      ],
      "metadata": {
        "id": "KWmLvTptFmf9"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class FeatureDataset(Dataset):\n",
        "\n",
        "    def __init__(self, features, labels, attr):\n",
        "        self.labels = labels\n",
        "        self.features = features\n",
        "        self.attr = attr\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(data_train)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        return self.features[idx], self.labels[idx]\n",
        "\n",
        "feature_dataset = FeatureDataset(data_train, data_train_label, attr)\n",
        "feature_loader = torch.utils.data.DataLoader(feature_dataset, shuffle=True, pin_memory=True, drop_last=False, batch_size=256) "
      ],
      "metadata": {
        "id": "OiH7f_bqFb3i"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Model**"
      ],
      "metadata": {
        "id": "foS4BJaI0poO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class FeatsVAE(nn.Module):\n",
        "    def __init__(self, x_dim, latent_dim, bottle_neck):\n",
        "        super(FeatsVAE, self).__init__()\n",
        "\n",
        "        self.x_dim = x_dim\n",
        "        self.latent_dim = latent_dim\n",
        "        self.bn1 = nn.BatchNorm1d(x_dim)\n",
        "        self.relu = nn.ReLU(inplace=True)\n",
        "        self.z_dist = normal.Normal(0, 1)\n",
        "        self.init_weights()\n",
        "\n",
        "        self.encoder = nn.Sequential(\n",
        "            nn.Linear(self.x_dim+self.latent_dim, 1096),\n",
        "            nn.LeakyReLU(),\n",
        "            nn.Linear(1096, bottle_neck),\n",
        "            nn.LeakyReLU())\n",
        "        \n",
        "        self.linear_mu =  nn.Sequential(\n",
        "            nn.Linear(bottle_neck, latent_dim),\n",
        "            nn.ReLU())\n",
        "        self.linear_logvar =  nn.Sequential(\n",
        "            nn.Linear(bottle_neck, latent_dim),\n",
        "            nn.ReLU())\n",
        "        \n",
        "        self.decoder = nn.Sequential(\n",
        "            nn.Linear(2*latent_dim, 512),  # 170\n",
        "            nn.LeakyReLU(),\n",
        "            nn.Linear(512, 1024),\n",
        "            nn.LeakyReLU(),\n",
        "            nn.Linear(1024, x_dim),  #2048\n",
        "            #nn.Sigmoid(),\n",
        "            nn.LeakyReLU(),\n",
        "        )\n",
        "        \n",
        "\n",
        "\n",
        "\n",
        "    def reparameterize(self, mu, logvar):\n",
        "        std = torch.exp(0.5*logvar)  \n",
        "        eps = torch.randn_like(std)\n",
        "        # remove abnormal points\n",
        "        return mu + eps*std\n",
        "\n",
        "    def init_weights(self):\n",
        "        for m in self.modules():\n",
        "          if isinstance(m, nn.Linear):\n",
        "              m.weight.data.normal_(0, 0.02)\n",
        "              m.bias.data.normal_(0, 0.02)\n",
        "\n",
        "    def forward(self, x, attr):\n",
        "        #print(x.size())\n",
        "        #print(attr.size())\n",
        "\n",
        "        x = torch.cat((x, attr), dim=1).to(torch.float32)   # 2048+85\n",
        "        #print(x.size())\n",
        "        #print(self.x_dim+self.latent_dim)\n",
        "        \n",
        "        x = self.encoder(x)    # 2048+85 -> 8\n",
        "        #print(x.size())\n",
        "        mu = self.linear_mu(x) # 8 -> 85\n",
        "        #print(x)\n",
        "        logvar = self.linear_logvar(x)  # 8 -> 85\n",
        "        #print(logvar)\n",
        "        latent_feats = self.reparameterize(mu, logvar)  # 85 (sample)\n",
        "        #Z = self.z_dist.sample(attr.shape).cuda() \n",
        "        concat_feats = torch.cat((latent_feats, attr), dim=1)  # 85+85 (predecoding concat)\n",
        "\n",
        "        recon_feats = self.decoder(concat_feats)  #85*2 -> 8\n",
        "        #recon_feats = self.relu(self.bn1(recon_feats))\n",
        "        recon_feats = self.relu(recon_feats)\n",
        "        return mu, logvar, recon_feats\n",
        "\n",
        "feats_vae = FeatsVAE(x_dim=2048, latent_dim=85, bottle_neck=128) # latent dim = attribute dim"
      ],
      "metadata": {
        "id": "QR8I-FHnK1gq"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Train**"
      ],
      "metadata": {
        "id": "M7OEf2vy0thp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def train_vae(feature_loader, feats_vae, attributes):\n",
        "    optimizer = torch.optim.Adam(feats_vae.parameters(), lr=0.001)\n",
        "    feats_vae.train()\n",
        "    feats_vae.cuda()\n",
        "    #for ep in range(1000):\n",
        "    for ep in range(4000):\n",
        "      loss_recon_all = 0\n",
        "      loss_kl_all = 0\n",
        "      for idx, (data, label) in enumerate(feature_loader):\n",
        "        print(\"training loop...\")\n",
        "        data = data\n",
        "        \n",
        "        #weight = weight.cuda() / torch.sum(weight)\n",
        "        attr = torch.from_numpy(attributes[label]).float().cuda()\n",
        "        data = data.cuda()\n",
        "        #print(attr.device)\n",
        "        #print(data.device)\n",
        "        mu, logvar, recon_feats = feats_vae(data, attr)\n",
        "        recon_loss = ((recon_feats - data)**2).mean(1)\n",
        "        recon_loss = torch.mean(recon_loss)\n",
        "        #kl_loss = -0.5*torch.sum(1+logvar-logvar.exp()-mu.pow(2)) / data.shape[0]\n",
        "        kl_loss = (1+logvar-logvar.exp()-mu.pow(2)).sum(1)\n",
        "        kl_loss = -0.5*torch.mean(kl_loss)\n",
        "        L_vae = recon_loss+kl_loss\n",
        "        optimizer.zero_grad()\n",
        "        L_vae.backward()   \n",
        "        optimizer.step()\n",
        "        loss_recon_all += recon_loss.item()\n",
        "        loss_kl_all += kl_loss.item()\n",
        "        break\n",
        "      print('Ep: %d   Recon Loss: %f   KL Loss: %f'%(ep, loss_recon_all/(idx+1), loss_kl_all/(idx+1)))\n",
        "      print(recon_feats.shape)\n",
        "    return feats_vae\n",
        "    #torch.save({'state': feats_vae.state_dict()}, 'feats_vae_mini.pth') \n",
        "\n",
        "feats_vae = train_vae(feature_loader, feats_vae, attr)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JN9RRAsJNhzB",
        "outputId": "d54cab99-468b-4bec-e53c-d2de823e6f9b"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1;30;43mStreaming output truncated to the last 5000 lines.\u001b[0m\n",
            "Ep: 2333   Recon Loss: 0.374802   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 2334   Recon Loss: 0.368234   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 2335   Recon Loss: 0.365991   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 2336   Recon Loss: 0.356757   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 2337   Recon Loss: 0.365357   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 2338   Recon Loss: 0.367599   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 2339   Recon Loss: 0.353729   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 2340   Recon Loss: 0.352685   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 2341   Recon Loss: 0.386200   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 2342   Recon Loss: 0.352259   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 2343   Recon Loss: 0.375430   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 2344   Recon Loss: 0.367397   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 2345   Recon Loss: 0.373077   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 2346   Recon Loss: 0.356749   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 2347   Recon Loss: 0.377985   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 2348   Recon Loss: 0.366196   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 2349   Recon Loss: 0.355605   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 2350   Recon Loss: 0.376159   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 2351   Recon Loss: 0.374884   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 2352   Recon Loss: 0.362335   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 2353   Recon Loss: 0.364191   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 2354   Recon Loss: 0.354790   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 2355   Recon Loss: 0.364206   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 2356   Recon Loss: 0.375328   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 2357   Recon Loss: 0.370484   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 2358   Recon Loss: 0.374363   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 2359   Recon Loss: 0.383992   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 2360   Recon Loss: 0.372801   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 2361   Recon Loss: 0.362355   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 2362   Recon Loss: 0.382705   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 2363   Recon Loss: 0.366914   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 2364   Recon Loss: 0.371170   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 2365   Recon Loss: 0.368986   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 2366   Recon Loss: 0.390527   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 2367   Recon Loss: 0.365099   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 2368   Recon Loss: 0.373452   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 2369   Recon Loss: 0.353967   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 2370   Recon Loss: 0.368878   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 2371   Recon Loss: 0.388347   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 2372   Recon Loss: 0.373975   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 2373   Recon Loss: 0.372419   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 2374   Recon Loss: 0.377758   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 2375   Recon Loss: 0.355325   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 2376   Recon Loss: 0.360835   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 2377   Recon Loss: 0.360348   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 2378   Recon Loss: 0.362881   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 2379   Recon Loss: 0.378682   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 2380   Recon Loss: 0.356633   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 2381   Recon Loss: 0.362390   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 2382   Recon Loss: 0.372657   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 2383   Recon Loss: 0.352511   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 2384   Recon Loss: 0.373117   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 2385   Recon Loss: 0.354604   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 2386   Recon Loss: 0.380598   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 2387   Recon Loss: 0.362800   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 2388   Recon Loss: 0.347497   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 2389   Recon Loss: 0.368241   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 2390   Recon Loss: 0.350573   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 2391   Recon Loss: 0.364572   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 2392   Recon Loss: 0.374921   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 2393   Recon Loss: 0.353130   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 2394   Recon Loss: 0.358088   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 2395   Recon Loss: 0.376182   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 2396   Recon Loss: 0.367021   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 2397   Recon Loss: 0.374900   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 2398   Recon Loss: 0.378349   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 2399   Recon Loss: 0.343855   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 2400   Recon Loss: 0.391134   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 2401   Recon Loss: 0.362267   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 2402   Recon Loss: 0.359466   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 2403   Recon Loss: 0.357504   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 2404   Recon Loss: 0.361218   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 2405   Recon Loss: 0.357862   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 2406   Recon Loss: 0.346854   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 2407   Recon Loss: 0.376685   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 2408   Recon Loss: 0.359519   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 2409   Recon Loss: 0.356264   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 2410   Recon Loss: 0.350528   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 2411   Recon Loss: 0.363842   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 2412   Recon Loss: 0.372288   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 2413   Recon Loss: 0.362856   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 2414   Recon Loss: 0.365096   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 2415   Recon Loss: 0.351043   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 2416   Recon Loss: 0.380813   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 2417   Recon Loss: 0.345059   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 2418   Recon Loss: 0.378173   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 2419   Recon Loss: 0.369117   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 2420   Recon Loss: 0.360827   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 2421   Recon Loss: 0.367445   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 2422   Recon Loss: 0.365977   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 2423   Recon Loss: 0.342876   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 2424   Recon Loss: 0.361396   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 2425   Recon Loss: 0.368995   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 2426   Recon Loss: 0.375261   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 2427   Recon Loss: 0.393198   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 2428   Recon Loss: 0.355000   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 2429   Recon Loss: 0.359558   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 2430   Recon Loss: 0.368102   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 2431   Recon Loss: 0.359682   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 2432   Recon Loss: 0.348322   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 2433   Recon Loss: 0.357215   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 2434   Recon Loss: 0.375714   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 2435   Recon Loss: 0.376518   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 2436   Recon Loss: 0.354773   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 2437   Recon Loss: 0.353789   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 2438   Recon Loss: 0.378409   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 2439   Recon Loss: 0.366467   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 2440   Recon Loss: 0.375417   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 2441   Recon Loss: 0.369917   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 2442   Recon Loss: 0.375897   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 2443   Recon Loss: 0.359501   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 2444   Recon Loss: 0.363857   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 2445   Recon Loss: 0.362964   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 2446   Recon Loss: 0.353728   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 2447   Recon Loss: 0.350312   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 2448   Recon Loss: 0.357485   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 2449   Recon Loss: 0.362316   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 2450   Recon Loss: 0.376857   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 2451   Recon Loss: 0.364848   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 2452   Recon Loss: 0.374017   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 2453   Recon Loss: 0.363621   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 2454   Recon Loss: 0.373686   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 2455   Recon Loss: 0.363648   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 2456   Recon Loss: 0.347580   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 2457   Recon Loss: 0.364360   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 2458   Recon Loss: 0.348442   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 2459   Recon Loss: 0.366150   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 2460   Recon Loss: 0.366764   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 2461   Recon Loss: 0.366377   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 2462   Recon Loss: 0.380339   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 2463   Recon Loss: 0.372054   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 2464   Recon Loss: 0.358887   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 2465   Recon Loss: 0.366184   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 2466   Recon Loss: 0.357305   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 2467   Recon Loss: 0.373487   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 2468   Recon Loss: 0.361864   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 2469   Recon Loss: 0.364743   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 2470   Recon Loss: 0.365934   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 2471   Recon Loss: 0.351348   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 2472   Recon Loss: 0.365017   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 2473   Recon Loss: 0.380272   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 2474   Recon Loss: 0.353840   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 2475   Recon Loss: 0.369539   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 2476   Recon Loss: 0.380180   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 2477   Recon Loss: 0.355176   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 2478   Recon Loss: 0.360760   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 2479   Recon Loss: 0.365820   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 2480   Recon Loss: 0.368544   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 2481   Recon Loss: 0.356316   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 2482   Recon Loss: 0.367806   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 2483   Recon Loss: 0.368138   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 2484   Recon Loss: 0.367924   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 2485   Recon Loss: 0.386517   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 2486   Recon Loss: 0.350818   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 2487   Recon Loss: 0.362799   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 2488   Recon Loss: 0.377084   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 2489   Recon Loss: 0.364472   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 2490   Recon Loss: 0.370066   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 2491   Recon Loss: 0.373057   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 2492   Recon Loss: 0.367100   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 2493   Recon Loss: 0.366371   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 2494   Recon Loss: 0.343429   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 2495   Recon Loss: 0.353006   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 2496   Recon Loss: 0.354291   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 2497   Recon Loss: 0.364329   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 2498   Recon Loss: 0.361288   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 2499   Recon Loss: 0.356881   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 2500   Recon Loss: 0.370291   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 2501   Recon Loss: 0.352099   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 2502   Recon Loss: 0.367704   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 2503   Recon Loss: 0.371839   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 2504   Recon Loss: 0.374234   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 2505   Recon Loss: 0.384501   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 2506   Recon Loss: 0.366762   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 2507   Recon Loss: 0.368267   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 2508   Recon Loss: 0.371066   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 2509   Recon Loss: 0.362822   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 2510   Recon Loss: 0.371560   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 2511   Recon Loss: 0.385146   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 2512   Recon Loss: 0.351448   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 2513   Recon Loss: 0.378066   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 2514   Recon Loss: 0.371900   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 2515   Recon Loss: 0.375986   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 2516   Recon Loss: 0.377262   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 2517   Recon Loss: 0.371083   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 2518   Recon Loss: 0.380104   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 2519   Recon Loss: 0.381209   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 2520   Recon Loss: 0.372958   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 2521   Recon Loss: 0.387387   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 2522   Recon Loss: 0.366759   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 2523   Recon Loss: 0.367172   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 2524   Recon Loss: 0.364665   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 2525   Recon Loss: 0.346145   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 2526   Recon Loss: 0.355977   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 2527   Recon Loss: 0.349294   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 2528   Recon Loss: 0.355017   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 2529   Recon Loss: 0.381082   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 2530   Recon Loss: 0.363634   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 2531   Recon Loss: 0.356544   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 2532   Recon Loss: 0.363560   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 2533   Recon Loss: 0.377103   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 2534   Recon Loss: 0.363538   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 2535   Recon Loss: 0.364022   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 2536   Recon Loss: 0.361378   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 2537   Recon Loss: 0.365263   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 2538   Recon Loss: 0.377891   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 2539   Recon Loss: 0.364517   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 2540   Recon Loss: 0.360338   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 2541   Recon Loss: 0.351112   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 2542   Recon Loss: 0.360064   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 2543   Recon Loss: 0.373380   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 2544   Recon Loss: 0.365542   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 2545   Recon Loss: 0.345486   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 2546   Recon Loss: 0.377310   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 2547   Recon Loss: 0.370331   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 2548   Recon Loss: 0.351570   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 2549   Recon Loss: 0.371358   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 2550   Recon Loss: 0.371268   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 2551   Recon Loss: 0.364358   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 2552   Recon Loss: 0.372376   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 2553   Recon Loss: 0.354371   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 2554   Recon Loss: 0.371872   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 2555   Recon Loss: 0.387239   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 2556   Recon Loss: 0.364307   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 2557   Recon Loss: 0.364141   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 2558   Recon Loss: 0.375818   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 2559   Recon Loss: 0.347441   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 2560   Recon Loss: 0.370107   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 2561   Recon Loss: 0.372200   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 2562   Recon Loss: 0.357597   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 2563   Recon Loss: 0.388383   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 2564   Recon Loss: 0.392019   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 2565   Recon Loss: 0.367200   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 2566   Recon Loss: 0.359942   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 2567   Recon Loss: 0.367097   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 2568   Recon Loss: 0.351684   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 2569   Recon Loss: 0.387966   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 2570   Recon Loss: 0.375200   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 2571   Recon Loss: 0.356646   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 2572   Recon Loss: 0.380534   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 2573   Recon Loss: 0.383976   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 2574   Recon Loss: 0.389254   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 2575   Recon Loss: 0.372425   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 2576   Recon Loss: 0.375016   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 2577   Recon Loss: 0.364217   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 2578   Recon Loss: 0.381404   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 2579   Recon Loss: 0.376715   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 2580   Recon Loss: 0.352176   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 2581   Recon Loss: 0.357698   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 2582   Recon Loss: 0.362823   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 2583   Recon Loss: 0.380370   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 2584   Recon Loss: 0.355850   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 2585   Recon Loss: 0.366849   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 2586   Recon Loss: 0.359885   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 2587   Recon Loss: 0.368050   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 2588   Recon Loss: 0.366898   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 2589   Recon Loss: 0.372478   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 2590   Recon Loss: 0.364982   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 2591   Recon Loss: 0.377077   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 2592   Recon Loss: 0.360547   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 2593   Recon Loss: 0.354842   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 2594   Recon Loss: 0.363781   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 2595   Recon Loss: 0.362182   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 2596   Recon Loss: 0.363898   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 2597   Recon Loss: 0.358593   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 2598   Recon Loss: 0.395642   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 2599   Recon Loss: 0.337384   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 2600   Recon Loss: 0.363580   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 2601   Recon Loss: 0.359988   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 2602   Recon Loss: 0.382695   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 2603   Recon Loss: 0.349765   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 2604   Recon Loss: 0.357132   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 2605   Recon Loss: 0.379039   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 2606   Recon Loss: 0.349794   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 2607   Recon Loss: 0.362476   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 2608   Recon Loss: 0.381196   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 2609   Recon Loss: 0.363692   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 2610   Recon Loss: 0.384689   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 2611   Recon Loss: 0.381180   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 2612   Recon Loss: 0.337007   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 2613   Recon Loss: 0.373665   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 2614   Recon Loss: 0.361528   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 2615   Recon Loss: 0.372400   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 2616   Recon Loss: 0.375914   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 2617   Recon Loss: 0.367126   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 2618   Recon Loss: 0.358960   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 2619   Recon Loss: 0.342084   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 2620   Recon Loss: 0.370518   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 2621   Recon Loss: 0.380051   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 2622   Recon Loss: 0.375357   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 2623   Recon Loss: 0.382934   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 2624   Recon Loss: 0.365505   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 2625   Recon Loss: 0.366410   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 2626   Recon Loss: 0.368760   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 2627   Recon Loss: 0.361514   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 2628   Recon Loss: 0.360273   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 2629   Recon Loss: 0.351812   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 2630   Recon Loss: 0.371987   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 2631   Recon Loss: 0.371429   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 2632   Recon Loss: 0.380387   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 2633   Recon Loss: 0.374013   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 2634   Recon Loss: 0.355050   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 2635   Recon Loss: 0.368260   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 2636   Recon Loss: 0.393394   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 2637   Recon Loss: 0.354469   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 2638   Recon Loss: 0.361442   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 2639   Recon Loss: 0.394000   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 2640   Recon Loss: 0.364967   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 2641   Recon Loss: 0.367541   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 2642   Recon Loss: 0.351579   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 2643   Recon Loss: 0.371084   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 2644   Recon Loss: 0.370969   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 2645   Recon Loss: 0.357380   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 2646   Recon Loss: 0.363403   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 2647   Recon Loss: 0.375152   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 2648   Recon Loss: 0.378599   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 2649   Recon Loss: 0.364396   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 2650   Recon Loss: 0.388236   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 2651   Recon Loss: 0.348559   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 2652   Recon Loss: 0.366367   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 2653   Recon Loss: 0.353888   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 2654   Recon Loss: 0.354612   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 2655   Recon Loss: 0.354179   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 2656   Recon Loss: 0.353532   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 2657   Recon Loss: 0.356112   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 2658   Recon Loss: 0.365408   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 2659   Recon Loss: 0.360739   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 2660   Recon Loss: 0.370202   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 2661   Recon Loss: 0.371065   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 2662   Recon Loss: 0.353599   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 2663   Recon Loss: 0.360155   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 2664   Recon Loss: 0.368262   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 2665   Recon Loss: 0.342557   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 2666   Recon Loss: 0.361767   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 2667   Recon Loss: 0.385485   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 2668   Recon Loss: 0.367054   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 2669   Recon Loss: 0.380159   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 2670   Recon Loss: 0.362078   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 2671   Recon Loss: 0.358895   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 2672   Recon Loss: 0.361104   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 2673   Recon Loss: 0.379438   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 2674   Recon Loss: 0.355732   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 2675   Recon Loss: 0.362706   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 2676   Recon Loss: 0.379311   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 2677   Recon Loss: 0.363905   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 2678   Recon Loss: 0.369829   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 2679   Recon Loss: 0.359249   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 2680   Recon Loss: 0.369396   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 2681   Recon Loss: 0.357748   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 2682   Recon Loss: 0.375822   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 2683   Recon Loss: 0.357957   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 2684   Recon Loss: 0.360952   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 2685   Recon Loss: 0.364097   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 2686   Recon Loss: 0.352390   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 2687   Recon Loss: 0.382810   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 2688   Recon Loss: 0.367325   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 2689   Recon Loss: 0.392470   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 2690   Recon Loss: 0.365382   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 2691   Recon Loss: 0.362470   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 2692   Recon Loss: 0.374063   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 2693   Recon Loss: 0.350090   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 2694   Recon Loss: 0.358589   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 2695   Recon Loss: 0.358320   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 2696   Recon Loss: 0.355840   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 2697   Recon Loss: 0.360899   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 2698   Recon Loss: 0.345242   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 2699   Recon Loss: 0.349745   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 2700   Recon Loss: 0.405634   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 2701   Recon Loss: 0.348387   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 2702   Recon Loss: 0.380123   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 2703   Recon Loss: 0.374074   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 2704   Recon Loss: 0.377359   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 2705   Recon Loss: 0.359210   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 2706   Recon Loss: 0.382210   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 2707   Recon Loss: 0.343432   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 2708   Recon Loss: 0.363595   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 2709   Recon Loss: 0.354090   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 2710   Recon Loss: 0.373164   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 2711   Recon Loss: 0.361135   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 2712   Recon Loss: 0.362036   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 2713   Recon Loss: 0.350098   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 2714   Recon Loss: 0.368700   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 2715   Recon Loss: 0.377860   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 2716   Recon Loss: 0.353183   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 2717   Recon Loss: 0.382516   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 2718   Recon Loss: 0.366731   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 2719   Recon Loss: 0.370173   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 2720   Recon Loss: 0.345304   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 2721   Recon Loss: 0.371457   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 2722   Recon Loss: 0.349680   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 2723   Recon Loss: 0.403664   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 2724   Recon Loss: 0.373019   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 2725   Recon Loss: 0.366633   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 2726   Recon Loss: 0.369320   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 2727   Recon Loss: 0.379310   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 2728   Recon Loss: 0.358902   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 2729   Recon Loss: 0.378534   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 2730   Recon Loss: 0.377049   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 2731   Recon Loss: 0.392721   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 2732   Recon Loss: 0.373551   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 2733   Recon Loss: 0.354824   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 2734   Recon Loss: 0.351406   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 2735   Recon Loss: 0.369990   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 2736   Recon Loss: 0.370403   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 2737   Recon Loss: 0.382492   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 2738   Recon Loss: 0.343895   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 2739   Recon Loss: 0.372470   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 2740   Recon Loss: 0.377238   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 2741   Recon Loss: 0.391732   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 2742   Recon Loss: 0.374925   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 2743   Recon Loss: 0.361473   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 2744   Recon Loss: 0.379918   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 2745   Recon Loss: 0.358154   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 2746   Recon Loss: 0.352125   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 2747   Recon Loss: 0.368197   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 2748   Recon Loss: 0.375411   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 2749   Recon Loss: 0.358945   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 2750   Recon Loss: 0.358486   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 2751   Recon Loss: 0.388985   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 2752   Recon Loss: 0.371377   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 2753   Recon Loss: 0.383800   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 2754   Recon Loss: 0.374032   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 2755   Recon Loss: 0.359666   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 2756   Recon Loss: 0.351288   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 2757   Recon Loss: 0.363081   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 2758   Recon Loss: 0.384904   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 2759   Recon Loss: 0.369955   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 2760   Recon Loss: 0.380039   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 2761   Recon Loss: 0.385016   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 2762   Recon Loss: 0.358716   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 2763   Recon Loss: 0.382004   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 2764   Recon Loss: 0.370411   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 2765   Recon Loss: 0.384872   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 2766   Recon Loss: 0.369589   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 2767   Recon Loss: 0.363366   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 2768   Recon Loss: 0.380462   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 2769   Recon Loss: 0.363607   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 2770   Recon Loss: 0.356341   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 2771   Recon Loss: 0.367658   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 2772   Recon Loss: 0.365051   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 2773   Recon Loss: 0.358027   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 2774   Recon Loss: 0.356392   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 2775   Recon Loss: 0.387108   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 2776   Recon Loss: 0.383576   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 2777   Recon Loss: 0.382433   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 2778   Recon Loss: 0.359073   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 2779   Recon Loss: 0.363503   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 2780   Recon Loss: 0.349045   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 2781   Recon Loss: 0.361626   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 2782   Recon Loss: 0.379542   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 2783   Recon Loss: 0.371774   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 2784   Recon Loss: 0.364209   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 2785   Recon Loss: 0.353672   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 2786   Recon Loss: 0.380822   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 2787   Recon Loss: 0.356345   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 2788   Recon Loss: 0.350835   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 2789   Recon Loss: 0.365575   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 2790   Recon Loss: 0.368173   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 2791   Recon Loss: 0.367429   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 2792   Recon Loss: 0.377727   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 2793   Recon Loss: 0.387034   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 2794   Recon Loss: 0.361570   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 2795   Recon Loss: 0.357320   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 2796   Recon Loss: 0.366574   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 2797   Recon Loss: 0.368408   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 2798   Recon Loss: 0.365838   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 2799   Recon Loss: 0.355129   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 2800   Recon Loss: 0.373131   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 2801   Recon Loss: 0.370193   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 2802   Recon Loss: 0.335702   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 2803   Recon Loss: 0.363254   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 2804   Recon Loss: 0.379347   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 2805   Recon Loss: 0.358375   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 2806   Recon Loss: 0.345611   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 2807   Recon Loss: 0.369439   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 2808   Recon Loss: 0.355415   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 2809   Recon Loss: 0.358738   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 2810   Recon Loss: 0.345302   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 2811   Recon Loss: 0.370195   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 2812   Recon Loss: 0.355762   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 2813   Recon Loss: 0.355995   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 2814   Recon Loss: 0.384653   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 2815   Recon Loss: 0.368064   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 2816   Recon Loss: 0.350178   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 2817   Recon Loss: 0.347819   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 2818   Recon Loss: 0.383413   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 2819   Recon Loss: 0.334844   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 2820   Recon Loss: 0.356002   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 2821   Recon Loss: 0.359842   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 2822   Recon Loss: 0.367294   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 2823   Recon Loss: 0.377881   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 2824   Recon Loss: 0.370931   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 2825   Recon Loss: 0.342823   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 2826   Recon Loss: 0.364146   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 2827   Recon Loss: 0.380031   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 2828   Recon Loss: 0.384736   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 2829   Recon Loss: 0.361523   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 2830   Recon Loss: 0.366074   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 2831   Recon Loss: 0.376328   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 2832   Recon Loss: 0.381542   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 2833   Recon Loss: 0.362507   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 2834   Recon Loss: 0.377777   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 2835   Recon Loss: 0.333360   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 2836   Recon Loss: 0.373099   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 2837   Recon Loss: 0.377327   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 2838   Recon Loss: 0.377651   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 2839   Recon Loss: 0.354933   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 2840   Recon Loss: 0.378581   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 2841   Recon Loss: 0.375833   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 2842   Recon Loss: 0.359344   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 2843   Recon Loss: 0.391139   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 2844   Recon Loss: 0.364484   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 2845   Recon Loss: 0.353688   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 2846   Recon Loss: 0.360712   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 2847   Recon Loss: 0.367017   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 2848   Recon Loss: 0.384883   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 2849   Recon Loss: 0.350207   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 2850   Recon Loss: 0.357360   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 2851   Recon Loss: 0.361421   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 2852   Recon Loss: 0.383636   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 2853   Recon Loss: 0.387578   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 2854   Recon Loss: 0.369895   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 2855   Recon Loss: 0.373513   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 2856   Recon Loss: 0.381426   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 2857   Recon Loss: 0.349298   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 2858   Recon Loss: 0.374788   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 2859   Recon Loss: 0.386646   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 2860   Recon Loss: 0.363135   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 2861   Recon Loss: 0.363907   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 2862   Recon Loss: 0.361027   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 2863   Recon Loss: 0.355607   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 2864   Recon Loss: 0.346186   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 2865   Recon Loss: 0.365079   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 2866   Recon Loss: 0.383675   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 2867   Recon Loss: 0.362113   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 2868   Recon Loss: 0.375851   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 2869   Recon Loss: 0.365492   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 2870   Recon Loss: 0.364177   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 2871   Recon Loss: 0.350681   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 2872   Recon Loss: 0.352601   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 2873   Recon Loss: 0.364792   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 2874   Recon Loss: 0.373225   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 2875   Recon Loss: 0.353602   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 2876   Recon Loss: 0.369486   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 2877   Recon Loss: 0.362032   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 2878   Recon Loss: 0.358711   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 2879   Recon Loss: 0.385824   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 2880   Recon Loss: 0.376778   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 2881   Recon Loss: 0.377257   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 2882   Recon Loss: 0.357948   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 2883   Recon Loss: 0.373897   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 2884   Recon Loss: 0.379104   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 2885   Recon Loss: 0.365157   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 2886   Recon Loss: 0.348168   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 2887   Recon Loss: 0.365166   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 2888   Recon Loss: 0.379863   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 2889   Recon Loss: 0.371246   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 2890   Recon Loss: 0.379490   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 2891   Recon Loss: 0.361929   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 2892   Recon Loss: 0.352375   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 2893   Recon Loss: 0.365142   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 2894   Recon Loss: 0.380998   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 2895   Recon Loss: 0.378892   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 2896   Recon Loss: 0.365407   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 2897   Recon Loss: 0.389598   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 2898   Recon Loss: 0.367145   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 2899   Recon Loss: 0.352267   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 2900   Recon Loss: 0.393393   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 2901   Recon Loss: 0.383411   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 2902   Recon Loss: 0.393239   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 2903   Recon Loss: 0.361084   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 2904   Recon Loss: 0.353326   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 2905   Recon Loss: 0.377895   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 2906   Recon Loss: 0.364577   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 2907   Recon Loss: 0.358387   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 2908   Recon Loss: 0.363220   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 2909   Recon Loss: 0.372714   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 2910   Recon Loss: 0.375301   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 2911   Recon Loss: 0.379973   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 2912   Recon Loss: 0.351276   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 2913   Recon Loss: 0.371739   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 2914   Recon Loss: 0.357211   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 2915   Recon Loss: 0.377487   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 2916   Recon Loss: 0.362789   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 2917   Recon Loss: 0.370118   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 2918   Recon Loss: 0.357301   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 2919   Recon Loss: 0.371421   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 2920   Recon Loss: 0.383818   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 2921   Recon Loss: 0.373720   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 2922   Recon Loss: 0.353553   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 2923   Recon Loss: 0.374224   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 2924   Recon Loss: 0.366449   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 2925   Recon Loss: 0.354626   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 2926   Recon Loss: 0.377141   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 2927   Recon Loss: 0.348009   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 2928   Recon Loss: 0.363118   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 2929   Recon Loss: 0.360597   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 2930   Recon Loss: 0.347049   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 2931   Recon Loss: 0.359538   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 2932   Recon Loss: 0.353415   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 2933   Recon Loss: 0.368489   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 2934   Recon Loss: 0.342830   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 2935   Recon Loss: 0.355523   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 2936   Recon Loss: 0.363651   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 2937   Recon Loss: 0.361498   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 2938   Recon Loss: 0.362232   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 2939   Recon Loss: 0.364331   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 2940   Recon Loss: 0.391384   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 2941   Recon Loss: 0.350188   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 2942   Recon Loss: 0.360800   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 2943   Recon Loss: 0.356440   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 2944   Recon Loss: 0.366878   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 2945   Recon Loss: 0.369937   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 2946   Recon Loss: 0.374434   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 2947   Recon Loss: 0.365816   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 2948   Recon Loss: 0.355336   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 2949   Recon Loss: 0.374066   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 2950   Recon Loss: 0.360604   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 2951   Recon Loss: 0.378651   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 2952   Recon Loss: 0.349702   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 2953   Recon Loss: 0.371898   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 2954   Recon Loss: 0.352679   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 2955   Recon Loss: 0.359911   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 2956   Recon Loss: 0.380160   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 2957   Recon Loss: 0.363614   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 2958   Recon Loss: 0.347278   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 2959   Recon Loss: 0.355088   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 2960   Recon Loss: 0.358919   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 2961   Recon Loss: 0.359524   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 2962   Recon Loss: 0.351816   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 2963   Recon Loss: 0.368306   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 2964   Recon Loss: 0.376840   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 2965   Recon Loss: 0.380691   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 2966   Recon Loss: 0.379224   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 2967   Recon Loss: 0.345405   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 2968   Recon Loss: 0.352535   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 2969   Recon Loss: 0.351133   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 2970   Recon Loss: 0.356887   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 2971   Recon Loss: 0.345014   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 2972   Recon Loss: 0.366548   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 2973   Recon Loss: 0.349804   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 2974   Recon Loss: 0.362306   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 2975   Recon Loss: 0.375600   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 2976   Recon Loss: 0.381043   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 2977   Recon Loss: 0.384151   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 2978   Recon Loss: 0.375641   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 2979   Recon Loss: 0.348793   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 2980   Recon Loss: 0.350212   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 2981   Recon Loss: 0.357114   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 2982   Recon Loss: 0.372884   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 2983   Recon Loss: 0.350392   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 2984   Recon Loss: 0.378685   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 2985   Recon Loss: 0.382352   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 2986   Recon Loss: 0.365495   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 2987   Recon Loss: 0.379861   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 2988   Recon Loss: 0.371244   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 2989   Recon Loss: 0.368662   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 2990   Recon Loss: 0.364859   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 2991   Recon Loss: 0.344533   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 2992   Recon Loss: 0.374484   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 2993   Recon Loss: 0.357626   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 2994   Recon Loss: 0.370519   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 2995   Recon Loss: 0.388520   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 2996   Recon Loss: 0.350109   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 2997   Recon Loss: 0.364732   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 2998   Recon Loss: 0.364070   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 2999   Recon Loss: 0.353533   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3000   Recon Loss: 0.358593   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3001   Recon Loss: 0.366693   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3002   Recon Loss: 0.359381   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3003   Recon Loss: 0.360114   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3004   Recon Loss: 0.359880   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3005   Recon Loss: 0.373125   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3006   Recon Loss: 0.382754   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3007   Recon Loss: 0.375285   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3008   Recon Loss: 0.350479   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3009   Recon Loss: 0.372573   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3010   Recon Loss: 0.350165   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3011   Recon Loss: 0.354806   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3012   Recon Loss: 0.369205   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3013   Recon Loss: 0.372165   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3014   Recon Loss: 0.376912   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3015   Recon Loss: 0.365060   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3016   Recon Loss: 0.355892   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3017   Recon Loss: 0.361226   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3018   Recon Loss: 0.385909   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3019   Recon Loss: 0.367446   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3020   Recon Loss: 0.380625   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3021   Recon Loss: 0.368100   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3022   Recon Loss: 0.351330   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3023   Recon Loss: 0.366217   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3024   Recon Loss: 0.369139   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3025   Recon Loss: 0.365677   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3026   Recon Loss: 0.379966   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3027   Recon Loss: 0.372574   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3028   Recon Loss: 0.348505   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3029   Recon Loss: 0.355524   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3030   Recon Loss: 0.351798   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3031   Recon Loss: 0.367167   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3032   Recon Loss: 0.365569   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3033   Recon Loss: 0.366639   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3034   Recon Loss: 0.354348   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3035   Recon Loss: 0.359544   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3036   Recon Loss: 0.354355   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3037   Recon Loss: 0.356082   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3038   Recon Loss: 0.351737   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3039   Recon Loss: 0.375553   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3040   Recon Loss: 0.357675   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3041   Recon Loss: 0.377078   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3042   Recon Loss: 0.381378   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3043   Recon Loss: 0.351855   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3044   Recon Loss: 0.367748   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3045   Recon Loss: 0.372435   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3046   Recon Loss: 0.356371   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3047   Recon Loss: 0.373604   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3048   Recon Loss: 0.357306   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3049   Recon Loss: 0.363647   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3050   Recon Loss: 0.360237   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3051   Recon Loss: 0.363950   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3052   Recon Loss: 0.362006   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3053   Recon Loss: 0.380279   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3054   Recon Loss: 0.350878   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3055   Recon Loss: 0.366623   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3056   Recon Loss: 0.366640   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3057   Recon Loss: 0.353099   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3058   Recon Loss: 0.350188   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3059   Recon Loss: 0.367910   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3060   Recon Loss: 0.363303   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3061   Recon Loss: 0.380273   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3062   Recon Loss: 0.350670   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3063   Recon Loss: 0.360035   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3064   Recon Loss: 0.364010   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3065   Recon Loss: 0.363765   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3066   Recon Loss: 0.357441   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3067   Recon Loss: 0.378176   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3068   Recon Loss: 0.382975   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3069   Recon Loss: 0.359761   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3070   Recon Loss: 0.376739   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3071   Recon Loss: 0.375157   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3072   Recon Loss: 0.364175   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3073   Recon Loss: 0.352364   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3074   Recon Loss: 0.375850   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3075   Recon Loss: 0.361179   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3076   Recon Loss: 0.368767   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3077   Recon Loss: 0.360171   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3078   Recon Loss: 0.372625   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3079   Recon Loss: 0.364326   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3080   Recon Loss: 0.376995   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3081   Recon Loss: 0.343446   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3082   Recon Loss: 0.360382   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3083   Recon Loss: 0.368820   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3084   Recon Loss: 0.370684   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3085   Recon Loss: 0.356383   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3086   Recon Loss: 0.379891   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3087   Recon Loss: 0.392063   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3088   Recon Loss: 0.358311   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3089   Recon Loss: 0.380311   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3090   Recon Loss: 0.368564   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3091   Recon Loss: 0.364861   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3092   Recon Loss: 0.359470   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3093   Recon Loss: 0.367245   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3094   Recon Loss: 0.360125   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3095   Recon Loss: 0.363703   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3096   Recon Loss: 0.373315   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3097   Recon Loss: 0.360501   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3098   Recon Loss: 0.380663   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3099   Recon Loss: 0.345977   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3100   Recon Loss: 0.351503   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3101   Recon Loss: 0.360834   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3102   Recon Loss: 0.376349   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3103   Recon Loss: 0.368154   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3104   Recon Loss: 0.377718   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3105   Recon Loss: 0.349746   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3106   Recon Loss: 0.353639   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3107   Recon Loss: 0.360981   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3108   Recon Loss: 0.346858   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3109   Recon Loss: 0.343978   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3110   Recon Loss: 0.341824   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3111   Recon Loss: 0.359106   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3112   Recon Loss: 0.354792   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3113   Recon Loss: 0.359337   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3114   Recon Loss: 0.359107   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3115   Recon Loss: 0.361672   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3116   Recon Loss: 0.358996   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3117   Recon Loss: 0.391881   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3118   Recon Loss: 0.349433   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3119   Recon Loss: 0.361364   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3120   Recon Loss: 0.375249   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3121   Recon Loss: 0.373084   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3122   Recon Loss: 0.387468   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3123   Recon Loss: 0.356897   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3124   Recon Loss: 0.345992   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3125   Recon Loss: 0.373697   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3126   Recon Loss: 0.372911   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3127   Recon Loss: 0.378007   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3128   Recon Loss: 0.384231   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3129   Recon Loss: 0.355862   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3130   Recon Loss: 0.371790   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3131   Recon Loss: 0.378923   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3132   Recon Loss: 0.340812   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3133   Recon Loss: 0.345173   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3134   Recon Loss: 0.381058   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3135   Recon Loss: 0.366159   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3136   Recon Loss: 0.366912   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3137   Recon Loss: 0.341433   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3138   Recon Loss: 0.378168   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3139   Recon Loss: 0.370262   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3140   Recon Loss: 0.375028   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3141   Recon Loss: 0.366322   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3142   Recon Loss: 0.386314   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3143   Recon Loss: 0.351072   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3144   Recon Loss: 0.359189   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3145   Recon Loss: 0.380442   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3146   Recon Loss: 0.368896   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3147   Recon Loss: 0.370735   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3148   Recon Loss: 0.364205   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3149   Recon Loss: 0.367254   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3150   Recon Loss: 0.375577   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3151   Recon Loss: 0.366555   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3152   Recon Loss: 0.360850   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3153   Recon Loss: 0.368392   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3154   Recon Loss: 0.363852   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3155   Recon Loss: 0.370313   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3156   Recon Loss: 0.371956   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3157   Recon Loss: 0.365391   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3158   Recon Loss: 0.374764   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3159   Recon Loss: 0.353523   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3160   Recon Loss: 0.359590   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3161   Recon Loss: 0.348399   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3162   Recon Loss: 0.349993   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3163   Recon Loss: 0.362106   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3164   Recon Loss: 0.368301   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3165   Recon Loss: 0.370415   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3166   Recon Loss: 0.356695   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3167   Recon Loss: 0.372906   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3168   Recon Loss: 0.334950   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3169   Recon Loss: 0.367165   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3170   Recon Loss: 0.351657   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3171   Recon Loss: 0.353331   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3172   Recon Loss: 0.368966   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3173   Recon Loss: 0.348677   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3174   Recon Loss: 0.378686   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3175   Recon Loss: 0.342398   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3176   Recon Loss: 0.351483   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3177   Recon Loss: 0.364046   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3178   Recon Loss: 0.366804   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3179   Recon Loss: 0.373330   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3180   Recon Loss: 0.343633   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3181   Recon Loss: 0.380121   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3182   Recon Loss: 0.398578   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3183   Recon Loss: 0.386403   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3184   Recon Loss: 0.373391   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3185   Recon Loss: 0.347001   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3186   Recon Loss: 0.376662   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3187   Recon Loss: 0.371341   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3188   Recon Loss: 0.366715   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3189   Recon Loss: 0.370136   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3190   Recon Loss: 0.362540   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3191   Recon Loss: 0.361382   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3192   Recon Loss: 0.381417   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3193   Recon Loss: 0.363278   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3194   Recon Loss: 0.352757   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3195   Recon Loss: 0.372945   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3196   Recon Loss: 0.361169   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3197   Recon Loss: 0.376556   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3198   Recon Loss: 0.370571   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3199   Recon Loss: 0.358288   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3200   Recon Loss: 0.362659   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3201   Recon Loss: 0.370280   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3202   Recon Loss: 0.381367   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3203   Recon Loss: 0.366581   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3204   Recon Loss: 0.370407   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3205   Recon Loss: 0.380821   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3206   Recon Loss: 0.369027   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3207   Recon Loss: 0.390884   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3208   Recon Loss: 0.371817   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3209   Recon Loss: 0.361197   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3210   Recon Loss: 0.360398   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3211   Recon Loss: 0.381080   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3212   Recon Loss: 0.348224   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3213   Recon Loss: 0.369083   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3214   Recon Loss: 0.367738   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3215   Recon Loss: 0.348780   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3216   Recon Loss: 0.356443   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3217   Recon Loss: 0.376420   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3218   Recon Loss: 0.382037   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3219   Recon Loss: 0.367506   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3220   Recon Loss: 0.372480   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3221   Recon Loss: 0.364962   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3222   Recon Loss: 0.373956   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3223   Recon Loss: 0.355639   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3224   Recon Loss: 0.362432   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3225   Recon Loss: 0.371165   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3226   Recon Loss: 0.349269   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3227   Recon Loss: 0.361020   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3228   Recon Loss: 0.375796   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3229   Recon Loss: 0.364444   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3230   Recon Loss: 0.378047   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3231   Recon Loss: 0.347614   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3232   Recon Loss: 0.359866   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3233   Recon Loss: 0.349753   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3234   Recon Loss: 0.359545   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3235   Recon Loss: 0.331262   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3236   Recon Loss: 0.338951   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3237   Recon Loss: 0.363546   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3238   Recon Loss: 0.368702   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3239   Recon Loss: 0.383659   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3240   Recon Loss: 0.380957   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3241   Recon Loss: 0.373065   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3242   Recon Loss: 0.354825   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3243   Recon Loss: 0.373627   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3244   Recon Loss: 0.382531   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3245   Recon Loss: 0.370221   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3246   Recon Loss: 0.354631   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3247   Recon Loss: 0.356752   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3248   Recon Loss: 0.367439   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3249   Recon Loss: 0.386106   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3250   Recon Loss: 0.369038   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3251   Recon Loss: 0.371305   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3252   Recon Loss: 0.366878   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3253   Recon Loss: 0.386956   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3254   Recon Loss: 0.363226   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3255   Recon Loss: 0.386887   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3256   Recon Loss: 0.358844   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3257   Recon Loss: 0.376703   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3258   Recon Loss: 0.372727   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3259   Recon Loss: 0.351669   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3260   Recon Loss: 0.363556   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3261   Recon Loss: 0.357193   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3262   Recon Loss: 0.379924   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3263   Recon Loss: 0.364061   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3264   Recon Loss: 0.353587   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3265   Recon Loss: 0.376473   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3266   Recon Loss: 0.364207   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3267   Recon Loss: 0.361166   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3268   Recon Loss: 0.353028   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3269   Recon Loss: 0.369780   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3270   Recon Loss: 0.373535   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3271   Recon Loss: 0.363279   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3272   Recon Loss: 0.385190   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3273   Recon Loss: 0.359288   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3274   Recon Loss: 0.382873   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3275   Recon Loss: 0.349600   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3276   Recon Loss: 0.347911   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3277   Recon Loss: 0.384810   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3278   Recon Loss: 0.393156   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3279   Recon Loss: 0.369889   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3280   Recon Loss: 0.376452   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3281   Recon Loss: 0.366307   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3282   Recon Loss: 0.372423   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3283   Recon Loss: 0.360675   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3284   Recon Loss: 0.378421   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3285   Recon Loss: 0.365690   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3286   Recon Loss: 0.381079   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3287   Recon Loss: 0.360556   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3288   Recon Loss: 0.360505   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3289   Recon Loss: 0.356798   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3290   Recon Loss: 0.371885   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3291   Recon Loss: 0.362054   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3292   Recon Loss: 0.357325   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3293   Recon Loss: 0.348149   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3294   Recon Loss: 0.352625   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3295   Recon Loss: 0.356939   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3296   Recon Loss: 0.352852   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3297   Recon Loss: 0.351027   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3298   Recon Loss: 0.347780   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3299   Recon Loss: 0.362066   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3300   Recon Loss: 0.362195   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3301   Recon Loss: 0.385708   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3302   Recon Loss: 0.363769   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3303   Recon Loss: 0.351476   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3304   Recon Loss: 0.375339   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3305   Recon Loss: 0.359418   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3306   Recon Loss: 0.372797   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3307   Recon Loss: 0.366065   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3308   Recon Loss: 0.365709   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3309   Recon Loss: 0.355793   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3310   Recon Loss: 0.360707   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3311   Recon Loss: 0.363639   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3312   Recon Loss: 0.365355   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3313   Recon Loss: 0.368476   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3314   Recon Loss: 0.353161   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3315   Recon Loss: 0.363606   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3316   Recon Loss: 0.354673   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3317   Recon Loss: 0.373600   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3318   Recon Loss: 0.359771   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3319   Recon Loss: 0.355873   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3320   Recon Loss: 0.374670   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3321   Recon Loss: 0.371286   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3322   Recon Loss: 0.361901   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3323   Recon Loss: 0.371368   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3324   Recon Loss: 0.373272   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3325   Recon Loss: 0.358620   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3326   Recon Loss: 0.354896   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3327   Recon Loss: 0.358336   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3328   Recon Loss: 0.365389   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3329   Recon Loss: 0.355066   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3330   Recon Loss: 0.373636   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3331   Recon Loss: 0.364545   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3332   Recon Loss: 0.368661   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3333   Recon Loss: 0.358178   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3334   Recon Loss: 0.387807   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3335   Recon Loss: 0.363733   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3336   Recon Loss: 0.373237   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3337   Recon Loss: 0.364733   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3338   Recon Loss: 0.357711   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3339   Recon Loss: 0.373386   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3340   Recon Loss: 0.366349   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3341   Recon Loss: 0.385279   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3342   Recon Loss: 0.361645   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3343   Recon Loss: 0.347436   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3344   Recon Loss: 0.366245   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3345   Recon Loss: 0.371287   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3346   Recon Loss: 0.379224   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3347   Recon Loss: 0.364203   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3348   Recon Loss: 0.370232   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3349   Recon Loss: 0.389201   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3350   Recon Loss: 0.350256   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3351   Recon Loss: 0.368954   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3352   Recon Loss: 0.373315   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3353   Recon Loss: 0.363615   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3354   Recon Loss: 0.360144   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3355   Recon Loss: 0.356734   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3356   Recon Loss: 0.381793   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3357   Recon Loss: 0.362452   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3358   Recon Loss: 0.344726   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3359   Recon Loss: 0.388446   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3360   Recon Loss: 0.354418   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3361   Recon Loss: 0.386431   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3362   Recon Loss: 0.374218   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3363   Recon Loss: 0.399113   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3364   Recon Loss: 0.367806   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3365   Recon Loss: 0.351511   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3366   Recon Loss: 0.346096   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3367   Recon Loss: 0.380530   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3368   Recon Loss: 0.357467   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3369   Recon Loss: 0.368218   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3370   Recon Loss: 0.356187   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3371   Recon Loss: 0.407074   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3372   Recon Loss: 0.380836   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3373   Recon Loss: 0.357720   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3374   Recon Loss: 0.383525   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3375   Recon Loss: 0.355717   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3376   Recon Loss: 0.396866   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3377   Recon Loss: 0.383411   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3378   Recon Loss: 0.348308   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3379   Recon Loss: 0.359616   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3380   Recon Loss: 0.380050   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3381   Recon Loss: 0.383749   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3382   Recon Loss: 0.384136   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3383   Recon Loss: 0.349690   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3384   Recon Loss: 0.382858   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3385   Recon Loss: 0.372326   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3386   Recon Loss: 0.391621   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3387   Recon Loss: 0.367707   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3388   Recon Loss: 0.359150   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3389   Recon Loss: 0.350123   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3390   Recon Loss: 0.362701   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3391   Recon Loss: 0.384179   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3392   Recon Loss: 0.344775   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3393   Recon Loss: 0.370107   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3394   Recon Loss: 0.358585   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3395   Recon Loss: 0.364798   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3396   Recon Loss: 0.385649   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3397   Recon Loss: 0.403362   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3398   Recon Loss: 0.366780   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3399   Recon Loss: 0.366525   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3400   Recon Loss: 0.372677   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3401   Recon Loss: 0.354627   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3402   Recon Loss: 0.380138   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3403   Recon Loss: 0.362074   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3404   Recon Loss: 0.365934   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3405   Recon Loss: 0.362365   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3406   Recon Loss: 0.367562   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3407   Recon Loss: 0.377591   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3408   Recon Loss: 0.375283   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3409   Recon Loss: 0.371801   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3410   Recon Loss: 0.369535   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3411   Recon Loss: 0.366967   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3412   Recon Loss: 0.356493   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3413   Recon Loss: 0.371687   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3414   Recon Loss: 0.356944   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3415   Recon Loss: 0.381651   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3416   Recon Loss: 0.368230   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3417   Recon Loss: 0.372642   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3418   Recon Loss: 0.354114   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3419   Recon Loss: 0.377349   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3420   Recon Loss: 0.364761   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3421   Recon Loss: 0.362781   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3422   Recon Loss: 0.373275   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3423   Recon Loss: 0.376820   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3424   Recon Loss: 0.385613   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3425   Recon Loss: 0.357794   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3426   Recon Loss: 0.353943   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3427   Recon Loss: 0.372146   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3428   Recon Loss: 0.364521   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3429   Recon Loss: 0.370328   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3430   Recon Loss: 0.376302   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3431   Recon Loss: 0.354656   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3432   Recon Loss: 0.376539   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3433   Recon Loss: 0.380408   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3434   Recon Loss: 0.370610   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3435   Recon Loss: 0.363466   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3436   Recon Loss: 0.372768   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3437   Recon Loss: 0.374624   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3438   Recon Loss: 0.368943   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3439   Recon Loss: 0.361809   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3440   Recon Loss: 0.370877   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3441   Recon Loss: 0.360235   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3442   Recon Loss: 0.353363   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3443   Recon Loss: 0.368975   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3444   Recon Loss: 0.375136   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3445   Recon Loss: 0.372260   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3446   Recon Loss: 0.360432   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3447   Recon Loss: 0.386234   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3448   Recon Loss: 0.381801   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3449   Recon Loss: 0.351540   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3450   Recon Loss: 0.341915   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3451   Recon Loss: 0.371793   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3452   Recon Loss: 0.362169   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3453   Recon Loss: 0.373011   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3454   Recon Loss: 0.360245   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3455   Recon Loss: 0.361514   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3456   Recon Loss: 0.368629   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3457   Recon Loss: 0.361411   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3458   Recon Loss: 0.373363   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3459   Recon Loss: 0.349652   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3460   Recon Loss: 0.370052   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3461   Recon Loss: 0.373893   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3462   Recon Loss: 0.355853   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3463   Recon Loss: 0.347172   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3464   Recon Loss: 0.377060   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3465   Recon Loss: 0.354076   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3466   Recon Loss: 0.377013   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3467   Recon Loss: 0.363056   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3468   Recon Loss: 0.387752   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3469   Recon Loss: 0.373180   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3470   Recon Loss: 0.366417   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3471   Recon Loss: 0.361957   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3472   Recon Loss: 0.362398   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3473   Recon Loss: 0.357804   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3474   Recon Loss: 0.366162   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3475   Recon Loss: 0.332010   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3476   Recon Loss: 0.382437   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3477   Recon Loss: 0.368934   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3478   Recon Loss: 0.367390   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3479   Recon Loss: 0.377911   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3480   Recon Loss: 0.374071   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3481   Recon Loss: 0.375409   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3482   Recon Loss: 0.348482   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3483   Recon Loss: 0.362655   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3484   Recon Loss: 0.384145   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3485   Recon Loss: 0.368147   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3486   Recon Loss: 0.362454   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3487   Recon Loss: 0.342769   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3488   Recon Loss: 0.360507   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3489   Recon Loss: 0.370250   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3490   Recon Loss: 0.362923   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3491   Recon Loss: 0.369507   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3492   Recon Loss: 0.364802   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3493   Recon Loss: 0.362920   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3494   Recon Loss: 0.370093   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3495   Recon Loss: 0.356045   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3496   Recon Loss: 0.376099   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3497   Recon Loss: 0.371460   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3498   Recon Loss: 0.360720   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3499   Recon Loss: 0.375367   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3500   Recon Loss: 0.363628   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3501   Recon Loss: 0.380636   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3502   Recon Loss: 0.375742   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3503   Recon Loss: 0.358883   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3504   Recon Loss: 0.364659   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3505   Recon Loss: 0.366023   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3506   Recon Loss: 0.364378   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3507   Recon Loss: 0.358249   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3508   Recon Loss: 0.359711   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3509   Recon Loss: 0.360340   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3510   Recon Loss: 0.357814   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3511   Recon Loss: 0.358065   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3512   Recon Loss: 0.380922   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3513   Recon Loss: 0.366537   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3514   Recon Loss: 0.353294   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3515   Recon Loss: 0.364888   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3516   Recon Loss: 0.366768   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3517   Recon Loss: 0.364761   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3518   Recon Loss: 0.362773   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3519   Recon Loss: 0.379491   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3520   Recon Loss: 0.367823   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3521   Recon Loss: 0.361084   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3522   Recon Loss: 0.365991   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3523   Recon Loss: 0.354141   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3524   Recon Loss: 0.381911   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3525   Recon Loss: 0.362861   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3526   Recon Loss: 0.372513   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3527   Recon Loss: 0.362077   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3528   Recon Loss: 0.385349   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3529   Recon Loss: 0.368635   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3530   Recon Loss: 0.370584   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3531   Recon Loss: 0.362578   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3532   Recon Loss: 0.353103   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3533   Recon Loss: 0.381254   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3534   Recon Loss: 0.375642   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3535   Recon Loss: 0.378422   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3536   Recon Loss: 0.363825   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3537   Recon Loss: 0.367274   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3538   Recon Loss: 0.374986   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3539   Recon Loss: 0.354930   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3540   Recon Loss: 0.349011   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3541   Recon Loss: 0.352046   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3542   Recon Loss: 0.383800   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3543   Recon Loss: 0.383046   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3544   Recon Loss: 0.388144   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3545   Recon Loss: 0.376108   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3546   Recon Loss: 0.360721   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3547   Recon Loss: 0.381629   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3548   Recon Loss: 0.359091   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3549   Recon Loss: 0.348977   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3550   Recon Loss: 0.348475   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3551   Recon Loss: 0.365666   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3552   Recon Loss: 0.369960   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3553   Recon Loss: 0.361192   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3554   Recon Loss: 0.354043   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3555   Recon Loss: 0.374883   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3556   Recon Loss: 0.345029   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3557   Recon Loss: 0.378444   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3558   Recon Loss: 0.364330   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3559   Recon Loss: 0.360738   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3560   Recon Loss: 0.355114   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3561   Recon Loss: 0.373142   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3562   Recon Loss: 0.363270   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3563   Recon Loss: 0.367248   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3564   Recon Loss: 0.365531   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3565   Recon Loss: 0.370357   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3566   Recon Loss: 0.366270   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3567   Recon Loss: 0.372114   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3568   Recon Loss: 0.340105   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3569   Recon Loss: 0.363853   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3570   Recon Loss: 0.355285   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3571   Recon Loss: 0.373511   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3572   Recon Loss: 0.366900   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3573   Recon Loss: 0.362612   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3574   Recon Loss: 0.369793   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3575   Recon Loss: 0.356877   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3576   Recon Loss: 0.374139   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3577   Recon Loss: 0.367692   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3578   Recon Loss: 0.399732   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3579   Recon Loss: 0.385843   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3580   Recon Loss: 0.378993   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3581   Recon Loss: 0.350510   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3582   Recon Loss: 0.343389   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3583   Recon Loss: 0.355710   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3584   Recon Loss: 0.369389   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3585   Recon Loss: 0.371135   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3586   Recon Loss: 0.360642   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3587   Recon Loss: 0.368089   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3588   Recon Loss: 0.400987   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3589   Recon Loss: 0.370833   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3590   Recon Loss: 0.364754   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3591   Recon Loss: 0.381307   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3592   Recon Loss: 0.374044   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3593   Recon Loss: 0.349610   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3594   Recon Loss: 0.357325   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3595   Recon Loss: 0.356848   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3596   Recon Loss: 0.341575   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3597   Recon Loss: 0.369345   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3598   Recon Loss: 0.362799   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3599   Recon Loss: 0.365882   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3600   Recon Loss: 0.364682   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3601   Recon Loss: 0.349835   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3602   Recon Loss: 0.356587   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3603   Recon Loss: 0.384998   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3604   Recon Loss: 0.369197   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3605   Recon Loss: 0.374116   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3606   Recon Loss: 0.374054   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3607   Recon Loss: 0.381899   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3608   Recon Loss: 0.363392   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3609   Recon Loss: 0.387081   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3610   Recon Loss: 0.351859   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3611   Recon Loss: 0.378133   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3612   Recon Loss: 0.374707   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3613   Recon Loss: 0.386917   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3614   Recon Loss: 0.386513   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3615   Recon Loss: 0.363052   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3616   Recon Loss: 0.349405   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3617   Recon Loss: 0.373767   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3618   Recon Loss: 0.362760   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3619   Recon Loss: 0.370134   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3620   Recon Loss: 0.385935   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3621   Recon Loss: 0.366346   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3622   Recon Loss: 0.373924   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3623   Recon Loss: 0.385861   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3624   Recon Loss: 0.380019   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3625   Recon Loss: 0.360031   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3626   Recon Loss: 0.366475   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3627   Recon Loss: 0.349887   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3628   Recon Loss: 0.359072   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3629   Recon Loss: 0.354146   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3630   Recon Loss: 0.354090   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3631   Recon Loss: 0.359420   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3632   Recon Loss: 0.367617   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3633   Recon Loss: 0.378757   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3634   Recon Loss: 0.383190   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3635   Recon Loss: 0.353128   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3636   Recon Loss: 0.371252   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3637   Recon Loss: 0.386137   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3638   Recon Loss: 0.357208   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3639   Recon Loss: 0.385735   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3640   Recon Loss: 0.364933   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3641   Recon Loss: 0.360689   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3642   Recon Loss: 0.376677   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3643   Recon Loss: 0.366494   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3644   Recon Loss: 0.355989   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3645   Recon Loss: 0.358931   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3646   Recon Loss: 0.353872   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3647   Recon Loss: 0.370096   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3648   Recon Loss: 0.355368   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3649   Recon Loss: 0.352870   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3650   Recon Loss: 0.377758   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3651   Recon Loss: 0.365644   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3652   Recon Loss: 0.371074   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3653   Recon Loss: 0.368572   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3654   Recon Loss: 0.381464   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3655   Recon Loss: 0.379752   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3656   Recon Loss: 0.379386   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3657   Recon Loss: 0.372269   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3658   Recon Loss: 0.373869   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3659   Recon Loss: 0.353526   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3660   Recon Loss: 0.361267   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3661   Recon Loss: 0.362328   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3662   Recon Loss: 0.365936   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3663   Recon Loss: 0.365746   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3664   Recon Loss: 0.365204   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3665   Recon Loss: 0.360165   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3666   Recon Loss: 0.379437   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3667   Recon Loss: 0.357308   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3668   Recon Loss: 0.361355   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3669   Recon Loss: 0.361819   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3670   Recon Loss: 0.383762   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3671   Recon Loss: 0.352776   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3672   Recon Loss: 0.347755   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3673   Recon Loss: 0.350907   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3674   Recon Loss: 0.351279   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3675   Recon Loss: 0.361248   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3676   Recon Loss: 0.370695   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3677   Recon Loss: 0.370824   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3678   Recon Loss: 0.363251   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3679   Recon Loss: 0.367334   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3680   Recon Loss: 0.374486   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3681   Recon Loss: 0.368254   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3682   Recon Loss: 0.374483   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3683   Recon Loss: 0.370813   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3684   Recon Loss: 0.361633   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3685   Recon Loss: 0.375651   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3686   Recon Loss: 0.361407   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3687   Recon Loss: 0.357200   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3688   Recon Loss: 0.371137   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3689   Recon Loss: 0.366073   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3690   Recon Loss: 0.376115   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3691   Recon Loss: 0.378883   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3692   Recon Loss: 0.367963   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3693   Recon Loss: 0.363873   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3694   Recon Loss: 0.371331   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3695   Recon Loss: 0.366137   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3696   Recon Loss: 0.356392   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3697   Recon Loss: 0.359941   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3698   Recon Loss: 0.355016   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3699   Recon Loss: 0.348794   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3700   Recon Loss: 0.371304   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3701   Recon Loss: 0.356397   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3702   Recon Loss: 0.375783   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3703   Recon Loss: 0.348254   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3704   Recon Loss: 0.353636   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3705   Recon Loss: 0.362620   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3706   Recon Loss: 0.364650   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3707   Recon Loss: 0.373688   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3708   Recon Loss: 0.375331   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3709   Recon Loss: 0.367568   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3710   Recon Loss: 0.363840   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3711   Recon Loss: 0.358738   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3712   Recon Loss: 0.380409   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3713   Recon Loss: 0.364346   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3714   Recon Loss: 0.354555   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3715   Recon Loss: 0.375157   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3716   Recon Loss: 0.373717   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3717   Recon Loss: 0.377783   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3718   Recon Loss: 0.346112   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3719   Recon Loss: 0.372460   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3720   Recon Loss: 0.378180   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3721   Recon Loss: 0.356842   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3722   Recon Loss: 0.384218   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3723   Recon Loss: 0.360985   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3724   Recon Loss: 0.371570   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3725   Recon Loss: 0.391624   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3726   Recon Loss: 0.373132   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3727   Recon Loss: 0.373732   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3728   Recon Loss: 0.345466   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3729   Recon Loss: 0.379416   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3730   Recon Loss: 0.341085   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3731   Recon Loss: 0.361951   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3732   Recon Loss: 0.366233   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3733   Recon Loss: 0.351506   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3734   Recon Loss: 0.394579   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3735   Recon Loss: 0.371099   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3736   Recon Loss: 0.347099   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3737   Recon Loss: 0.378085   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3738   Recon Loss: 0.368978   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3739   Recon Loss: 0.361449   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3740   Recon Loss: 0.383001   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3741   Recon Loss: 0.379425   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3742   Recon Loss: 0.367746   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3743   Recon Loss: 0.370587   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3744   Recon Loss: 0.362910   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3745   Recon Loss: 0.361451   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3746   Recon Loss: 0.350693   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3747   Recon Loss: 0.376804   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3748   Recon Loss: 0.357716   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3749   Recon Loss: 0.354099   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3750   Recon Loss: 0.383801   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3751   Recon Loss: 0.371824   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3752   Recon Loss: 0.365661   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3753   Recon Loss: 0.365194   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3754   Recon Loss: 0.379139   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3755   Recon Loss: 0.366675   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3756   Recon Loss: 0.368091   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3757   Recon Loss: 0.372425   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3758   Recon Loss: 0.365510   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3759   Recon Loss: 0.328689   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3760   Recon Loss: 0.385715   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3761   Recon Loss: 0.364241   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3762   Recon Loss: 0.368809   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3763   Recon Loss: 0.383007   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3764   Recon Loss: 0.368995   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3765   Recon Loss: 0.371146   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3766   Recon Loss: 0.363493   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3767   Recon Loss: 0.369955   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3768   Recon Loss: 0.386393   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3769   Recon Loss: 0.370062   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3770   Recon Loss: 0.346841   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3771   Recon Loss: 0.387284   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3772   Recon Loss: 0.358661   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3773   Recon Loss: 0.366214   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3774   Recon Loss: 0.363714   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3775   Recon Loss: 0.347200   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3776   Recon Loss: 0.377256   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3777   Recon Loss: 0.360360   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3778   Recon Loss: 0.383253   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3779   Recon Loss: 0.382032   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3780   Recon Loss: 0.350952   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3781   Recon Loss: 0.370488   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3782   Recon Loss: 0.371108   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3783   Recon Loss: 0.352334   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3784   Recon Loss: 0.372853   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3785   Recon Loss: 0.388355   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3786   Recon Loss: 0.361653   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3787   Recon Loss: 0.390134   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3788   Recon Loss: 0.377817   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3789   Recon Loss: 0.366268   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3790   Recon Loss: 0.356362   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3791   Recon Loss: 0.337051   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3792   Recon Loss: 0.413531   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3793   Recon Loss: 0.378584   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3794   Recon Loss: 0.382754   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3795   Recon Loss: 0.356413   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3796   Recon Loss: 0.358855   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3797   Recon Loss: 0.368085   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3798   Recon Loss: 0.380332   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3799   Recon Loss: 0.365691   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3800   Recon Loss: 0.372248   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3801   Recon Loss: 0.356921   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3802   Recon Loss: 0.368969   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3803   Recon Loss: 0.379194   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3804   Recon Loss: 0.366756   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3805   Recon Loss: 0.357788   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3806   Recon Loss: 0.357644   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3807   Recon Loss: 0.362594   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3808   Recon Loss: 0.376770   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3809   Recon Loss: 0.357284   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3810   Recon Loss: 0.365301   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3811   Recon Loss: 0.363615   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3812   Recon Loss: 0.359198   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3813   Recon Loss: 0.366836   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3814   Recon Loss: 0.372697   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3815   Recon Loss: 0.352575   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3816   Recon Loss: 0.360134   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3817   Recon Loss: 0.373851   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3818   Recon Loss: 0.369590   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3819   Recon Loss: 0.358720   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3820   Recon Loss: 0.368868   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3821   Recon Loss: 0.361614   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3822   Recon Loss: 0.372153   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3823   Recon Loss: 0.362605   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3824   Recon Loss: 0.346545   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3825   Recon Loss: 0.374971   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3826   Recon Loss: 0.358024   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3827   Recon Loss: 0.365219   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3828   Recon Loss: 0.352869   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3829   Recon Loss: 0.364400   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3830   Recon Loss: 0.372411   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3831   Recon Loss: 0.352447   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3832   Recon Loss: 0.378277   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3833   Recon Loss: 0.353599   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3834   Recon Loss: 0.358442   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3835   Recon Loss: 0.365899   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3836   Recon Loss: 0.368487   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3837   Recon Loss: 0.360360   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3838   Recon Loss: 0.367912   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3839   Recon Loss: 0.370334   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3840   Recon Loss: 0.370254   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3841   Recon Loss: 0.375078   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3842   Recon Loss: 0.363191   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3843   Recon Loss: 0.373054   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3844   Recon Loss: 0.360286   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3845   Recon Loss: 0.350359   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3846   Recon Loss: 0.349259   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3847   Recon Loss: 0.368190   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3848   Recon Loss: 0.368545   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3849   Recon Loss: 0.366440   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3850   Recon Loss: 0.363409   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3851   Recon Loss: 0.387054   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3852   Recon Loss: 0.360131   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3853   Recon Loss: 0.370640   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3854   Recon Loss: 0.379499   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3855   Recon Loss: 0.380934   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3856   Recon Loss: 0.346903   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3857   Recon Loss: 0.382928   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3858   Recon Loss: 0.353105   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3859   Recon Loss: 0.352990   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3860   Recon Loss: 0.370013   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3861   Recon Loss: 0.373838   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3862   Recon Loss: 0.389533   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3863   Recon Loss: 0.358864   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3864   Recon Loss: 0.382936   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3865   Recon Loss: 0.383689   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3866   Recon Loss: 0.370591   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3867   Recon Loss: 0.365638   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3868   Recon Loss: 0.383306   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3869   Recon Loss: 0.360276   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3870   Recon Loss: 0.370936   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3871   Recon Loss: 0.385381   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3872   Recon Loss: 0.367581   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3873   Recon Loss: 0.385253   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3874   Recon Loss: 0.389035   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3875   Recon Loss: 0.368460   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3876   Recon Loss: 0.361622   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3877   Recon Loss: 0.348273   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3878   Recon Loss: 0.358581   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3879   Recon Loss: 0.354483   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3880   Recon Loss: 0.378815   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3881   Recon Loss: 0.346045   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3882   Recon Loss: 0.369112   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3883   Recon Loss: 0.359197   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3884   Recon Loss: 0.339713   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3885   Recon Loss: 0.373346   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3886   Recon Loss: 0.362760   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3887   Recon Loss: 0.385516   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3888   Recon Loss: 0.370911   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3889   Recon Loss: 0.374695   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3890   Recon Loss: 0.356664   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3891   Recon Loss: 0.381032   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3892   Recon Loss: 0.349689   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3893   Recon Loss: 0.351544   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3894   Recon Loss: 0.359322   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3895   Recon Loss: 0.352816   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3896   Recon Loss: 0.394715   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3897   Recon Loss: 0.339085   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3898   Recon Loss: 0.369299   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3899   Recon Loss: 0.351965   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3900   Recon Loss: 0.370734   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3901   Recon Loss: 0.371795   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3902   Recon Loss: 0.363715   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3903   Recon Loss: 0.373231   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3904   Recon Loss: 0.364378   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3905   Recon Loss: 0.386009   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3906   Recon Loss: 0.365116   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3907   Recon Loss: 0.362656   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3908   Recon Loss: 0.355946   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3909   Recon Loss: 0.359333   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3910   Recon Loss: 0.357379   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3911   Recon Loss: 0.348627   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3912   Recon Loss: 0.379837   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3913   Recon Loss: 0.363073   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3914   Recon Loss: 0.340341   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3915   Recon Loss: 0.361260   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3916   Recon Loss: 0.361463   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3917   Recon Loss: 0.359415   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3918   Recon Loss: 0.360980   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3919   Recon Loss: 0.365997   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3920   Recon Loss: 0.355492   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3921   Recon Loss: 0.367376   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3922   Recon Loss: 0.360868   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3923   Recon Loss: 0.352152   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3924   Recon Loss: 0.382796   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3925   Recon Loss: 0.355754   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3926   Recon Loss: 0.357241   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3927   Recon Loss: 0.371775   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3928   Recon Loss: 0.356838   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3929   Recon Loss: 0.387738   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3930   Recon Loss: 0.360950   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3931   Recon Loss: 0.343710   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3932   Recon Loss: 0.361933   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3933   Recon Loss: 0.347103   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3934   Recon Loss: 0.369835   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3935   Recon Loss: 0.362872   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3936   Recon Loss: 0.355022   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3937   Recon Loss: 0.378167   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3938   Recon Loss: 0.353851   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3939   Recon Loss: 0.359083   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3940   Recon Loss: 0.370807   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3941   Recon Loss: 0.377209   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3942   Recon Loss: 0.347697   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3943   Recon Loss: 0.347037   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3944   Recon Loss: 0.370321   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3945   Recon Loss: 0.380040   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3946   Recon Loss: 0.363345   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3947   Recon Loss: 0.372773   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3948   Recon Loss: 0.367219   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3949   Recon Loss: 0.352386   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3950   Recon Loss: 0.355013   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3951   Recon Loss: 0.368764   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3952   Recon Loss: 0.366312   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3953   Recon Loss: 0.367285   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3954   Recon Loss: 0.402210   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3955   Recon Loss: 0.352115   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3956   Recon Loss: 0.372315   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3957   Recon Loss: 0.372125   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3958   Recon Loss: 0.363020   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3959   Recon Loss: 0.378642   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3960   Recon Loss: 0.372755   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3961   Recon Loss: 0.350701   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3962   Recon Loss: 0.391509   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3963   Recon Loss: 0.377060   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3964   Recon Loss: 0.354495   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3965   Recon Loss: 0.340131   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3966   Recon Loss: 0.361593   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3967   Recon Loss: 0.359901   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3968   Recon Loss: 0.375603   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3969   Recon Loss: 0.376366   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3970   Recon Loss: 0.356035   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3971   Recon Loss: 0.372060   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3972   Recon Loss: 0.368384   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3973   Recon Loss: 0.380790   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3974   Recon Loss: 0.351670   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3975   Recon Loss: 0.364312   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3976   Recon Loss: 0.372025   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3977   Recon Loss: 0.382690   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3978   Recon Loss: 0.361845   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3979   Recon Loss: 0.370167   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3980   Recon Loss: 0.367132   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3981   Recon Loss: 0.366933   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3982   Recon Loss: 0.361499   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3983   Recon Loss: 0.364785   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3984   Recon Loss: 0.363473   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3985   Recon Loss: 0.359093   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3986   Recon Loss: 0.367298   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3987   Recon Loss: 0.361868   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3988   Recon Loss: 0.361552   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3989   Recon Loss: 0.372551   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3990   Recon Loss: 0.387141   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3991   Recon Loss: 0.360884   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3992   Recon Loss: 0.381799   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3993   Recon Loss: 0.371055   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3994   Recon Loss: 0.379904   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3995   Recon Loss: 0.371752   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3996   Recon Loss: 0.367159   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3997   Recon Loss: 0.365435   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3998   Recon Loss: 0.379690   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3999   Recon Loss: 0.371206   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Inference and Save: Unseen Set**"
      ],
      "metadata": {
        "id": "XKLK9fOVqNZ8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data_unseen_test = scipy.io.loadmat('/content/fsl-rsvae/datasets/AWA1/unseen_test.mat')\n",
        "data_unseen_test = data_unseen_test['feature']\n",
        "#data_train = np.transpose(data_train)\n",
        "\n",
        "# labels\n",
        "label_unseen_test = scipy.io.loadmat('/content/fsl-rsvae/datasets/AWA1/unseen_test_label.mat')\n",
        "label_unseen_test = label_unseen_test['label'][0]\n",
        "\n",
        "# attr\n",
        "unseen_attr = scipy.io.loadmat('/content/fsl-rsvae/datasets/AWA1/unseen_attribute.mat')\n",
        "unseen_attr = unseen_attr['unseen_attribute']\n",
        "\n",
        "#/content/fsl-rsvae/datasets/AWA1/unseen_attribute.mat"
      ],
      "metadata": {
        "id": "vWAa8HEplB2t"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "feature_un_dataset = FeatureDataset(data_unseen_test, label_unseen_test, unseen_attr)\n",
        "feature_un_loader = torch.utils.data.DataLoader(feature_dataset, shuffle=False, drop_last=False, batch_size=len(feature_un_dataset))  # len(feature_un_dataset)"
      ],
      "metadata": {
        "id": "jLAB7R1SqVqE"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_feats_with_noise(feats_vae, unseen_attr, samples_per_class=1000):\n",
        "    feats_vae.eval()\n",
        "    #feats_vae.to()\n",
        "    feats_vae.to(torch.device('cuda:0'))\n",
        "    #z_dist = normal.Normal(0, 1)\n",
        "    ground_truths = list(range(len(unseen_attr)))*samples_per_class\n",
        "    uns_atr = torch.from_numpy(np.array(unseen_attr)[ground_truths]).float().cuda() #to(torch.float32)\n",
        "    #attr = torch.from_numpy(attributes[label])\n",
        "    #attr = attr.repeat(ind_count, 1)\n",
        "\n",
        "    z_dist = normal.Normal(0, 1)\n",
        "    Z = z_dist.sample((samples_per_class*len(unseen_attr), 2048)).cuda()\n",
        "\n",
        "    mu, logvar, recon_feats = feats_vae(Z, uns_atr)\n",
        "    return ground_truths, recon_feats\n",
        "\n",
        "noise_gt, noise_feats = generate_feats_with_noise(feats_vae, attr)\n",
        "print(noise_feats.size())\n",
        "print(np.shape(noise_gt))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DU5ajTXEoE1i",
        "outputId": "faab93fd-ceeb-40a8-cc00-717fc767b099"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([40000, 2048])\n",
            "(40000,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "noise_feats = noise_feats.cpu().detach().numpy()\n",
        "noise_gt = np.array(noise_gt)\n",
        "recon_noise = {\"reconstructed_noise\" : noise_feats, \"labels\" : noise_gt}\n",
        "scipy.io.savemat(\"reconstructed_noise.mat\", recon_noise)"
      ],
      "metadata": {
        "id": "hMkp_2J03TAG"
      },
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#feature_loader = torch.utils.data.DataLoader(feature_dataset, shuffle=True, pin_memory=True, drop_last=False, batch_size=len(feature_un_dataset))\n",
        "\n",
        "def generate_feats_with_image(feats_vae, data, labels, attrib):\n",
        "    feats_vae.eval()\n",
        "    #feats_vae.to()\n",
        "    feats_vae.to(torch.device('cuda:0'))\n",
        "    ground_truths = labels\n",
        "    #print(torch.from_numpy(np.array((attr)[label])).to(torch.float32)\n",
        "    #uns_atr = torch.from_numpy(np.array(attr)[label]).to(torch.float32)\n",
        "    attrib = torch.from_numpy(np.array((attrib)[labels])).to(torch.float32).cuda()\n",
        "    #print(uns_atr.shape)\n",
        "    #print(data.shape)\n",
        "    #print(uns_atr.shape)\n",
        "    data = torch.from_numpy(data).cuda()\n",
        "    mu, logvar, recon_feats = feats_vae(data, attrib)\n",
        "    #print(recon_feats.shape)\n",
        "    #ground_truths = ground_truths.cpu().detach().numpy()\n",
        "    recon_feats = recon_feats.cpu().detach().numpy()\n",
        "\n",
        "    return ground_truths, recon_feats\n",
        "\n",
        "image_gt, image_feats = generate_feats_with_image(feats_vae, data_train, data_train_label, attr)\n",
        "print(image_feats.shape)\n",
        "print(image_gt.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fNd_6dzVqsmH",
        "outputId": "88fb6a2c-9b03-44fe-a711-06b98a78542d"
      },
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(19832, 2048)\n",
            "(19832,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "recon_image = {\"reconstructed_image\" : image_feats, \"labels\" : image_gt}\n",
        "scipy.io.savemat(\"reconstructed_image.mat\", recon_image)"
      ],
      "metadata": {
        "id": "wjkGgelx5UrV"
      },
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!cp /content/reconstructed_noise.mat /content/gdrive/MyDrive/generated_data"
      ],
      "metadata": {
        "id": "8yopX_sE68P8"
      },
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!cp /content/reconstructed_image.mat /content/gdrive/MyDrive/generated_data"
      ],
      "metadata": {
        "id": "9qFR09JF8alF"
      },
      "execution_count": 52,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "NHxcw62PSINk"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}