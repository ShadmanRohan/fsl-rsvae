{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyN9DvxnDTHcKH+8oEiO556l",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ShadmanRohan/fsl-rsvae/blob/main/starter.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 93,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9Fkr40LMo7uc",
        "outputId": "bc4c6e55-f4db-4e44-a92f-21945004a736"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fatal: destination path 'fsl-rsvae' already exists and is not an empty directory.\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/ShadmanRohan/fsl-rsvae.git"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4ktupjgODfja",
        "outputId": "219b1775-1356-400d-e4f6-64580adf868b"
      },
      "execution_count": 94,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from distutils.dir_util import copy_tree\n",
        "copy_tree(\"/content/gdrive/MyDrive/PAMI/AWA1_AWA2_SUN/data/AWA1\", \"/content/fsl-rsvae/datasets/AWA1\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IEef9zeLD52b",
        "outputId": "49bae03b-7d87-42eb-9cd2-d6a03842a6c3"
      },
      "execution_count": 95,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['/content/fsl-rsvae/datasets/AWA1/seen_test.mat',\n",
              " '/content/fsl-rsvae/datasets/AWA1/seen_attribute.mat',\n",
              " '/content/fsl-rsvae/datasets/AWA1/seen_test_label.mat',\n",
              " '/content/fsl-rsvae/datasets/AWA1/seen_train.mat',\n",
              " '/content/fsl-rsvae/datasets/AWA1/unseen_attribute.mat',\n",
              " '/content/fsl-rsvae/datasets/AWA1/seen_train_label.mat',\n",
              " '/content/fsl-rsvae/datasets/AWA1/unseen_test.mat',\n",
              " '/content/fsl-rsvae/datasets/AWA1/unseen_test_label.mat']"
            ]
          },
          "metadata": {},
          "execution_count": 95
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import argparse\n",
        "import numpy as np\n",
        "from torch.autograd import Variable\n",
        "#from torchvision.datasets.folder import DatasetFolder\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torch.distributions import uniform, normal\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from matplotlib import pyplot as plt\n",
        "import torch.optim\n",
        "import json\n",
        "import torch.utils.data.sampler\n",
        "import os\n",
        "import glob\n",
        "import random\n",
        "import time\n",
        "import pdb\n",
        "import yaml\n",
        "#import datasets.feature_loader as feat_loader\n",
        "from sklearn.manifold import TSNE\n",
        "import h5py\n",
        "from scipy.stats import multivariate_normal\n",
        "import scipy"
      ],
      "metadata": {
        "id": "k8kzzG1xpNSE"
      },
      "execution_count": 96,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def finetune_vae(feats_vae, x_shot, label_real):\n",
        "    attributes = np.load('./mini_attr.npy')\n",
        "    x_shot = x_shot.detach()\n",
        "    z_dist = normal.Normal(0, 1)\n",
        "    bs_list = np.arange(4)\n",
        "    feats_vae.train()\n",
        "    optimizer = torch.optim.Adam(feats_vae.parameters(), lr=0.0001)\n",
        "    for ep in range(5):\n",
        "      np.random.shuffle(bs_list)\n",
        "      for idx in bs_list:\n",
        "        targets = x_shot[idx]\n",
        "        labels_sel = label_real[idx] + 80\n",
        "        attr = torch.from_numpy(attributes[labels_sel]).float().cuda()\n",
        "        attr = attr.repeat((1, 50)).reshape((5, 50, -1))\n",
        "        Z = z_dist.sample((5, 50, 512)).cuda()\n",
        "        concat_feats = torch.cat((Z, attr), dim=2)\n",
        "        concat_feats = torch.autograd.Variable(concat_feats, requires_grad=True)\n",
        "        feats = feats_vae.model(concat_feats).reshape((-1, 512))\n",
        "        feats = feats_vae.relu(feats_vae.bn1(feats)).reshape((5, 50, 512))\n",
        "        feats = feats.mean(1)\n",
        "        feats = F.normalize(feats, dim=-1)\n",
        "        mse_loss = F.mse_loss(feats, targets)\n",
        "        optimizer.zero_grad()\n",
        "        mse_loss.backward()\n",
        "        optimizer.step()\n",
        "        print(mse_loss.item())"
      ],
      "metadata": {
        "id": "diZ7mTLrpE2Y"
      },
      "execution_count": 97,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def shrink_feats(cl_data_file):\n",
        "    cl_mean_file = {}\n",
        "    weight_data_file = {}\n",
        "    for k, v in cl_data_file.items():\n",
        "        mean_feats = np.mean(v, 0)\n",
        "        cl_mean_file[k] = mean_feats / np.sqrt(np.sum(mean_feats*mean_feats))\n",
        "    for k, v in cl_data_file.items():\n",
        "        v = np.array(v)\n",
        "        v = v / np.sqrt(np.sum(v*v, -1, keepdims=True))\n",
        "        dist = np.sum((v - cl_mean_file[k])**2, 1)\n",
        "        sort_idx = np.argsort(dist)\n",
        "        in_idx = sort_idx[:50]\n",
        "        out_idx = sort_idx[50:200]\n",
        "        in_feats = v[in_idx]\n",
        "        out_feats = v[out_idx]\n",
        "        cl_data_file[k] = []\n",
        "        for in_f in in_feats:\n",
        "          cl_data_file[k].append(in_f)\n",
        "        for o_idx in out_idx:\n",
        "          close_feats = (v[o_idx] + cl_mean_file[k]) / 2\n",
        "          close_dist = np.sum((in_feats - close_feats)**2, -1)\n",
        "          min_idx = np.argsort(close_dist)[0]\n",
        "          cl_data_file[k].append(in_feats[min_idx])\n",
        "    pdb.set_trace()\n",
        "    return cl_data_file\n",
        "\n",
        "def det(matrix):\n",
        "    order=len(matrix)\n",
        "    posdet=0\n",
        "    for i in range(order):\n",
        "        posdet+=reduce((lambda x, y: x * y), [matrix[(i+j)%order][j] for j in range(order)])\n",
        "    negdet=0\n",
        "    for i in range(order):\n",
        "        negdet+=reduce((lambda x, y: x * y), [matrix[(order-i-j)%order][j] for j in range(order)])\n",
        "    return posdet-negdet\n",
        "\n",
        "\n",
        "def remove_feats(cl_data_file):\n",
        "    cl_mean_file = {}\n",
        "    cl_var_file = {}\n",
        "    weight_data_file = {}\n",
        "    remove_num = []\n",
        "    for k, v in cl_data_file.items():\n",
        "        mean_feats = np.mean(v, 0)\n",
        "        cl_mean_file[k] = mean_feats\n",
        "        cl_var_file[k] = np.cov(np.array(v).T)\n",
        "    for k, v in cl_data_file.items():\n",
        "        v = np.array(v)\n",
        "        #dist = np.sum((v - cl_mean_file[k])**2, 1)\n",
        "        #sort_idx = np.argsort(dist)[:220]\n",
        "        cl_data_file[k] = []\n",
        "        #weight_data_file[k] = []\n",
        "        inv_var = scipy.linalg.inv(cl_var_file[k])\n",
        "        mean = cl_mean_file[k]\n",
        "        prob = np.sum(np.matmul((v-mean),inv_var)*(v-mean), -1)\n",
        "        prob = 1-scipy.stats.chi2.cdf(prob, 512)\n",
        "        #rv = multivariate_normal(mean = cl_mean_file[k], cov = cl_var_file[k])\n",
        "        for idx in range(600):\n",
        "          if prob[idx] > 0.9:\n",
        "            cl_data_file[k].append(v[idx]) \n",
        "        remove_num.append(np.sum(prob<0.9))\n",
        "        #for sidx in sort_idx:\n",
        "        #  cl_data_file[k].append(v[sidx])\n",
        "        #  cl_data_file[k].append((cl_mean_file[k] + (np.random.normal(v[sidx].shape)*0.001)).astype(np.float32))\n",
        "        #  weight_data_file[k].append(1./dist[sidx])\n",
        "        #all_feats = (np.random.multivariate_normal(mean=cl_mean_file[k], cov=cl_var_file[k], size=200)).astype(np.float32)\n",
        "        #for all_feat in all_feats:\n",
        "        #  cl_data_file[k].append(all_feat*0.3 + cl_mean_file[k]*0.7)\n",
        "    pdb.set_trace()\n",
        "    return cl_data_file\n",
        "\n",
        "def interpolate_feats(cl_data_file):\n",
        "    cl_mean_file = {}\n",
        "    for k, v in cl_data_file.items():\n",
        "        mean_feats = np.mean(v, 0)\n",
        "        cl_mean_file[k] = mean_feats\n",
        "    for k, v in cl_data_file.items():\n",
        "        v = np.array(v) \n",
        "        dist = np.sum((v - cl_mean_file[k])**2, 1)\n",
        "        cl_data_file[k] = []\n",
        "        for iv in v:\n",
        "          cl_data_file[k].append(0.6*iv+0.4*cl_mean_file[k])\n",
        "\n",
        "    return cl_data_file\n",
        "\n",
        "def get_vae_center(out_dir, split='train', use_mean=True):\n",
        "    attr_out_file = os.path.join(out_dir, '%s_attr.hdf5'%split)\n",
        "    vae_data_file = feat_loader.init_loader(attr_out_file)\n",
        "    if 'train' in split:\n",
        "      num = 64\n",
        "    else:\n",
        "      num = 20\n",
        "    if use_mean:\n",
        "      vae_feats_all = torch.zeros((num, 512))\n",
        "    else:\n",
        "      vae_feats_all = torch.zeros((num, 20, 512))\n",
        "    mean_data_file = {}\n",
        "\n",
        "    for k, feats in vae_data_file.items():\n",
        "        mean_feats = np.mean(feats, 0)\n",
        "        mean_data_file[k] = mean_feats\n",
        "\n",
        "    for k, feats in vae_data_file.items():\n",
        "        #mean_feats = np.array(feats)[:50]\n",
        "        #mean_feats = 3*mean_feats - 2*mean_data_file[k]\n",
        "        if use_mean:\n",
        "          mean_feats = np.mean(feats, 0)\n",
        "        else:\n",
        "          mean_feats = np.array(feats)[:20]\n",
        "        mean_feats = torch.from_numpy(mean_feats)\n",
        "        mean_feats = F.normalize(mean_feats, dim=-1) \n",
        "        if 'test' in split: \n",
        "          k = k - 80\n",
        "        vae_feats_all[k] = mean_feats\n",
        "  \n",
        "    return vae_feats_all\n",
        "\n",
        "\n",
        "def generate_feats(feats_vae, attributes, output_file, label_list):\n",
        "    f = h5py.File(output_file, 'w')\n",
        "    ind_count = 500\n",
        "    max_count = ind_count * len(label_list)\n",
        "    all_labels = f.create_dataset('all_labels',(max_count,), dtype='i')\n",
        "    all_feats=None\n",
        "    count=0\n",
        "    feats_vae.eval()\n",
        "    z_dist = normal.Normal(0, 1)\n",
        "    for label in label_list:\n",
        "        attr = torch.from_numpy(attributes[label]).float().cuda()\n",
        "        attr = attr.repeat(ind_count, 1)\n",
        "        Z = z_dist.sample((ind_count, 512)).cuda()\n",
        "        concat_feats = torch.cat((Z, attr), dim=1)\n",
        "        feats = feats_vae.model(concat_feats)\n",
        "        feats = feats_vae.relu(feats_vae.bn1(feats))\n",
        "        if all_feats is None:      \n",
        "          all_feats = f.create_dataset('all_feats', [max_count] + list(feats.size()[1:]) , dtype='f')\n",
        "        all_feats[count:count+feats.size(0)] = feats.data.cpu().numpy()\n",
        "        all_labels[count:count+feats.size(0)] = np.array([label]*ind_count)\n",
        "        count = count + feats.size(0)\n",
        "    count_var = f.create_dataset('count', (1,), dtype='i')\n",
        "    count_var[0] = count\n",
        "\n",
        "    f.close()\n",
        "\n",
        "\n",
        "def visualize_feats(feats_dir):\n",
        "    visual_feats = []\n",
        "    attr_feats = []\n",
        "    visual_labels = []\n",
        "    attr_labels = []\n",
        "    cl_data_file = os.path.join(feats_dir, 'test.hdf5')\n",
        "    cl_data_file = feat_loader.init_loader(cl_data_file)\n",
        "    vae_data_file = os.path.join(feats_dir, 'test_attr_ood.hdf5')\n",
        "    vae_data_file = feat_loader.init_loader(vae_data_file)\n",
        "    pdb.set_trace()\n",
        "    #labels = [51, 3, 179, 7, 11, 175] \n",
        "    #labels = [15,6,17,8,9]\n",
        "    labels = [85, 86, 87, 88, 89]\n",
        "    #labels = [13, 17, 21, 29, 33, 37]\n",
        "    tsne = TSNE(n_components=2, random_state=0)\n",
        "    for idx in range(5):\n",
        "        label = labels[idx]\n",
        "        visual_feats.extend(cl_data_file[label-80][:100])\n",
        "        #attr_feats.extend((vae_data_file[label][:300]))\n",
        "        #attr_feats.extend(np.mean(np.array(vae_data_file[label]), 0, keepdims=True))\n",
        "        visual_labels.extend([idx]*len(cl_data_file[label-80][:100]))\n",
        "        #attr_labels.extend([idx]*len(vae_data_file[label][:300]))\n",
        "        #attr_labels.extend([idx])\n",
        "    visual_feats = np.array(visual_feats)\n",
        "    #attr_feats = np.array(attr_feats)\n",
        "    #all_feats = np.concatenate((visual_feats, attr_feats), 0)\n",
        "    pdb.set_trace()\n",
        "    all_labels = visual_labels \n",
        "    all_feats = visual_feats\n",
        "    all_feats_2D = tsne.fit_transform(all_feats)\n",
        "    #all_feats_2D = tsne.fit_transform(visual_feats)\n",
        "    #all_labels = visual_labels\n",
        "    colors = np.array(['r', 'g', 'b', 'c', 'm', 'y', 'k',  'orange', 'purple'])      \n",
        "    for idx in range(all_feats_2D.shape[0]):\n",
        "        feat = all_feats_2D[idx]\n",
        "        #if feat[0] < -30 or feat[1] < -30:\n",
        "        #  continue\n",
        "        label = all_labels[idx]\n",
        "        color = colors[label]\n",
        "        if idx < visual_feats.shape[0]:\n",
        "          marker = '*'\n",
        "          #continue\n",
        "        else:\n",
        "          marker = 'o'\n",
        "          #continue\n",
        "        plt.scatter(feat[0], feat[1], c=color, marker=marker) \n",
        "    plt.savefig('features_base_mini.png')\n",
        "\n",
        "def save_vae_features(out_file, attr_out_dir):\n",
        "    cl_data_file = feat_loader.init_loader(out_file)\n",
        "    cl_data_file = remove_feats(cl_data_file)\n",
        "    feature_dataset = FeatureDataset(cl_data_file)\n",
        "    feature_loader = torch.utils.data.DataLoader(feature_dataset, shuffle=True, pin_memory=True, drop_last=False, batch_size=256) \n",
        "    attributes = np.load('./mini_attr.npy')\n",
        "    feats_vae = FeatsVAE(512, 512).cuda()\n",
        "    feats_vae = train_vae(feature_loader, feats_vae, attributes)\n",
        "    #feats_vae.load_state_dict(torch.load('feats_vae_mini.pth')['state'])\n",
        "    #torch.save({'state': feats_vae.state_dict()}, 'feats_vae_mini.pth') \n",
        "    generate_feats(feats_vae, attributes, os.path.join(attr_out_dir, 'train_attr.hdf5'), np.arange(0, 64))\n",
        "    generate_feats(feats_vae, attributes, os.path.join(attr_out_dir, 'test_attr.hdf5'), np.arange(80, 100))\n",
        "    #return feats_vae\n",
        "\n"
      ],
      "metadata": {
        "id": "xn3pYo2fpYek"
      },
      "execution_count": 98,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#/content/fsl-rsvae/configs/test_few_shot.yaml\n",
        "#config = yaml.load(open(args.config, 'r'), Loader=yaml.FullLoader)\n",
        "#out_dir = os.path.dirname(config['load_encoder'])\n",
        "#out_file = os.path.join(out_dir, 'features', 'test.hdf5')\n",
        "#cl_data_file = feat_loader.init_loader(out_file)\n",
        "#feature_dataset = FeatureDataset(cl_data_file)\n",
        "#feature_loader = torch.utils.data.DataLoader(feature_dataset, shuffle=True, pin_memory=True, drop_last=False, batch_size=256)\n",
        "\n",
        "#attributes = np.load('./mini_attr.npy')\n",
        "#feats_vae = FeatsVAE(512, 512).cuda()\n",
        "#train_vae(feature_loader, feats_vae, attributes)\n",
        "#generate_feats(feats_vae, attributes, os.path.join(out_dir, 'features', 'test_attr.hdf5'), np.arange(80, 100))\n",
        "#save_vae_features(out_file, out_dir)\n",
        "\n",
        "#vae_feats_file = os.path.join(out_dir, 'features', 'test_attr.hdf5')\n",
        "#vae_data_file = feat_loader.init_loader(vae_feats_file)\n",
        "#visualize_feats(cl_data_file, vae_data_file)\n"
      ],
      "metadata": {
        "id": "TcagUsiDDFXB"
      },
      "execution_count": 99,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import scipy.io\n",
        "#features\n",
        "data_train = scipy.io.loadmat('/content/fsl-rsvae/datasets/AWA1/seen_train.mat')\n",
        "data_train = data_train['feature']\n",
        "#data_train = np.transpose(data_train)\n",
        "\n",
        "\n",
        "# labels\n",
        "label_train = scipy.io.loadmat('/content/fsl-rsvae/datasets/AWA1/seen_train_label.mat')\n",
        "data_train_label = label_train['label'][0]\n",
        "\n",
        "\n",
        "# attr\n",
        "tmp = scipy.io.loadmat('/content/fsl-rsvae/datasets/AWA1/seen_attribute.mat')\n",
        "attr = tmp['seen_attribute']\n",
        "#attr = np.transpose(attr)"
      ],
      "metadata": {
        "id": "KWmLvTptFmf9"
      },
      "execution_count": 100,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class FeatureDataset(Dataset):\n",
        "\n",
        "    def __init__(self, features, labels, attr):\n",
        "        self.labels = labels\n",
        "        self.features = features\n",
        "        self.attr = attr\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(data_train)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        return self.features[idx], self.labels[idx]\n",
        "\n",
        "feature_dataset = FeatureDataset(data_train, data_train_label, attr)\n",
        "feature_loader = torch.utils.data.DataLoader(feature_dataset, shuffle=True, pin_memory=True, drop_last=False, batch_size=256) "
      ],
      "metadata": {
        "id": "OiH7f_bqFb3i"
      },
      "execution_count": 101,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class FeatsVAE(nn.Module):\n",
        "    def __init__(self, x_dim, latent_dim, bottle_neck):\n",
        "        super(FeatsVAE, self).__init__()\n",
        "\n",
        "        self.x_dim = x_dim\n",
        "        self.latent_dim = latent_dim\n",
        "        self.bn1 = nn.BatchNorm1d(x_dim)\n",
        "        self.relu = nn.ReLU(inplace=True)\n",
        "        self.z_dist = normal.Normal(0, 1)\n",
        "        self.init_weights()\n",
        "\n",
        "        self.linear = nn.Sequential(\n",
        "            nn.Linear(self.x_dim+self.latent_dim, bottle_neck),\n",
        "            #nn.LeakyReLU(),\n",
        "            #nn.Linear(1096, 2096),\n",
        "            nn.LeakyReLU())\n",
        "        self.linear_mu =  nn.Sequential(\n",
        "            nn.Linear(bottle_neck, latent_dim),\n",
        "            nn.ReLU())\n",
        "        self.linear_logvar =  nn.Sequential(\n",
        "            nn.Linear(bottle_neck, latent_dim),\n",
        "            nn.ReLU())\n",
        "        self.model = nn.Sequential(\n",
        "            nn.Linear(2*latent_dim, bottle_neck),\n",
        "            nn.LeakyReLU(),\n",
        "            #nn.Linear(4096, 4096),\n",
        "            #nn.LeakyReLU(),\n",
        "            nn.Linear(bottle_neck, x_dim),\n",
        "            #nn.Sigmoid(),\n",
        "        )\n",
        "        \n",
        "\n",
        "\n",
        "\n",
        "    def reparameterize(self, mu, logvar):\n",
        "        std = torch.exp(0.5*logvar)  \n",
        "        eps = torch.randn_like(std)\n",
        "        # remove abnormal points\n",
        "        return mu + eps*std\n",
        "\n",
        "    def init_weights(self):\n",
        "        for m in self.modules():\n",
        "          if isinstance(m, nn.Linear):\n",
        "              m.weight.data.normal_(0, 0.02)\n",
        "              m.bias.data.normal_(0, 0.02)\n",
        "\n",
        "    def forward(self, x, attr):\n",
        "        #print(x.size())\n",
        "        #print(attr.size())\n",
        "\n",
        "        x = torch.cat((x, attr), dim=1).to(torch.float32)\n",
        "        #print(x.size())\n",
        "        #print(self.x_dim+self.latent_dim)\n",
        "        \n",
        "        x = self.linear(x)\n",
        "        #print(x.size())\n",
        "        mu = self.linear_mu(x)\n",
        "        #print(x)\n",
        "        logvar = self.linear_logvar(x)\n",
        "        #print(logvar)\n",
        "        latent_feats = self.reparameterize(mu, logvar)\n",
        "        #Z = self.z_dist.sample(attr.shape).cuda() \n",
        "        concat_feats = torch.cat((latent_feats, attr), dim=1)\n",
        "        recon_feats = self.model(concat_feats)\n",
        "        recon_feats = self.relu(self.bn1(recon_feats))\n",
        "        return mu, logvar, recon_feats\n",
        "\n",
        "feats_vae = FeatsVAE(x_dim=2048, latent_dim=85, bottle_neck=96) # latent dim = attribute dim"
      ],
      "metadata": {
        "id": "QR8I-FHnK1gq"
      },
      "execution_count": 102,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train_vae(feature_loader, feats_vae, attributes):\n",
        "    optimizer = torch.optim.Adam(feats_vae.parameters(), lr=0.001)\n",
        "    #for ep in range(10):\n",
        "    for ep in range(2000):\n",
        "      loss_recon_all = 0\n",
        "      loss_kl_all = 0\n",
        "      for idx, (data, label) in enumerate(feature_loader):\n",
        "        print(\"training loop...\")\n",
        "        data = data\n",
        "        #weight = weight.cuda() / torch.sum(weight)\n",
        "        attr = torch.from_numpy(attributes[label]).float()\n",
        "        mu, logvar, recon_feats = feats_vae(data, attr)\n",
        "        recon_loss = ((recon_feats - data)**2).mean(1)\n",
        "        recon_loss = torch.mean(recon_loss)\n",
        "        #kl_loss = -0.5*torch.sum(1+logvar-logvar.exp()-mu.pow(2)) / data.shape[0]\n",
        "        kl_loss = (1+logvar-logvar.exp()-mu.pow(2)).sum(1)\n",
        "        kl_loss = -0.5*torch.mean(kl_loss)\n",
        "        L_vae = recon_loss+kl_loss\n",
        "        optimizer.zero_grad()\n",
        "        L_vae.backward()   \n",
        "        optimizer.step()\n",
        "        loss_recon_all += recon_loss.item()\n",
        "        loss_kl_all += kl_loss.item()\n",
        "        break\n",
        "      print('Ep: %d   Recon Loss: %f   KL Loss: %f'%(ep, loss_recon_all/(idx+1), loss_kl_all/(idx+1)))\n",
        "      print(recon_feats.shape)\n",
        "    return feats_vae\n",
        "    #torch.save({'state': feats_vae.state_dict()}, 'feats_vae_mini.pth') \n",
        "\n",
        "feats_vae = train_vae(feature_loader, feats_vae, attr)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JN9RRAsJNhzB",
        "outputId": "485ec785-6f3a-4bb9-d210-f5ffec7bd6f4"
      },
      "execution_count": 110,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1;30;43mStreaming output truncated to the last 5000 lines.\u001b[0m\n",
            "Ep: 333   Recon Loss: 0.385479   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 334   Recon Loss: 0.394832   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 335   Recon Loss: 0.412688   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 336   Recon Loss: 0.391238   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 337   Recon Loss: 0.408288   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 338   Recon Loss: 0.394347   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 339   Recon Loss: 0.387664   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 340   Recon Loss: 0.392206   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 341   Recon Loss: 0.380836   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 342   Recon Loss: 0.375373   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 343   Recon Loss: 0.395558   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 344   Recon Loss: 0.399023   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 345   Recon Loss: 0.386119   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 346   Recon Loss: 0.383486   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 347   Recon Loss: 0.395182   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 348   Recon Loss: 0.392398   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 349   Recon Loss: 0.408085   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 350   Recon Loss: 0.399508   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 351   Recon Loss: 0.392252   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 352   Recon Loss: 0.415430   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 353   Recon Loss: 0.400706   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 354   Recon Loss: 0.384776   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 355   Recon Loss: 0.382787   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 356   Recon Loss: 0.401251   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 357   Recon Loss: 0.409026   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 358   Recon Loss: 0.381657   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 359   Recon Loss: 0.407883   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 360   Recon Loss: 0.387304   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 361   Recon Loss: 0.400305   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 362   Recon Loss: 0.382718   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 363   Recon Loss: 0.383963   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 364   Recon Loss: 0.375840   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 365   Recon Loss: 0.392659   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 366   Recon Loss: 0.389173   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 367   Recon Loss: 0.397355   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 368   Recon Loss: 0.384213   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 369   Recon Loss: 0.406291   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 370   Recon Loss: 0.375604   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 371   Recon Loss: 0.390591   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 372   Recon Loss: 0.407012   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 373   Recon Loss: 0.400539   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 374   Recon Loss: 0.397373   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 375   Recon Loss: 0.379269   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 376   Recon Loss: 0.400149   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 377   Recon Loss: 0.390081   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 378   Recon Loss: 0.386863   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 379   Recon Loss: 0.386018   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 380   Recon Loss: 0.378442   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 381   Recon Loss: 0.401994   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 382   Recon Loss: 0.374435   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 383   Recon Loss: 0.389381   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 384   Recon Loss: 0.382169   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 385   Recon Loss: 0.373113   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 386   Recon Loss: 0.397280   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 387   Recon Loss: 0.409898   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 388   Recon Loss: 0.395329   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 389   Recon Loss: 0.404233   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 390   Recon Loss: 0.399978   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 391   Recon Loss: 0.391633   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 392   Recon Loss: 0.410236   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 393   Recon Loss: 0.401516   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 394   Recon Loss: 0.387209   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 395   Recon Loss: 0.393543   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 396   Recon Loss: 0.380891   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 397   Recon Loss: 0.389898   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 398   Recon Loss: 0.374651   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 399   Recon Loss: 0.392149   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 400   Recon Loss: 0.377745   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 401   Recon Loss: 0.389363   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 402   Recon Loss: 0.387435   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 403   Recon Loss: 0.384749   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 404   Recon Loss: 0.377220   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 405   Recon Loss: 0.374003   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 406   Recon Loss: 0.377915   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 407   Recon Loss: 0.386528   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 408   Recon Loss: 0.377292   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 409   Recon Loss: 0.390303   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 410   Recon Loss: 0.384878   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 411   Recon Loss: 0.382229   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 412   Recon Loss: 0.391121   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 413   Recon Loss: 0.374690   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 414   Recon Loss: 0.379829   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 415   Recon Loss: 0.386736   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 416   Recon Loss: 0.387214   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 417   Recon Loss: 0.357292   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 418   Recon Loss: 0.392718   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 419   Recon Loss: 0.413041   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 420   Recon Loss: 0.364550   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 421   Recon Loss: 0.390236   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 422   Recon Loss: 0.421715   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 423   Recon Loss: 0.381583   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 424   Recon Loss: 0.415810   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 425   Recon Loss: 0.390315   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 426   Recon Loss: 0.370376   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 427   Recon Loss: 0.394378   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 428   Recon Loss: 0.370165   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 429   Recon Loss: 0.399520   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 430   Recon Loss: 0.382059   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 431   Recon Loss: 0.387292   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 432   Recon Loss: 0.397638   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 433   Recon Loss: 0.363156   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 434   Recon Loss: 0.374512   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 435   Recon Loss: 0.377312   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 436   Recon Loss: 0.383523   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 437   Recon Loss: 0.369991   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 438   Recon Loss: 0.391448   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 439   Recon Loss: 0.379682   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 440   Recon Loss: 0.384973   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 441   Recon Loss: 0.382353   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 442   Recon Loss: 0.381994   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 443   Recon Loss: 0.379752   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 444   Recon Loss: 0.375621   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 445   Recon Loss: 0.383656   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 446   Recon Loss: 0.388881   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 447   Recon Loss: 0.359303   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 448   Recon Loss: 0.373998   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 449   Recon Loss: 0.393187   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 450   Recon Loss: 0.374868   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 451   Recon Loss: 0.368119   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 452   Recon Loss: 0.398300   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 453   Recon Loss: 0.377449   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 454   Recon Loss: 0.386312   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 455   Recon Loss: 0.385715   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 456   Recon Loss: 0.394248   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 457   Recon Loss: 0.381921   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 458   Recon Loss: 0.375835   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 459   Recon Loss: 0.386875   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 460   Recon Loss: 0.393010   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 461   Recon Loss: 0.387559   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 462   Recon Loss: 0.381523   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 463   Recon Loss: 0.378956   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 464   Recon Loss: 0.375181   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 465   Recon Loss: 0.372381   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 466   Recon Loss: 0.378311   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 467   Recon Loss: 0.384333   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 468   Recon Loss: 0.381046   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 469   Recon Loss: 0.401740   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 470   Recon Loss: 0.395996   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 471   Recon Loss: 0.380182   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 472   Recon Loss: 0.393919   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 473   Recon Loss: 0.391187   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 474   Recon Loss: 0.405595   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 475   Recon Loss: 0.396462   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 476   Recon Loss: 0.379711   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 477   Recon Loss: 0.375865   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 478   Recon Loss: 0.377332   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 479   Recon Loss: 0.363680   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 480   Recon Loss: 0.380169   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 481   Recon Loss: 0.385982   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 482   Recon Loss: 0.381708   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 483   Recon Loss: 0.365264   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 484   Recon Loss: 0.386125   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 485   Recon Loss: 0.379780   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 486   Recon Loss: 0.370090   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 487   Recon Loss: 0.379007   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 488   Recon Loss: 0.385566   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 489   Recon Loss: 0.405619   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 490   Recon Loss: 0.377934   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 491   Recon Loss: 0.378944   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 492   Recon Loss: 0.369873   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 493   Recon Loss: 0.384413   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 494   Recon Loss: 0.366317   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 495   Recon Loss: 0.385050   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 496   Recon Loss: 0.369064   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 497   Recon Loss: 0.416561   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 498   Recon Loss: 0.373807   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 499   Recon Loss: 0.366963   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 500   Recon Loss: 0.382096   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 501   Recon Loss: 0.401407   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 502   Recon Loss: 0.382829   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 503   Recon Loss: 0.387400   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 504   Recon Loss: 0.371556   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 505   Recon Loss: 0.370200   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 506   Recon Loss: 0.377339   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 507   Recon Loss: 0.357392   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 508   Recon Loss: 0.401686   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 509   Recon Loss: 0.397060   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 510   Recon Loss: 0.389734   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 511   Recon Loss: 0.389594   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 512   Recon Loss: 0.401270   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 513   Recon Loss: 0.369813   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 514   Recon Loss: 0.375499   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 515   Recon Loss: 0.383216   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 516   Recon Loss: 0.389279   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 517   Recon Loss: 0.367144   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 518   Recon Loss: 0.395762   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 519   Recon Loss: 0.393438   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 520   Recon Loss: 0.395947   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 521   Recon Loss: 0.375572   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 522   Recon Loss: 0.383592   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 523   Recon Loss: 0.383960   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 524   Recon Loss: 0.355966   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 525   Recon Loss: 0.386353   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 526   Recon Loss: 0.390260   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 527   Recon Loss: 0.380070   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 528   Recon Loss: 0.374987   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 529   Recon Loss: 0.394567   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 530   Recon Loss: 0.395979   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 531   Recon Loss: 0.381724   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 532   Recon Loss: 0.394412   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 533   Recon Loss: 0.373104   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 534   Recon Loss: 0.380893   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 535   Recon Loss: 0.369984   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 536   Recon Loss: 0.369322   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 537   Recon Loss: 0.389559   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 538   Recon Loss: 0.387215   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 539   Recon Loss: 0.386565   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 540   Recon Loss: 0.389851   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 541   Recon Loss: 0.387687   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 542   Recon Loss: 0.363520   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 543   Recon Loss: 0.362549   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 544   Recon Loss: 0.396007   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 545   Recon Loss: 0.383781   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 546   Recon Loss: 0.373934   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 547   Recon Loss: 0.376638   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 548   Recon Loss: 0.382359   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 549   Recon Loss: 0.366725   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 550   Recon Loss: 0.385018   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 551   Recon Loss: 0.400632   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 552   Recon Loss: 0.406368   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 553   Recon Loss: 0.369625   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 554   Recon Loss: 0.382294   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 555   Recon Loss: 0.390094   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 556   Recon Loss: 0.378849   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 557   Recon Loss: 0.383635   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 558   Recon Loss: 0.378264   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 559   Recon Loss: 0.384570   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 560   Recon Loss: 0.383151   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 561   Recon Loss: 0.387587   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 562   Recon Loss: 0.384258   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 563   Recon Loss: 0.371332   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 564   Recon Loss: 0.386626   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 565   Recon Loss: 0.398148   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 566   Recon Loss: 0.374852   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 567   Recon Loss: 0.368670   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 568   Recon Loss: 0.383432   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 569   Recon Loss: 0.368337   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 570   Recon Loss: 0.360661   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 571   Recon Loss: 0.364652   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 572   Recon Loss: 0.363611   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 573   Recon Loss: 0.378559   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 574   Recon Loss: 0.388768   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 575   Recon Loss: 0.361350   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 576   Recon Loss: 0.374888   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 577   Recon Loss: 0.374837   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 578   Recon Loss: 0.374800   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 579   Recon Loss: 0.351821   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 580   Recon Loss: 0.376101   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 581   Recon Loss: 0.407205   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 582   Recon Loss: 0.362849   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 583   Recon Loss: 0.382655   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 584   Recon Loss: 0.376221   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 585   Recon Loss: 0.370190   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 586   Recon Loss: 0.393771   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 587   Recon Loss: 0.392248   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 588   Recon Loss: 0.383517   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 589   Recon Loss: 0.365070   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 590   Recon Loss: 0.384335   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 591   Recon Loss: 0.388008   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 592   Recon Loss: 0.384719   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 593   Recon Loss: 0.393451   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 594   Recon Loss: 0.390675   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 595   Recon Loss: 0.382239   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 596   Recon Loss: 0.381074   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 597   Recon Loss: 0.361992   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 598   Recon Loss: 0.365057   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 599   Recon Loss: 0.380370   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 600   Recon Loss: 0.398258   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 601   Recon Loss: 0.382763   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 602   Recon Loss: 0.372151   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 603   Recon Loss: 0.385761   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 604   Recon Loss: 0.396144   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 605   Recon Loss: 0.375604   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 606   Recon Loss: 0.395003   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 607   Recon Loss: 0.374352   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 608   Recon Loss: 0.368001   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 609   Recon Loss: 0.391273   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 610   Recon Loss: 0.372116   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 611   Recon Loss: 0.383948   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 612   Recon Loss: 0.399694   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 613   Recon Loss: 0.389236   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 614   Recon Loss: 0.384890   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 615   Recon Loss: 0.374485   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 616   Recon Loss: 0.367542   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 617   Recon Loss: 0.381878   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 618   Recon Loss: 0.390492   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 619   Recon Loss: 0.386513   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 620   Recon Loss: 0.371404   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 621   Recon Loss: 0.378766   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 622   Recon Loss: 0.405194   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 623   Recon Loss: 0.383608   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 624   Recon Loss: 0.376635   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 625   Recon Loss: 0.359121   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 626   Recon Loss: 0.359512   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 627   Recon Loss: 0.362614   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 628   Recon Loss: 0.375580   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 629   Recon Loss: 0.384313   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 630   Recon Loss: 0.400342   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 631   Recon Loss: 0.386423   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 632   Recon Loss: 0.365924   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 633   Recon Loss: 0.384238   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 634   Recon Loss: 0.378261   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 635   Recon Loss: 0.374613   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 636   Recon Loss: 0.399276   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 637   Recon Loss: 0.375466   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 638   Recon Loss: 0.400316   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 639   Recon Loss: 0.375137   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 640   Recon Loss: 0.377339   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 641   Recon Loss: 0.373792   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 642   Recon Loss: 0.393546   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 643   Recon Loss: 0.384883   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 644   Recon Loss: 0.368974   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 645   Recon Loss: 0.381548   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 646   Recon Loss: 0.365245   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 647   Recon Loss: 0.379444   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 648   Recon Loss: 0.379887   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 649   Recon Loss: 0.370606   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 650   Recon Loss: 0.371602   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 651   Recon Loss: 0.397704   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 652   Recon Loss: 0.392596   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 653   Recon Loss: 0.369160   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 654   Recon Loss: 0.380439   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 655   Recon Loss: 0.365570   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 656   Recon Loss: 0.377355   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 657   Recon Loss: 0.344346   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 658   Recon Loss: 0.380473   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 659   Recon Loss: 0.369541   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 660   Recon Loss: 0.360181   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 661   Recon Loss: 0.382010   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 662   Recon Loss: 0.361240   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 663   Recon Loss: 0.371055   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 664   Recon Loss: 0.370041   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 665   Recon Loss: 0.382654   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 666   Recon Loss: 0.389997   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 667   Recon Loss: 0.384425   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 668   Recon Loss: 0.384433   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 669   Recon Loss: 0.357261   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 670   Recon Loss: 0.375025   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 671   Recon Loss: 0.369370   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 672   Recon Loss: 0.357047   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 673   Recon Loss: 0.367645   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 674   Recon Loss: 0.394185   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 675   Recon Loss: 0.385233   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 676   Recon Loss: 0.371337   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 677   Recon Loss: 0.394587   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 678   Recon Loss: 0.419426   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 679   Recon Loss: 0.378650   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 680   Recon Loss: 0.376853   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 681   Recon Loss: 0.358085   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 682   Recon Loss: 0.384460   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 683   Recon Loss: 0.386831   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 684   Recon Loss: 0.372840   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 685   Recon Loss: 0.374605   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 686   Recon Loss: 0.374471   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 687   Recon Loss: 0.395078   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 688   Recon Loss: 0.375868   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 689   Recon Loss: 0.384830   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 690   Recon Loss: 0.371800   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 691   Recon Loss: 0.381215   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 692   Recon Loss: 0.369620   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 693   Recon Loss: 0.390943   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 694   Recon Loss: 0.385626   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 695   Recon Loss: 0.394529   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 696   Recon Loss: 0.368611   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 697   Recon Loss: 0.391192   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 698   Recon Loss: 0.390121   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 699   Recon Loss: 0.387812   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 700   Recon Loss: 0.368127   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 701   Recon Loss: 0.377201   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 702   Recon Loss: 0.379817   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 703   Recon Loss: 0.374986   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 704   Recon Loss: 0.388716   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 705   Recon Loss: 0.372701   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 706   Recon Loss: 0.366463   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 707   Recon Loss: 0.369045   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 708   Recon Loss: 0.364480   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 709   Recon Loss: 0.381598   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 710   Recon Loss: 0.375726   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 711   Recon Loss: 0.399899   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 712   Recon Loss: 0.353689   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 713   Recon Loss: 0.387448   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 714   Recon Loss: 0.392174   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 715   Recon Loss: 0.374830   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 716   Recon Loss: 0.371357   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 717   Recon Loss: 0.375494   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 718   Recon Loss: 0.374846   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 719   Recon Loss: 0.373612   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 720   Recon Loss: 0.394401   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 721   Recon Loss: 0.362089   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 722   Recon Loss: 0.375040   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 723   Recon Loss: 0.395743   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 724   Recon Loss: 0.387378   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 725   Recon Loss: 0.365063   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 726   Recon Loss: 0.382087   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 727   Recon Loss: 0.365135   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 728   Recon Loss: 0.403338   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 729   Recon Loss: 0.387103   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 730   Recon Loss: 0.375988   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 731   Recon Loss: 0.373712   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 732   Recon Loss: 0.381792   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 733   Recon Loss: 0.359622   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 734   Recon Loss: 0.396499   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 735   Recon Loss: 0.358062   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 736   Recon Loss: 0.382967   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 737   Recon Loss: 0.379086   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 738   Recon Loss: 0.383067   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 739   Recon Loss: 0.392746   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 740   Recon Loss: 0.371489   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 741   Recon Loss: 0.356486   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 742   Recon Loss: 0.383899   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 743   Recon Loss: 0.363238   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 744   Recon Loss: 0.392959   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 745   Recon Loss: 0.359352   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 746   Recon Loss: 0.365776   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 747   Recon Loss: 0.355199   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 748   Recon Loss: 0.371206   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 749   Recon Loss: 0.400897   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 750   Recon Loss: 0.375965   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 751   Recon Loss: 0.382499   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 752   Recon Loss: 0.381012   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 753   Recon Loss: 0.377896   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 754   Recon Loss: 0.397188   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 755   Recon Loss: 0.376613   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 756   Recon Loss: 0.361067   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 757   Recon Loss: 0.380950   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 758   Recon Loss: 0.381104   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 759   Recon Loss: 0.372304   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 760   Recon Loss: 0.380540   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 761   Recon Loss: 0.374055   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 762   Recon Loss: 0.375063   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 763   Recon Loss: 0.367922   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 764   Recon Loss: 0.383948   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 765   Recon Loss: 0.362202   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 766   Recon Loss: 0.375778   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 767   Recon Loss: 0.362848   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 768   Recon Loss: 0.375465   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 769   Recon Loss: 0.386315   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 770   Recon Loss: 0.373246   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 771   Recon Loss: 0.370954   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 772   Recon Loss: 0.369588   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 773   Recon Loss: 0.382679   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 774   Recon Loss: 0.367858   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 775   Recon Loss: 0.385691   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 776   Recon Loss: 0.366822   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 777   Recon Loss: 0.362981   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 778   Recon Loss: 0.377281   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 779   Recon Loss: 0.376334   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 780   Recon Loss: 0.355623   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 781   Recon Loss: 0.367905   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 782   Recon Loss: 0.372854   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 783   Recon Loss: 0.380309   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 784   Recon Loss: 0.379328   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 785   Recon Loss: 0.371142   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 786   Recon Loss: 0.376696   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 787   Recon Loss: 0.387449   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 788   Recon Loss: 0.389622   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 789   Recon Loss: 0.358767   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 790   Recon Loss: 0.399738   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 791   Recon Loss: 0.379878   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 792   Recon Loss: 0.361952   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 793   Recon Loss: 0.375036   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 794   Recon Loss: 0.388626   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 795   Recon Loss: 0.375358   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 796   Recon Loss: 0.370182   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 797   Recon Loss: 0.364184   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 798   Recon Loss: 0.390269   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 799   Recon Loss: 0.375000   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 800   Recon Loss: 0.368865   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 801   Recon Loss: 0.366574   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 802   Recon Loss: 0.373009   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 803   Recon Loss: 0.388702   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 804   Recon Loss: 0.357621   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 805   Recon Loss: 0.380159   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 806   Recon Loss: 0.380246   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 807   Recon Loss: 0.376967   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 808   Recon Loss: 0.368986   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 809   Recon Loss: 0.346614   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 810   Recon Loss: 0.369452   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 811   Recon Loss: 0.376263   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 812   Recon Loss: 0.367906   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 813   Recon Loss: 0.396964   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 814   Recon Loss: 0.387567   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 815   Recon Loss: 0.373807   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 816   Recon Loss: 0.370606   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 817   Recon Loss: 0.360088   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 818   Recon Loss: 0.391249   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 819   Recon Loss: 0.368378   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 820   Recon Loss: 0.378904   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 821   Recon Loss: 0.390543   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 822   Recon Loss: 0.387895   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 823   Recon Loss: 0.374239   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 824   Recon Loss: 0.374054   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 825   Recon Loss: 0.355661   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 826   Recon Loss: 0.386612   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 827   Recon Loss: 0.391384   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 828   Recon Loss: 0.382045   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 829   Recon Loss: 0.359984   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 830   Recon Loss: 0.363583   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 831   Recon Loss: 0.391899   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 832   Recon Loss: 0.377569   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 833   Recon Loss: 0.376243   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 834   Recon Loss: 0.371924   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 835   Recon Loss: 0.393823   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 836   Recon Loss: 0.374557   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 837   Recon Loss: 0.364971   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 838   Recon Loss: 0.398456   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 839   Recon Loss: 0.397539   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 840   Recon Loss: 0.393426   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 841   Recon Loss: 0.379266   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 842   Recon Loss: 0.374418   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 843   Recon Loss: 0.386246   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 844   Recon Loss: 0.367244   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 845   Recon Loss: 0.373862   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 846   Recon Loss: 0.363142   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 847   Recon Loss: 0.399514   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 848   Recon Loss: 0.384783   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 849   Recon Loss: 0.359210   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 850   Recon Loss: 0.374984   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 851   Recon Loss: 0.406311   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 852   Recon Loss: 0.375760   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 853   Recon Loss: 0.386360   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 854   Recon Loss: 0.365499   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 855   Recon Loss: 0.371306   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 856   Recon Loss: 0.384499   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 857   Recon Loss: 0.370350   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 858   Recon Loss: 0.360799   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 859   Recon Loss: 0.383941   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 860   Recon Loss: 0.391491   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 861   Recon Loss: 0.377183   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 862   Recon Loss: 0.384529   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 863   Recon Loss: 0.359793   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 864   Recon Loss: 0.365015   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 865   Recon Loss: 0.381886   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 866   Recon Loss: 0.380200   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 867   Recon Loss: 0.384366   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 868   Recon Loss: 0.391390   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 869   Recon Loss: 0.367502   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 870   Recon Loss: 0.399276   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 871   Recon Loss: 0.375704   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 872   Recon Loss: 0.392587   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 873   Recon Loss: 0.377745   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 874   Recon Loss: 0.378870   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 875   Recon Loss: 0.387551   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 876   Recon Loss: 0.390227   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 877   Recon Loss: 0.392753   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 878   Recon Loss: 0.386295   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 879   Recon Loss: 0.384637   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 880   Recon Loss: 0.382805   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 881   Recon Loss: 0.377021   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 882   Recon Loss: 0.363629   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 883   Recon Loss: 0.375423   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 884   Recon Loss: 0.390025   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 885   Recon Loss: 0.373889   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 886   Recon Loss: 0.390487   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 887   Recon Loss: 0.379959   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 888   Recon Loss: 0.370316   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 889   Recon Loss: 0.373473   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 890   Recon Loss: 0.376801   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 891   Recon Loss: 0.381907   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 892   Recon Loss: 0.384727   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 893   Recon Loss: 0.373958   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 894   Recon Loss: 0.356229   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 895   Recon Loss: 0.365850   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 896   Recon Loss: 0.371982   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 897   Recon Loss: 0.361654   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 898   Recon Loss: 0.374620   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 899   Recon Loss: 0.352749   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 900   Recon Loss: 0.364192   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 901   Recon Loss: 0.363112   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 902   Recon Loss: 0.366395   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 903   Recon Loss: 0.370447   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 904   Recon Loss: 0.374481   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 905   Recon Loss: 0.385755   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 906   Recon Loss: 0.379638   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 907   Recon Loss: 0.373147   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 908   Recon Loss: 0.368820   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 909   Recon Loss: 0.369806   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 910   Recon Loss: 0.366733   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 911   Recon Loss: 0.385848   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 912   Recon Loss: 0.385631   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 913   Recon Loss: 0.366110   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 914   Recon Loss: 0.383236   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 915   Recon Loss: 0.381627   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 916   Recon Loss: 0.378062   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 917   Recon Loss: 0.395967   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 918   Recon Loss: 0.371076   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 919   Recon Loss: 0.373524   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 920   Recon Loss: 0.364359   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 921   Recon Loss: 0.374611   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 922   Recon Loss: 0.364990   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 923   Recon Loss: 0.379960   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 924   Recon Loss: 0.373254   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 925   Recon Loss: 0.370969   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 926   Recon Loss: 0.369314   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 927   Recon Loss: 0.381599   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 928   Recon Loss: 0.368783   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 929   Recon Loss: 0.358383   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 930   Recon Loss: 0.363032   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 931   Recon Loss: 0.388412   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 932   Recon Loss: 0.364666   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 933   Recon Loss: 0.386873   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 934   Recon Loss: 0.354177   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 935   Recon Loss: 0.365241   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 936   Recon Loss: 0.368149   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 937   Recon Loss: 0.394380   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 938   Recon Loss: 0.373707   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 939   Recon Loss: 0.365418   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 940   Recon Loss: 0.369936   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 941   Recon Loss: 0.366231   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 942   Recon Loss: 0.371515   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 943   Recon Loss: 0.380355   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 944   Recon Loss: 0.380691   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 945   Recon Loss: 0.391374   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 946   Recon Loss: 0.350840   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 947   Recon Loss: 0.358271   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 948   Recon Loss: 0.390439   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 949   Recon Loss: 0.383202   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 950   Recon Loss: 0.392310   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 951   Recon Loss: 0.361410   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 952   Recon Loss: 0.379201   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 953   Recon Loss: 0.361131   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 954   Recon Loss: 0.375502   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 955   Recon Loss: 0.403594   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 956   Recon Loss: 0.367654   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 957   Recon Loss: 0.373862   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 958   Recon Loss: 0.384536   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 959   Recon Loss: 0.381829   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 960   Recon Loss: 0.376321   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 961   Recon Loss: 0.387507   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 962   Recon Loss: 0.391048   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 963   Recon Loss: 0.388801   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 964   Recon Loss: 0.378694   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 965   Recon Loss: 0.373469   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 966   Recon Loss: 0.375744   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 967   Recon Loss: 0.381539   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 968   Recon Loss: 0.376577   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 969   Recon Loss: 0.356798   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 970   Recon Loss: 0.375126   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 971   Recon Loss: 0.377775   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 972   Recon Loss: 0.371326   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 973   Recon Loss: 0.375301   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 974   Recon Loss: 0.379340   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 975   Recon Loss: 0.379762   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 976   Recon Loss: 0.407416   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 977   Recon Loss: 0.370176   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 978   Recon Loss: 0.380147   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 979   Recon Loss: 0.379569   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 980   Recon Loss: 0.382312   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 981   Recon Loss: 0.369989   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 982   Recon Loss: 0.358273   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 983   Recon Loss: 0.381162   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 984   Recon Loss: 0.352034   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 985   Recon Loss: 0.375295   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 986   Recon Loss: 0.364303   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 987   Recon Loss: 0.367163   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 988   Recon Loss: 0.381996   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 989   Recon Loss: 0.376365   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 990   Recon Loss: 0.371264   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 991   Recon Loss: 0.370271   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 992   Recon Loss: 0.364462   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 993   Recon Loss: 0.358070   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 994   Recon Loss: 0.364003   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 995   Recon Loss: 0.360102   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 996   Recon Loss: 0.394219   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 997   Recon Loss: 0.353814   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 998   Recon Loss: 0.365994   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 999   Recon Loss: 0.345314   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 1000   Recon Loss: 0.366141   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 1001   Recon Loss: 0.378467   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 1002   Recon Loss: 0.380279   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 1003   Recon Loss: 0.369903   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 1004   Recon Loss: 0.369199   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 1005   Recon Loss: 0.374270   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 1006   Recon Loss: 0.377516   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 1007   Recon Loss: 0.373891   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 1008   Recon Loss: 0.396534   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 1009   Recon Loss: 0.375413   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 1010   Recon Loss: 0.365489   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 1011   Recon Loss: 0.370744   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 1012   Recon Loss: 0.371461   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 1013   Recon Loss: 0.387181   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 1014   Recon Loss: 0.392371   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 1015   Recon Loss: 0.356176   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 1016   Recon Loss: 0.384533   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 1017   Recon Loss: 0.371906   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 1018   Recon Loss: 0.367803   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 1019   Recon Loss: 0.370081   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 1020   Recon Loss: 0.361115   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 1021   Recon Loss: 0.389084   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 1022   Recon Loss: 0.389288   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 1023   Recon Loss: 0.376751   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 1024   Recon Loss: 0.375500   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 1025   Recon Loss: 0.362291   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 1026   Recon Loss: 0.397691   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 1027   Recon Loss: 0.372583   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 1028   Recon Loss: 0.361333   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 1029   Recon Loss: 0.380567   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 1030   Recon Loss: 0.356561   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 1031   Recon Loss: 0.370032   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 1032   Recon Loss: 0.399668   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 1033   Recon Loss: 0.373572   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 1034   Recon Loss: 0.372771   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 1035   Recon Loss: 0.364973   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 1036   Recon Loss: 0.355771   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 1037   Recon Loss: 0.395444   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 1038   Recon Loss: 0.371183   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 1039   Recon Loss: 0.372977   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 1040   Recon Loss: 0.379041   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 1041   Recon Loss: 0.387978   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 1042   Recon Loss: 0.375380   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 1043   Recon Loss: 0.375121   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 1044   Recon Loss: 0.364679   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 1045   Recon Loss: 0.378617   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 1046   Recon Loss: 0.391674   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 1047   Recon Loss: 0.385139   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 1048   Recon Loss: 0.381326   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 1049   Recon Loss: 0.364844   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 1050   Recon Loss: 0.369269   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 1051   Recon Loss: 0.375599   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 1052   Recon Loss: 0.375814   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 1053   Recon Loss: 0.369213   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 1054   Recon Loss: 0.363406   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 1055   Recon Loss: 0.359758   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 1056   Recon Loss: 0.371585   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 1057   Recon Loss: 0.376158   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 1058   Recon Loss: 0.369577   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 1059   Recon Loss: 0.393488   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 1060   Recon Loss: 0.381429   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 1061   Recon Loss: 0.381587   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 1062   Recon Loss: 0.369357   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 1063   Recon Loss: 0.391955   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 1064   Recon Loss: 0.390896   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 1065   Recon Loss: 0.371346   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 1066   Recon Loss: 0.383518   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 1067   Recon Loss: 0.361837   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 1068   Recon Loss: 0.366927   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 1069   Recon Loss: 0.374714   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 1070   Recon Loss: 0.372354   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 1071   Recon Loss: 0.378421   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 1072   Recon Loss: 0.350261   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 1073   Recon Loss: 0.373849   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 1074   Recon Loss: 0.393798   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 1075   Recon Loss: 0.393928   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 1076   Recon Loss: 0.367249   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 1077   Recon Loss: 0.388889   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 1078   Recon Loss: 0.386004   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 1079   Recon Loss: 0.354085   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 1080   Recon Loss: 0.364747   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 1081   Recon Loss: 0.365573   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 1082   Recon Loss: 0.387949   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 1083   Recon Loss: 0.365804   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 1084   Recon Loss: 0.384297   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 1085   Recon Loss: 0.368870   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 1086   Recon Loss: 0.396610   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 1087   Recon Loss: 0.382556   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 1088   Recon Loss: 0.382068   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 1089   Recon Loss: 0.367894   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 1090   Recon Loss: 0.368704   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 1091   Recon Loss: 0.369188   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 1092   Recon Loss: 0.369121   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 1093   Recon Loss: 0.394299   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 1094   Recon Loss: 0.362468   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 1095   Recon Loss: 0.365472   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 1096   Recon Loss: 0.364704   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 1097   Recon Loss: 0.376446   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 1098   Recon Loss: 0.352274   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 1099   Recon Loss: 0.351121   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 1100   Recon Loss: 0.361496   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 1101   Recon Loss: 0.369975   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 1102   Recon Loss: 0.370329   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 1103   Recon Loss: 0.372301   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 1104   Recon Loss: 0.344813   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 1105   Recon Loss: 0.376539   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 1106   Recon Loss: 0.371241   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 1107   Recon Loss: 0.384588   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 1108   Recon Loss: 0.377105   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 1109   Recon Loss: 0.384481   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 1110   Recon Loss: 0.361079   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 1111   Recon Loss: 0.372637   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 1112   Recon Loss: 0.372617   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 1113   Recon Loss: 0.357830   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 1114   Recon Loss: 0.353322   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 1115   Recon Loss: 0.360358   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 1116   Recon Loss: 0.368665   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 1117   Recon Loss: 0.383511   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 1118   Recon Loss: 0.365851   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 1119   Recon Loss: 0.390688   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 1120   Recon Loss: 0.376004   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 1121   Recon Loss: 0.367820   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 1122   Recon Loss: 0.375500   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 1123   Recon Loss: 0.380355   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 1124   Recon Loss: 0.366479   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 1125   Recon Loss: 0.381686   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 1126   Recon Loss: 0.373080   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 1127   Recon Loss: 0.364712   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 1128   Recon Loss: 0.363357   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 1129   Recon Loss: 0.380108   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 1130   Recon Loss: 0.372056   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 1131   Recon Loss: 0.377756   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 1132   Recon Loss: 0.357276   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 1133   Recon Loss: 0.364246   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 1134   Recon Loss: 0.350713   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 1135   Recon Loss: 0.393787   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 1136   Recon Loss: 0.409259   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 1137   Recon Loss: 0.359793   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 1138   Recon Loss: 0.380195   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 1139   Recon Loss: 0.381293   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 1140   Recon Loss: 0.353075   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 1141   Recon Loss: 0.378506   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 1142   Recon Loss: 0.364929   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 1143   Recon Loss: 0.370093   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 1144   Recon Loss: 0.383417   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 1145   Recon Loss: 0.359703   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 1146   Recon Loss: 0.362562   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 1147   Recon Loss: 0.382776   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 1148   Recon Loss: 0.363733   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 1149   Recon Loss: 0.362016   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 1150   Recon Loss: 0.387664   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 1151   Recon Loss: 0.378970   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 1152   Recon Loss: 0.390616   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 1153   Recon Loss: 0.357879   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 1154   Recon Loss: 0.385357   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 1155   Recon Loss: 0.360388   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 1156   Recon Loss: 0.364983   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 1157   Recon Loss: 0.370730   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 1158   Recon Loss: 0.378539   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 1159   Recon Loss: 0.379880   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 1160   Recon Loss: 0.369651   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 1161   Recon Loss: 0.358420   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 1162   Recon Loss: 0.368096   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 1163   Recon Loss: 0.394260   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 1164   Recon Loss: 0.379607   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 1165   Recon Loss: 0.361737   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 1166   Recon Loss: 0.377528   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 1167   Recon Loss: 0.367599   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 1168   Recon Loss: 0.372035   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 1169   Recon Loss: 0.373914   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 1170   Recon Loss: 0.374916   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 1171   Recon Loss: 0.390068   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 1172   Recon Loss: 0.377213   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 1173   Recon Loss: 0.367659   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 1174   Recon Loss: 0.366225   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 1175   Recon Loss: 0.366694   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 1176   Recon Loss: 0.370104   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 1177   Recon Loss: 0.379335   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 1178   Recon Loss: 0.398913   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 1179   Recon Loss: 0.383209   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 1180   Recon Loss: 0.372093   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 1181   Recon Loss: 0.389476   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 1182   Recon Loss: 0.374450   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 1183   Recon Loss: 0.360754   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 1184   Recon Loss: 0.371628   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 1185   Recon Loss: 0.382740   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 1186   Recon Loss: 0.371064   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 1187   Recon Loss: 0.368198   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 1188   Recon Loss: 0.383317   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 1189   Recon Loss: 0.373026   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 1190   Recon Loss: 0.377238   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 1191   Recon Loss: 0.385952   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 1192   Recon Loss: 0.372507   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 1193   Recon Loss: 0.379989   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 1194   Recon Loss: 0.392673   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 1195   Recon Loss: 0.374668   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 1196   Recon Loss: 0.387132   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 1197   Recon Loss: 0.365422   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 1198   Recon Loss: 0.369838   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 1199   Recon Loss: 0.383068   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 1200   Recon Loss: 0.369966   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 1201   Recon Loss: 0.369704   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 1202   Recon Loss: 0.373440   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 1203   Recon Loss: 0.361916   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 1204   Recon Loss: 0.362485   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 1205   Recon Loss: 0.367907   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 1206   Recon Loss: 0.385327   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 1207   Recon Loss: 0.366463   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 1208   Recon Loss: 0.371534   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 1209   Recon Loss: 0.344183   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 1210   Recon Loss: 0.392845   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 1211   Recon Loss: 0.367023   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 1212   Recon Loss: 0.378726   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 1213   Recon Loss: 0.382470   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 1214   Recon Loss: 0.375726   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 1215   Recon Loss: 0.365685   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 1216   Recon Loss: 0.368858   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 1217   Recon Loss: 0.371110   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 1218   Recon Loss: 0.380991   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 1219   Recon Loss: 0.392822   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 1220   Recon Loss: 0.354122   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 1221   Recon Loss: 0.375775   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 1222   Recon Loss: 0.366278   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 1223   Recon Loss: 0.369660   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 1224   Recon Loss: 0.373351   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 1225   Recon Loss: 0.366297   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 1226   Recon Loss: 0.362474   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 1227   Recon Loss: 0.382625   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 1228   Recon Loss: 0.363381   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 1229   Recon Loss: 0.358294   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 1230   Recon Loss: 0.354677   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 1231   Recon Loss: 0.370670   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 1232   Recon Loss: 0.375052   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 1233   Recon Loss: 0.377920   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 1234   Recon Loss: 0.370009   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 1235   Recon Loss: 0.360294   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 1236   Recon Loss: 0.377864   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 1237   Recon Loss: 0.377082   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 1238   Recon Loss: 0.367488   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 1239   Recon Loss: 0.399542   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 1240   Recon Loss: 0.372330   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 1241   Recon Loss: 0.367106   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 1242   Recon Loss: 0.402925   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 1243   Recon Loss: 0.346244   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 1244   Recon Loss: 0.353080   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 1245   Recon Loss: 0.375085   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 1246   Recon Loss: 0.358981   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 1247   Recon Loss: 0.367516   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 1248   Recon Loss: 0.379699   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 1249   Recon Loss: 0.365887   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 1250   Recon Loss: 0.360731   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 1251   Recon Loss: 0.363058   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 1252   Recon Loss: 0.378693   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 1253   Recon Loss: 0.367625   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 1254   Recon Loss: 0.391236   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 1255   Recon Loss: 0.376241   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 1256   Recon Loss: 0.384453   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 1257   Recon Loss: 0.353202   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 1258   Recon Loss: 0.367417   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 1259   Recon Loss: 0.371104   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 1260   Recon Loss: 0.373538   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 1261   Recon Loss: 0.360540   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 1262   Recon Loss: 0.355275   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 1263   Recon Loss: 0.382737   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 1264   Recon Loss: 0.379106   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 1265   Recon Loss: 0.374345   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 1266   Recon Loss: 0.358534   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 1267   Recon Loss: 0.374940   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 1268   Recon Loss: 0.380215   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 1269   Recon Loss: 0.403225   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 1270   Recon Loss: 0.386240   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 1271   Recon Loss: 0.369950   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 1272   Recon Loss: 0.370159   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 1273   Recon Loss: 0.347520   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 1274   Recon Loss: 0.379035   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 1275   Recon Loss: 0.377046   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 1276   Recon Loss: 0.375409   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 1277   Recon Loss: 0.370438   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 1278   Recon Loss: 0.395590   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 1279   Recon Loss: 0.371262   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 1280   Recon Loss: 0.358878   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 1281   Recon Loss: 0.370339   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 1282   Recon Loss: 0.372024   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 1283   Recon Loss: 0.355230   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 1284   Recon Loss: 0.387704   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 1285   Recon Loss: 0.367632   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 1286   Recon Loss: 0.378816   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 1287   Recon Loss: 0.366946   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 1288   Recon Loss: 0.380947   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 1289   Recon Loss: 0.383252   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 1290   Recon Loss: 0.369131   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 1291   Recon Loss: 0.365282   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 1292   Recon Loss: 0.378333   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 1293   Recon Loss: 0.359496   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 1294   Recon Loss: 0.362429   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 1295   Recon Loss: 0.375941   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 1296   Recon Loss: 0.375605   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 1297   Recon Loss: 0.360648   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 1298   Recon Loss: 0.357133   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 1299   Recon Loss: 0.360368   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 1300   Recon Loss: 0.366659   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 1301   Recon Loss: 0.386637   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 1302   Recon Loss: 0.376847   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 1303   Recon Loss: 0.388814   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 1304   Recon Loss: 0.367449   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 1305   Recon Loss: 0.365138   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 1306   Recon Loss: 0.385558   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 1307   Recon Loss: 0.380515   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 1308   Recon Loss: 0.384909   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 1309   Recon Loss: 0.369554   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 1310   Recon Loss: 0.384362   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 1311   Recon Loss: 0.378230   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 1312   Recon Loss: 0.368033   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 1313   Recon Loss: 0.367386   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 1314   Recon Loss: 0.375025   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 1315   Recon Loss: 0.381109   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 1316   Recon Loss: 0.370935   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 1317   Recon Loss: 0.383445   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 1318   Recon Loss: 0.370756   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 1319   Recon Loss: 0.361254   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 1320   Recon Loss: 0.367764   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 1321   Recon Loss: 0.372044   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 1322   Recon Loss: 0.372615   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 1323   Recon Loss: 0.383286   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 1324   Recon Loss: 0.398670   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 1325   Recon Loss: 0.355287   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 1326   Recon Loss: 0.369518   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 1327   Recon Loss: 0.353775   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 1328   Recon Loss: 0.369051   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 1329   Recon Loss: 0.368788   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 1330   Recon Loss: 0.382610   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 1331   Recon Loss: 0.367099   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 1332   Recon Loss: 0.382116   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 1333   Recon Loss: 0.387096   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 1334   Recon Loss: 0.374763   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 1335   Recon Loss: 0.372657   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 1336   Recon Loss: 0.374440   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 1337   Recon Loss: 0.369240   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 1338   Recon Loss: 0.370828   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 1339   Recon Loss: 0.362933   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 1340   Recon Loss: 0.376008   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 1341   Recon Loss: 0.384542   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 1342   Recon Loss: 0.361165   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 1343   Recon Loss: 0.374161   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 1344   Recon Loss: 0.361970   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 1345   Recon Loss: 0.373271   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 1346   Recon Loss: 0.341044   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 1347   Recon Loss: 0.385251   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 1348   Recon Loss: 0.386036   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 1349   Recon Loss: 0.368047   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 1350   Recon Loss: 0.383612   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 1351   Recon Loss: 0.379503   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 1352   Recon Loss: 0.358228   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 1353   Recon Loss: 0.363940   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 1354   Recon Loss: 0.369627   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 1355   Recon Loss: 0.373530   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 1356   Recon Loss: 0.355624   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 1357   Recon Loss: 0.350585   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 1358   Recon Loss: 0.360093   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 1359   Recon Loss: 0.357593   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 1360   Recon Loss: 0.388279   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 1361   Recon Loss: 0.396084   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 1362   Recon Loss: 0.374873   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 1363   Recon Loss: 0.359034   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 1364   Recon Loss: 0.374156   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 1365   Recon Loss: 0.386930   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 1366   Recon Loss: 0.379090   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 1367   Recon Loss: 0.371661   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 1368   Recon Loss: 0.363746   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 1369   Recon Loss: 0.377488   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 1370   Recon Loss: 0.387309   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 1371   Recon Loss: 0.361952   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 1372   Recon Loss: 0.367916   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 1373   Recon Loss: 0.377690   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 1374   Recon Loss: 0.359193   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 1375   Recon Loss: 0.376481   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 1376   Recon Loss: 0.362350   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 1377   Recon Loss: 0.375876   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 1378   Recon Loss: 0.378804   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 1379   Recon Loss: 0.366250   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 1380   Recon Loss: 0.362574   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 1381   Recon Loss: 0.376696   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 1382   Recon Loss: 0.394546   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 1383   Recon Loss: 0.376639   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 1384   Recon Loss: 0.362353   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 1385   Recon Loss: 0.374947   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 1386   Recon Loss: 0.375949   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 1387   Recon Loss: 0.381321   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 1388   Recon Loss: 0.373394   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 1389   Recon Loss: 0.372258   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 1390   Recon Loss: 0.390676   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 1391   Recon Loss: 0.371990   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 1392   Recon Loss: 0.362395   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 1393   Recon Loss: 0.374976   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 1394   Recon Loss: 0.367168   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 1395   Recon Loss: 0.385403   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 1396   Recon Loss: 0.354574   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 1397   Recon Loss: 0.372123   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 1398   Recon Loss: 0.370087   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 1399   Recon Loss: 0.368972   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 1400   Recon Loss: 0.356509   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 1401   Recon Loss: 0.384521   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 1402   Recon Loss: 0.364699   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 1403   Recon Loss: 0.374805   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 1404   Recon Loss: 0.360925   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 1405   Recon Loss: 0.403294   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 1406   Recon Loss: 0.370616   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 1407   Recon Loss: 0.375041   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 1408   Recon Loss: 0.371860   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 1409   Recon Loss: 0.364429   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 1410   Recon Loss: 0.373543   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 1411   Recon Loss: 0.357597   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 1412   Recon Loss: 0.372485   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 1413   Recon Loss: 0.361901   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 1414   Recon Loss: 0.360177   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 1415   Recon Loss: 0.349451   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 1416   Recon Loss: 0.364046   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 1417   Recon Loss: 0.371937   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 1418   Recon Loss: 0.362112   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 1419   Recon Loss: 0.380215   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 1420   Recon Loss: 0.376730   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 1421   Recon Loss: 0.380961   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 1422   Recon Loss: 0.354837   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 1423   Recon Loss: 0.362170   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 1424   Recon Loss: 0.371893   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 1425   Recon Loss: 0.369465   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 1426   Recon Loss: 0.388033   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 1427   Recon Loss: 0.374995   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 1428   Recon Loss: 0.374449   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 1429   Recon Loss: 0.348228   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 1430   Recon Loss: 0.375872   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 1431   Recon Loss: 0.390406   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 1432   Recon Loss: 0.351329   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 1433   Recon Loss: 0.360856   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 1434   Recon Loss: 0.363781   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 1435   Recon Loss: 0.371634   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 1436   Recon Loss: 0.373665   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 1437   Recon Loss: 0.390709   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 1438   Recon Loss: 0.370203   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 1439   Recon Loss: 0.374852   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 1440   Recon Loss: 0.364362   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 1441   Recon Loss: 0.372219   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 1442   Recon Loss: 0.368712   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 1443   Recon Loss: 0.349481   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 1444   Recon Loss: 0.381923   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 1445   Recon Loss: 0.352982   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 1446   Recon Loss: 0.378578   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 1447   Recon Loss: 0.378905   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 1448   Recon Loss: 0.387506   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 1449   Recon Loss: 0.355976   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 1450   Recon Loss: 0.371327   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 1451   Recon Loss: 0.383544   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 1452   Recon Loss: 0.372196   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 1453   Recon Loss: 0.356489   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 1454   Recon Loss: 0.372343   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 1455   Recon Loss: 0.364228   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 1456   Recon Loss: 0.371920   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 1457   Recon Loss: 0.367164   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 1458   Recon Loss: 0.353916   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 1459   Recon Loss: 0.380822   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 1460   Recon Loss: 0.383402   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 1461   Recon Loss: 0.364949   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 1462   Recon Loss: 0.391942   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 1463   Recon Loss: 0.371953   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 1464   Recon Loss: 0.365390   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 1465   Recon Loss: 0.367015   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 1466   Recon Loss: 0.363318   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 1467   Recon Loss: 0.378476   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 1468   Recon Loss: 0.379148   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 1469   Recon Loss: 0.361387   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 1470   Recon Loss: 0.373748   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 1471   Recon Loss: 0.377087   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 1472   Recon Loss: 0.358546   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 1473   Recon Loss: 0.362706   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 1474   Recon Loss: 0.369988   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 1475   Recon Loss: 0.364753   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 1476   Recon Loss: 0.352389   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 1477   Recon Loss: 0.379512   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 1478   Recon Loss: 0.361089   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 1479   Recon Loss: 0.367781   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 1480   Recon Loss: 0.369457   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 1481   Recon Loss: 0.356597   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 1482   Recon Loss: 0.368305   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 1483   Recon Loss: 0.371035   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 1484   Recon Loss: 0.365391   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 1485   Recon Loss: 0.358160   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 1486   Recon Loss: 0.364124   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 1487   Recon Loss: 0.371177   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 1488   Recon Loss: 0.370638   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 1489   Recon Loss: 0.390285   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 1490   Recon Loss: 0.386103   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 1491   Recon Loss: 0.376714   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 1492   Recon Loss: 0.374537   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 1493   Recon Loss: 0.378813   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 1494   Recon Loss: 0.362958   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 1495   Recon Loss: 0.345311   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 1496   Recon Loss: 0.351663   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 1497   Recon Loss: 0.347750   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 1498   Recon Loss: 0.352288   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 1499   Recon Loss: 0.382863   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 1500   Recon Loss: 0.382707   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 1501   Recon Loss: 0.395483   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 1502   Recon Loss: 0.358971   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 1503   Recon Loss: 0.373494   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 1504   Recon Loss: 0.361511   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 1505   Recon Loss: 0.378586   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 1506   Recon Loss: 0.377399   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 1507   Recon Loss: 0.381731   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 1508   Recon Loss: 0.396293   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 1509   Recon Loss: 0.356007   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 1510   Recon Loss: 0.360125   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 1511   Recon Loss: 0.366445   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 1512   Recon Loss: 0.366447   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 1513   Recon Loss: 0.372550   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 1514   Recon Loss: 0.350422   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 1515   Recon Loss: 0.364246   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 1516   Recon Loss: 0.379104   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 1517   Recon Loss: 0.369134   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 1518   Recon Loss: 0.360638   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 1519   Recon Loss: 0.362980   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 1520   Recon Loss: 0.365736   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 1521   Recon Loss: 0.380155   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 1522   Recon Loss: 0.389240   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 1523   Recon Loss: 0.367164   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 1524   Recon Loss: 0.364753   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 1525   Recon Loss: 0.357006   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 1526   Recon Loss: 0.366788   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 1527   Recon Loss: 0.351711   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 1528   Recon Loss: 0.371621   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 1529   Recon Loss: 0.367524   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 1530   Recon Loss: 0.379026   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 1531   Recon Loss: 0.376863   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 1532   Recon Loss: 0.370550   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 1533   Recon Loss: 0.379342   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 1534   Recon Loss: 0.352672   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 1535   Recon Loss: 0.411748   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 1536   Recon Loss: 0.351214   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 1537   Recon Loss: 0.357725   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 1538   Recon Loss: 0.336625   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 1539   Recon Loss: 0.391628   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 1540   Recon Loss: 0.379260   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 1541   Recon Loss: 0.372267   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 1542   Recon Loss: 0.359157   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 1543   Recon Loss: 0.398708   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 1544   Recon Loss: 0.377733   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 1545   Recon Loss: 0.393478   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 1546   Recon Loss: 0.374459   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 1547   Recon Loss: 0.367599   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 1548   Recon Loss: 0.355789   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 1549   Recon Loss: 0.378423   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 1550   Recon Loss: 0.377753   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 1551   Recon Loss: 0.351824   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 1552   Recon Loss: 0.368238   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 1553   Recon Loss: 0.372130   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 1554   Recon Loss: 0.369440   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 1555   Recon Loss: 0.364501   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 1556   Recon Loss: 0.376881   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 1557   Recon Loss: 0.366187   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 1558   Recon Loss: 0.376793   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 1559   Recon Loss: 0.361623   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 1560   Recon Loss: 0.367817   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 1561   Recon Loss: 0.353844   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 1562   Recon Loss: 0.359029   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 1563   Recon Loss: 0.351611   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 1564   Recon Loss: 0.362578   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 1565   Recon Loss: 0.378327   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 1566   Recon Loss: 0.370069   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 1567   Recon Loss: 0.369247   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 1568   Recon Loss: 0.379375   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 1569   Recon Loss: 0.390912   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 1570   Recon Loss: 0.398434   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 1571   Recon Loss: 0.379486   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 1572   Recon Loss: 0.374452   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 1573   Recon Loss: 0.366124   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 1574   Recon Loss: 0.376352   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 1575   Recon Loss: 0.373818   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 1576   Recon Loss: 0.392612   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 1577   Recon Loss: 0.353026   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 1578   Recon Loss: 0.364832   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 1579   Recon Loss: 0.360830   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 1580   Recon Loss: 0.380644   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 1581   Recon Loss: 0.369658   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 1582   Recon Loss: 0.366229   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 1583   Recon Loss: 0.378879   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 1584   Recon Loss: 0.374562   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 1585   Recon Loss: 0.359177   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 1586   Recon Loss: 0.380781   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 1587   Recon Loss: 0.386592   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 1588   Recon Loss: 0.369867   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 1589   Recon Loss: 0.368568   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 1590   Recon Loss: 0.377243   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 1591   Recon Loss: 0.359444   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 1592   Recon Loss: 0.373767   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 1593   Recon Loss: 0.369171   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 1594   Recon Loss: 0.373528   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 1595   Recon Loss: 0.382983   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 1596   Recon Loss: 0.362141   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 1597   Recon Loss: 0.375720   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 1598   Recon Loss: 0.366400   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 1599   Recon Loss: 0.397747   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 1600   Recon Loss: 0.362678   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 1601   Recon Loss: 0.372954   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 1602   Recon Loss: 0.379562   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 1603   Recon Loss: 0.350735   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 1604   Recon Loss: 0.387997   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 1605   Recon Loss: 0.390531   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 1606   Recon Loss: 0.370440   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 1607   Recon Loss: 0.384993   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 1608   Recon Loss: 0.386283   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 1609   Recon Loss: 0.371346   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 1610   Recon Loss: 0.369302   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 1611   Recon Loss: 0.382561   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 1612   Recon Loss: 0.365238   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 1613   Recon Loss: 0.370873   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 1614   Recon Loss: 0.360466   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 1615   Recon Loss: 0.357676   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 1616   Recon Loss: 0.356048   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 1617   Recon Loss: 0.369705   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 1618   Recon Loss: 0.368927   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 1619   Recon Loss: 0.385324   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 1620   Recon Loss: 0.397421   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 1621   Recon Loss: 0.364145   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 1622   Recon Loss: 0.403484   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 1623   Recon Loss: 0.351546   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 1624   Recon Loss: 0.373870   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 1625   Recon Loss: 0.370757   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 1626   Recon Loss: 0.363714   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 1627   Recon Loss: 0.383883   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 1628   Recon Loss: 0.370174   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 1629   Recon Loss: 0.384333   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 1630   Recon Loss: 0.370929   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 1631   Recon Loss: 0.376546   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 1632   Recon Loss: 0.353039   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 1633   Recon Loss: 0.357704   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 1634   Recon Loss: 0.353882   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 1635   Recon Loss: 0.378571   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 1636   Recon Loss: 0.377236   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 1637   Recon Loss: 0.359302   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 1638   Recon Loss: 0.360175   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 1639   Recon Loss: 0.374288   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 1640   Recon Loss: 0.371771   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 1641   Recon Loss: 0.382307   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 1642   Recon Loss: 0.358225   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 1643   Recon Loss: 0.375680   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 1644   Recon Loss: 0.385622   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 1645   Recon Loss: 0.372636   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 1646   Recon Loss: 0.353561   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 1647   Recon Loss: 0.362596   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 1648   Recon Loss: 0.379897   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 1649   Recon Loss: 0.372241   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 1650   Recon Loss: 0.356184   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 1651   Recon Loss: 0.358043   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 1652   Recon Loss: 0.351816   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 1653   Recon Loss: 0.382799   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 1654   Recon Loss: 0.368175   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 1655   Recon Loss: 0.388781   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 1656   Recon Loss: 0.367431   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 1657   Recon Loss: 0.363823   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 1658   Recon Loss: 0.376409   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 1659   Recon Loss: 0.350575   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 1660   Recon Loss: 0.384296   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 1661   Recon Loss: 0.372064   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 1662   Recon Loss: 0.366785   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 1663   Recon Loss: 0.382128   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 1664   Recon Loss: 0.369874   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 1665   Recon Loss: 0.370545   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 1666   Recon Loss: 0.388807   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 1667   Recon Loss: 0.376011   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 1668   Recon Loss: 0.363077   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 1669   Recon Loss: 0.354185   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 1670   Recon Loss: 0.367957   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 1671   Recon Loss: 0.370206   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 1672   Recon Loss: 0.363743   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 1673   Recon Loss: 0.378371   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 1674   Recon Loss: 0.371274   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 1675   Recon Loss: 0.367458   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 1676   Recon Loss: 0.355234   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 1677   Recon Loss: 0.368282   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 1678   Recon Loss: 0.376437   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 1679   Recon Loss: 0.368673   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 1680   Recon Loss: 0.367147   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 1681   Recon Loss: 0.355790   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 1682   Recon Loss: 0.361278   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 1683   Recon Loss: 0.385522   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 1684   Recon Loss: 0.371156   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 1685   Recon Loss: 0.372445   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 1686   Recon Loss: 0.365500   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 1687   Recon Loss: 0.391592   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 1688   Recon Loss: 0.351033   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 1689   Recon Loss: 0.377151   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 1690   Recon Loss: 0.393044   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 1691   Recon Loss: 0.385868   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 1692   Recon Loss: 0.402699   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 1693   Recon Loss: 0.371826   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 1694   Recon Loss: 0.359459   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 1695   Recon Loss: 0.365218   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 1696   Recon Loss: 0.377727   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 1697   Recon Loss: 0.374087   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 1698   Recon Loss: 0.386311   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 1699   Recon Loss: 0.377724   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 1700   Recon Loss: 0.366037   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 1701   Recon Loss: 0.382062   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 1702   Recon Loss: 0.367227   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 1703   Recon Loss: 0.347278   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 1704   Recon Loss: 0.368839   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 1705   Recon Loss: 0.362439   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 1706   Recon Loss: 0.359260   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 1707   Recon Loss: 0.365712   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 1708   Recon Loss: 0.381912   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 1709   Recon Loss: 0.383726   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 1710   Recon Loss: 0.379032   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 1711   Recon Loss: 0.379258   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 1712   Recon Loss: 0.352757   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 1713   Recon Loss: 0.366226   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 1714   Recon Loss: 0.374649   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 1715   Recon Loss: 0.384994   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 1716   Recon Loss: 0.381216   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 1717   Recon Loss: 0.356227   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 1718   Recon Loss: 0.381357   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 1719   Recon Loss: 0.368961   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 1720   Recon Loss: 0.367296   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 1721   Recon Loss: 0.376827   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 1722   Recon Loss: 0.369525   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 1723   Recon Loss: 0.360162   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 1724   Recon Loss: 0.361188   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 1725   Recon Loss: 0.384194   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 1726   Recon Loss: 0.371307   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 1727   Recon Loss: 0.366724   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 1728   Recon Loss: 0.374583   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 1729   Recon Loss: 0.366686   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 1730   Recon Loss: 0.394404   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 1731   Recon Loss: 0.377332   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 1732   Recon Loss: 0.368841   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 1733   Recon Loss: 0.360529   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 1734   Recon Loss: 0.373079   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 1735   Recon Loss: 0.374985   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 1736   Recon Loss: 0.375307   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 1737   Recon Loss: 0.368433   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 1738   Recon Loss: 0.391823   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 1739   Recon Loss: 0.366647   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 1740   Recon Loss: 0.381185   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 1741   Recon Loss: 0.368031   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 1742   Recon Loss: 0.375122   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 1743   Recon Loss: 0.358163   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 1744   Recon Loss: 0.380691   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 1745   Recon Loss: 0.403257   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 1746   Recon Loss: 0.348143   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 1747   Recon Loss: 0.373161   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 1748   Recon Loss: 0.385464   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 1749   Recon Loss: 0.372398   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 1750   Recon Loss: 0.361299   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 1751   Recon Loss: 0.369554   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 1752   Recon Loss: 0.368886   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 1753   Recon Loss: 0.375403   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 1754   Recon Loss: 0.386841   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 1755   Recon Loss: 0.390303   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 1756   Recon Loss: 0.358993   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 1757   Recon Loss: 0.376204   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 1758   Recon Loss: 0.362600   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 1759   Recon Loss: 0.369755   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 1760   Recon Loss: 0.353168   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 1761   Recon Loss: 0.377091   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 1762   Recon Loss: 0.359116   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 1763   Recon Loss: 0.376937   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 1764   Recon Loss: 0.368151   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 1765   Recon Loss: 0.354286   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 1766   Recon Loss: 0.383186   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 1767   Recon Loss: 0.369890   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 1768   Recon Loss: 0.387324   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 1769   Recon Loss: 0.349377   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 1770   Recon Loss: 0.382562   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 1771   Recon Loss: 0.361840   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 1772   Recon Loss: 0.352786   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 1773   Recon Loss: 0.385658   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 1774   Recon Loss: 0.360152   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 1775   Recon Loss: 0.390312   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 1776   Recon Loss: 0.364227   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 1777   Recon Loss: 0.367196   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 1778   Recon Loss: 0.374238   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 1779   Recon Loss: 0.384866   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 1780   Recon Loss: 0.367919   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 1781   Recon Loss: 0.369183   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 1782   Recon Loss: 0.360560   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 1783   Recon Loss: 0.363416   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 1784   Recon Loss: 0.381179   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 1785   Recon Loss: 0.364662   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 1786   Recon Loss: 0.393368   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 1787   Recon Loss: 0.364686   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 1788   Recon Loss: 0.379542   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 1789   Recon Loss: 0.359419   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 1790   Recon Loss: 0.405447   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 1791   Recon Loss: 0.364005   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 1792   Recon Loss: 0.370162   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 1793   Recon Loss: 0.389901   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 1794   Recon Loss: 0.344344   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 1795   Recon Loss: 0.381287   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 1796   Recon Loss: 0.385917   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 1797   Recon Loss: 0.393232   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 1798   Recon Loss: 0.383187   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 1799   Recon Loss: 0.379351   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 1800   Recon Loss: 0.372718   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 1801   Recon Loss: 0.365533   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 1802   Recon Loss: 0.367061   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 1803   Recon Loss: 0.359276   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 1804   Recon Loss: 0.353129   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 1805   Recon Loss: 0.384716   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 1806   Recon Loss: 0.379805   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 1807   Recon Loss: 0.392999   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 1808   Recon Loss: 0.378225   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 1809   Recon Loss: 0.376291   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 1810   Recon Loss: 0.371596   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 1811   Recon Loss: 0.373140   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 1812   Recon Loss: 0.359755   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 1813   Recon Loss: 0.355438   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 1814   Recon Loss: 0.371361   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 1815   Recon Loss: 0.375153   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 1816   Recon Loss: 0.365995   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 1817   Recon Loss: 0.366612   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 1818   Recon Loss: 0.375632   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 1819   Recon Loss: 0.376716   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 1820   Recon Loss: 0.386887   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 1821   Recon Loss: 0.355601   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 1822   Recon Loss: 0.383119   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 1823   Recon Loss: 0.358011   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 1824   Recon Loss: 0.373481   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 1825   Recon Loss: 0.370806   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 1826   Recon Loss: 0.370394   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 1827   Recon Loss: 0.377412   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 1828   Recon Loss: 0.361983   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 1829   Recon Loss: 0.358595   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 1830   Recon Loss: 0.366822   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 1831   Recon Loss: 0.368615   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 1832   Recon Loss: 0.368233   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 1833   Recon Loss: 0.356316   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 1834   Recon Loss: 0.377940   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 1835   Recon Loss: 0.351843   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 1836   Recon Loss: 0.371114   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 1837   Recon Loss: 0.362186   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 1838   Recon Loss: 0.348657   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 1839   Recon Loss: 0.367347   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 1840   Recon Loss: 0.378093   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 1841   Recon Loss: 0.362065   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 1842   Recon Loss: 0.373962   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 1843   Recon Loss: 0.356424   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 1844   Recon Loss: 0.379591   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 1845   Recon Loss: 0.349511   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 1846   Recon Loss: 0.364175   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 1847   Recon Loss: 0.384811   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 1848   Recon Loss: 0.373281   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 1849   Recon Loss: 0.371322   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 1850   Recon Loss: 0.364345   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 1851   Recon Loss: 0.364610   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 1852   Recon Loss: 0.388643   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 1853   Recon Loss: 0.393384   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 1854   Recon Loss: 0.371746   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 1855   Recon Loss: 0.354343   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 1856   Recon Loss: 0.379820   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 1857   Recon Loss: 0.386683   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 1858   Recon Loss: 0.382125   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 1859   Recon Loss: 0.342079   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 1860   Recon Loss: 0.360533   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 1861   Recon Loss: 0.348640   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 1862   Recon Loss: 0.361013   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 1863   Recon Loss: 0.371193   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 1864   Recon Loss: 0.370500   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 1865   Recon Loss: 0.372934   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 1866   Recon Loss: 0.345781   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 1867   Recon Loss: 0.371670   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 1868   Recon Loss: 0.359679   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 1869   Recon Loss: 0.364854   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 1870   Recon Loss: 0.365655   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 1871   Recon Loss: 0.356246   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 1872   Recon Loss: 0.362281   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 1873   Recon Loss: 0.390383   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 1874   Recon Loss: 0.359245   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 1875   Recon Loss: 0.388681   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 1876   Recon Loss: 0.355552   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 1877   Recon Loss: 0.348981   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 1878   Recon Loss: 0.361538   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 1879   Recon Loss: 0.348097   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 1880   Recon Loss: 0.366191   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 1881   Recon Loss: 0.357723   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 1882   Recon Loss: 0.394005   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 1883   Recon Loss: 0.362829   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 1884   Recon Loss: 0.372039   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 1885   Recon Loss: 0.378265   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 1886   Recon Loss: 0.367901   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 1887   Recon Loss: 0.377353   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 1888   Recon Loss: 0.369777   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 1889   Recon Loss: 0.372884   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 1890   Recon Loss: 0.375770   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 1891   Recon Loss: 0.340282   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 1892   Recon Loss: 0.372411   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 1893   Recon Loss: 0.358397   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 1894   Recon Loss: 0.393450   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 1895   Recon Loss: 0.359302   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 1896   Recon Loss: 0.369613   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 1897   Recon Loss: 0.394567   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 1898   Recon Loss: 0.370466   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 1899   Recon Loss: 0.360295   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 1900   Recon Loss: 0.358103   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 1901   Recon Loss: 0.384777   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 1902   Recon Loss: 0.364075   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 1903   Recon Loss: 0.341746   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 1904   Recon Loss: 0.364576   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 1905   Recon Loss: 0.370460   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 1906   Recon Loss: 0.381173   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 1907   Recon Loss: 0.368886   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 1908   Recon Loss: 0.382053   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 1909   Recon Loss: 0.376002   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 1910   Recon Loss: 0.361105   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 1911   Recon Loss: 0.382951   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 1912   Recon Loss: 0.364148   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 1913   Recon Loss: 0.365294   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 1914   Recon Loss: 0.362282   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 1915   Recon Loss: 0.359841   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 1916   Recon Loss: 0.370871   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 1917   Recon Loss: 0.381461   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 1918   Recon Loss: 0.361644   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 1919   Recon Loss: 0.368349   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 1920   Recon Loss: 0.376971   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 1921   Recon Loss: 0.364608   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 1922   Recon Loss: 0.362112   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 1923   Recon Loss: 0.365320   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 1924   Recon Loss: 0.365093   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 1925   Recon Loss: 0.382651   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 1926   Recon Loss: 0.358810   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 1927   Recon Loss: 0.368931   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 1928   Recon Loss: 0.363086   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 1929   Recon Loss: 0.373747   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 1930   Recon Loss: 0.368606   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 1931   Recon Loss: 0.370939   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 1932   Recon Loss: 0.365011   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 1933   Recon Loss: 0.377918   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 1934   Recon Loss: 0.376648   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 1935   Recon Loss: 0.386618   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 1936   Recon Loss: 0.371258   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 1937   Recon Loss: 0.381982   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 1938   Recon Loss: 0.387777   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 1939   Recon Loss: 0.392704   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 1940   Recon Loss: 0.364211   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 1941   Recon Loss: 0.383145   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 1942   Recon Loss: 0.367474   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 1943   Recon Loss: 0.380434   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 1944   Recon Loss: 0.363848   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 1945   Recon Loss: 0.362292   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 1946   Recon Loss: 0.366261   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 1947   Recon Loss: 0.349120   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 1948   Recon Loss: 0.376925   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 1949   Recon Loss: 0.388633   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 1950   Recon Loss: 0.373091   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 1951   Recon Loss: 0.388300   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 1952   Recon Loss: 0.365651   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 1953   Recon Loss: 0.346286   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 1954   Recon Loss: 0.356019   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 1955   Recon Loss: 0.367268   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 1956   Recon Loss: 0.370219   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 1957   Recon Loss: 0.349544   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 1958   Recon Loss: 0.344864   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 1959   Recon Loss: 0.365948   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 1960   Recon Loss: 0.366026   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 1961   Recon Loss: 0.374561   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 1962   Recon Loss: 0.367438   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 1963   Recon Loss: 0.355722   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 1964   Recon Loss: 0.361819   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 1965   Recon Loss: 0.391101   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 1966   Recon Loss: 0.372290   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 1967   Recon Loss: 0.379184   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 1968   Recon Loss: 0.363218   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 1969   Recon Loss: 0.403834   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 1970   Recon Loss: 0.361898   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 1971   Recon Loss: 0.367394   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 1972   Recon Loss: 0.374101   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 1973   Recon Loss: 0.344472   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 1974   Recon Loss: 0.384137   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 1975   Recon Loss: 0.365997   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 1976   Recon Loss: 0.372377   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 1977   Recon Loss: 0.365234   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 1978   Recon Loss: 0.382899   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 1979   Recon Loss: 0.381490   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 1980   Recon Loss: 0.368570   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 1981   Recon Loss: 0.373740   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 1982   Recon Loss: 0.374580   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 1983   Recon Loss: 0.365771   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 1984   Recon Loss: 0.359226   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 1985   Recon Loss: 0.347722   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 1986   Recon Loss: 0.379445   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 1987   Recon Loss: 0.367407   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 1988   Recon Loss: 0.371497   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 1989   Recon Loss: 0.364280   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 1990   Recon Loss: 0.345527   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 1991   Recon Loss: 0.365957   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 1992   Recon Loss: 0.344563   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 1993   Recon Loss: 0.360144   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 1994   Recon Loss: 0.399817   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 1995   Recon Loss: 0.378067   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 1996   Recon Loss: 0.357501   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 1997   Recon Loss: 0.351098   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 1998   Recon Loss: 0.383450   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 1999   Recon Loss: 0.377947   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Inference and Save: Unseen Set"
      ],
      "metadata": {
        "id": "XKLK9fOVqNZ8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data_unseen_test = scipy.io.loadmat('/content/fsl-rsvae/datasets/AWA1/unseen_test.mat')\n",
        "data_unseen_test = data_unseen_test['feature']\n",
        "#data_train = np.transpose(data_train)\n",
        "\n",
        "\n",
        "# labels\n",
        "label_unseen_test = scipy.io.loadmat('/content/fsl-rsvae/datasets/AWA1/unseen_test_label.mat')\n",
        "label_unseen_test = label_unseen_test['label'][0]\n",
        "\n",
        "\n",
        "# attr\n",
        "unseen_attr = scipy.io.loadmat('/content/fsl-rsvae/datasets/AWA1/unseen_attribute.mat')\n",
        "unseen_attr = unseen_attr['unseen_attribute']\n",
        "\n",
        "#/content/fsl-rsvae/datasets/AWA1/unseen_attribute.mat"
      ],
      "metadata": {
        "id": "vWAa8HEplB2t"
      },
      "execution_count": 111,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "feature_un_dataset = FeatureDataset(data_unseen_test, label_unseen_test, unseen_attr)\n",
        "feature_un_loader = torch.utils.data.DataLoader(feature_dataset, shuffle=False, pin_memory=True, drop_last=False, batch_size=len(feature_un_dataset))  # len(feature_un_dataset)"
      ],
      "metadata": {
        "id": "jLAB7R1SqVqE"
      },
      "execution_count": 112,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#attr = torch.from_numpy(attr)\n",
        "feats_vae.eval()\n",
        "for idx, (data, label) in enumerate(feature_un_loader):\n",
        "    #print(idx)\n",
        "    print(data.size())\n",
        "    #print(label)\n",
        "    print(np.array(attr)[label].shape)\n",
        "    uns_atr = torch.from_numpy(np.array(attr)[label]).to(torch.float32)\n",
        "    mu, logvar, recon_feats = feats_vae(data, uns_atr)\n",
        "    break"
      ],
      "metadata": {
        "id": "1Ofh8JLcKSMA",
        "outputId": "865aa985-f85c-4c9e-be6d-f634d2f5d415",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 113,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([19832, 2048])\n",
            "(19832, 85)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pickle\n",
        "\n",
        "recon_feats = recon_feats.cpu().detach().numpy()\n",
        "with open('new_feats.pickle', 'wb') as handle:\n",
        "    pickle.dump(recon_feats, handle, protocol=pickle.HIGHEST_PROTOCOL)"
      ],
      "metadata": {
        "id": "ak4bfxu6nDfO"
      },
      "execution_count": 114,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with open('new_feats.pickle', 'rb') as handle:\n",
        "    recon_feats2 = pickle.load(handle)"
      ],
      "metadata": {
        "id": "4D2Hqa_MnVTP"
      },
      "execution_count": 108,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "G1b3ZvkOrI7f"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}