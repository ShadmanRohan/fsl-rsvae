{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNqshMZ1wJnaIqaav+JzUA2",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ShadmanRohan/fsl-rsvae/blob/main/starter.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9Fkr40LMo7uc",
        "outputId": "7f6a562b-ea13-4a6a-d184-dda935508ba1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'fsl-rsvae'...\n",
            "remote: Enumerating objects: 420, done.\u001b[K\n",
            "remote: Counting objects: 100% (420/420), done.\u001b[K\n",
            "remote: Compressing objects: 100% (224/224), done.\u001b[K\n",
            "remote: Total 420 (delta 204), reused 402 (delta 195), pack-reused 0\u001b[K\n",
            "Receiving objects: 100% (420/420), 435.73 KiB | 19.81 MiB/s, done.\n",
            "Resolving deltas: 100% (204/204), done.\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/ShadmanRohan/fsl-rsvae.git"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4ktupjgODfja",
        "outputId": "c4102cc6-1656-4449-85b8-873149c4932a"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/gdrive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from distutils.dir_util import copy_tree\n",
        "copy_tree(\"/content/gdrive/MyDrive/PAMI/AWA1_AWA2_SUN/data/AWA1\", \"/content/fsl-rsvae/datasets/AWA1\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IEef9zeLD52b",
        "outputId": "9ac8d2a0-a709-4849-8267-81f99ddb5478"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['/content/fsl-rsvae/datasets/AWA1/seen_test.mat',\n",
              " '/content/fsl-rsvae/datasets/AWA1/seen_attribute.mat',\n",
              " '/content/fsl-rsvae/datasets/AWA1/seen_test_label.mat',\n",
              " '/content/fsl-rsvae/datasets/AWA1/seen_train.mat',\n",
              " '/content/fsl-rsvae/datasets/AWA1/unseen_attribute.mat',\n",
              " '/content/fsl-rsvae/datasets/AWA1/seen_train_label.mat',\n",
              " '/content/fsl-rsvae/datasets/AWA1/unseen_test.mat',\n",
              " '/content/fsl-rsvae/datasets/AWA1/unseen_test_label.mat']"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import argparse\n",
        "import numpy as np\n",
        "from torch.autograd import Variable\n",
        "#from torchvision.datasets.folder import DatasetFolder\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torch.distributions import uniform, normal\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from matplotlib import pyplot as plt\n",
        "import torch.optim\n",
        "import json\n",
        "import torch.utils.data.sampler\n",
        "import os\n",
        "import glob\n",
        "import random\n",
        "import time\n",
        "import pdb\n",
        "import yaml\n",
        "#import datasets.feature_loader as feat_loader\n",
        "from sklearn.manifold import TSNE\n",
        "import h5py\n",
        "from scipy.stats import multivariate_normal\n",
        "import scipy"
      ],
      "metadata": {
        "id": "k8kzzG1xpNSE"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def finetune_vae(feats_vae, x_shot, label_real):\n",
        "    attributes = np.load('./mini_attr.npy')\n",
        "    x_shot = x_shot.detach()\n",
        "    z_dist = normal.Normal(0, 1)\n",
        "    bs_list = np.arange(4)\n",
        "    feats_vae.train()\n",
        "    optimizer = torch.optim.Adam(feats_vae.parameters(), lr=0.0001)\n",
        "    for ep in range(5):\n",
        "      np.random.shuffle(bs_list)\n",
        "      for idx in bs_list:\n",
        "        targets = x_shot[idx]\n",
        "        labels_sel = label_real[idx] + 80\n",
        "        attr = torch.from_numpy(attributes[labels_sel]).float().cuda()\n",
        "        attr = attr.repeat((1, 50)).reshape((5, 50, -1))\n",
        "        Z = z_dist.sample((5, 50, 512)).cuda()\n",
        "        concat_feats = torch.cat((Z, attr), dim=2)\n",
        "        concat_feats = torch.autograd.Variable(concat_feats, requires_grad=True)\n",
        "        feats = feats_vae.model(concat_feats).reshape((-1, 512))\n",
        "        feats = feats_vae.relu(feats_vae.bn1(feats)).reshape((5, 50, 512))\n",
        "        feats = feats.mean(1)\n",
        "        feats = F.normalize(feats, dim=-1)\n",
        "        mse_loss = F.mse_loss(feats, targets)\n",
        "        optimizer.zero_grad()\n",
        "        mse_loss.backward()\n",
        "        optimizer.step()\n",
        "        print(mse_loss.item())"
      ],
      "metadata": {
        "id": "diZ7mTLrpE2Y"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def shrink_feats(cl_data_file):\n",
        "    cl_mean_file = {}\n",
        "    weight_data_file = {}\n",
        "    for k, v in cl_data_file.items():\n",
        "        mean_feats = np.mean(v, 0)\n",
        "        cl_mean_file[k] = mean_feats / np.sqrt(np.sum(mean_feats*mean_feats))\n",
        "    for k, v in cl_data_file.items():\n",
        "        v = np.array(v)\n",
        "        v = v / np.sqrt(np.sum(v*v, -1, keepdims=True))\n",
        "        dist = np.sum((v - cl_mean_file[k])**2, 1)\n",
        "        sort_idx = np.argsort(dist)\n",
        "        in_idx = sort_idx[:50]\n",
        "        out_idx = sort_idx[50:200]\n",
        "        in_feats = v[in_idx]\n",
        "        out_feats = v[out_idx]\n",
        "        cl_data_file[k] = []\n",
        "        for in_f in in_feats:\n",
        "          cl_data_file[k].append(in_f)\n",
        "        for o_idx in out_idx:\n",
        "          close_feats = (v[o_idx] + cl_mean_file[k]) / 2\n",
        "          close_dist = np.sum((in_feats - close_feats)**2, -1)\n",
        "          min_idx = np.argsort(close_dist)[0]\n",
        "          cl_data_file[k].append(in_feats[min_idx])\n",
        "    pdb.set_trace()\n",
        "    return cl_data_file\n",
        "\n",
        "def det(matrix):\n",
        "    order=len(matrix)\n",
        "    posdet=0\n",
        "    for i in range(order):\n",
        "        posdet+=reduce((lambda x, y: x * y), [matrix[(i+j)%order][j] for j in range(order)])\n",
        "    negdet=0\n",
        "    for i in range(order):\n",
        "        negdet+=reduce((lambda x, y: x * y), [matrix[(order-i-j)%order][j] for j in range(order)])\n",
        "    return posdet-negdet\n",
        "\n",
        "\n",
        "def remove_feats(cl_data_file):\n",
        "    cl_mean_file = {}\n",
        "    cl_var_file = {}\n",
        "    weight_data_file = {}\n",
        "    remove_num = []\n",
        "    for k, v in cl_data_file.items():\n",
        "        mean_feats = np.mean(v, 0)\n",
        "        cl_mean_file[k] = mean_feats\n",
        "        cl_var_file[k] = np.cov(np.array(v).T)\n",
        "    for k, v in cl_data_file.items():\n",
        "        v = np.array(v)\n",
        "        #dist = np.sum((v - cl_mean_file[k])**2, 1)\n",
        "        #sort_idx = np.argsort(dist)[:220]\n",
        "        cl_data_file[k] = []\n",
        "        #weight_data_file[k] = []\n",
        "        inv_var = scipy.linalg.inv(cl_var_file[k])\n",
        "        mean = cl_mean_file[k]\n",
        "        prob = np.sum(np.matmul((v-mean),inv_var)*(v-mean), -1)\n",
        "        prob = 1-scipy.stats.chi2.cdf(prob, 512)\n",
        "        #rv = multivariate_normal(mean = cl_mean_file[k], cov = cl_var_file[k])\n",
        "        for idx in range(600):\n",
        "          if prob[idx] > 0.9:\n",
        "            cl_data_file[k].append(v[idx]) \n",
        "        remove_num.append(np.sum(prob<0.9))\n",
        "        #for sidx in sort_idx:\n",
        "        #  cl_data_file[k].append(v[sidx])\n",
        "        #  cl_data_file[k].append((cl_mean_file[k] + (np.random.normal(v[sidx].shape)*0.001)).astype(np.float32))\n",
        "        #  weight_data_file[k].append(1./dist[sidx])\n",
        "        #all_feats = (np.random.multivariate_normal(mean=cl_mean_file[k], cov=cl_var_file[k], size=200)).astype(np.float32)\n",
        "        #for all_feat in all_feats:\n",
        "        #  cl_data_file[k].append(all_feat*0.3 + cl_mean_file[k]*0.7)\n",
        "    pdb.set_trace()\n",
        "    return cl_data_file\n",
        "\n",
        "def interpolate_feats(cl_data_file):\n",
        "    cl_mean_file = {}\n",
        "    for k, v in cl_data_file.items():\n",
        "        mean_feats = np.mean(v, 0)\n",
        "        cl_mean_file[k] = mean_feats\n",
        "    for k, v in cl_data_file.items():\n",
        "        v = np.array(v) \n",
        "        dist = np.sum((v - cl_mean_file[k])**2, 1)\n",
        "        cl_data_file[k] = []\n",
        "        for iv in v:\n",
        "          cl_data_file[k].append(0.6*iv+0.4*cl_mean_file[k])\n",
        "\n",
        "    return cl_data_file\n",
        "\n",
        "def get_vae_center(out_dir, split='train', use_mean=True):\n",
        "    attr_out_file = os.path.join(out_dir, '%s_attr.hdf5'%split)\n",
        "    vae_data_file = feat_loader.init_loader(attr_out_file)\n",
        "    if 'train' in split:\n",
        "      num = 64\n",
        "    else:\n",
        "      num = 20\n",
        "    if use_mean:\n",
        "      vae_feats_all = torch.zeros((num, 512))\n",
        "    else:\n",
        "      vae_feats_all = torch.zeros((num, 20, 512))\n",
        "    mean_data_file = {}\n",
        "\n",
        "    for k, feats in vae_data_file.items():\n",
        "        mean_feats = np.mean(feats, 0)\n",
        "        mean_data_file[k] = mean_feats\n",
        "\n",
        "    for k, feats in vae_data_file.items():\n",
        "        #mean_feats = np.array(feats)[:50]\n",
        "        #mean_feats = 3*mean_feats - 2*mean_data_file[k]\n",
        "        if use_mean:\n",
        "          mean_feats = np.mean(feats, 0)\n",
        "        else:\n",
        "          mean_feats = np.array(feats)[:20]\n",
        "        mean_feats = torch.from_numpy(mean_feats)\n",
        "        mean_feats = F.normalize(mean_feats, dim=-1) \n",
        "        if 'test' in split: \n",
        "          k = k - 80\n",
        "        vae_feats_all[k] = mean_feats\n",
        "  \n",
        "    return vae_feats_all\n",
        "\n",
        "\n",
        "def generate_feats(feats_vae, attributes, output_file, label_list):\n",
        "    f = h5py.File(output_file, 'w')\n",
        "    ind_count = 500\n",
        "    max_count = ind_count * len(label_list)\n",
        "    all_labels = f.create_dataset('all_labels',(max_count,), dtype='i')\n",
        "    all_feats=None\n",
        "    count=0\n",
        "    feats_vae.eval()\n",
        "    z_dist = normal.Normal(0, 1)\n",
        "    for label in label_list:\n",
        "        attr = torch.from_numpy(attributes[label]).float().cuda()\n",
        "        attr = attr.repeat(ind_count, 1)\n",
        "        Z = z_dist.sample((ind_count, 512)).cuda()\n",
        "        concat_feats = torch.cat((Z, attr), dim=1)\n",
        "        feats = feats_vae.model(concat_feats)\n",
        "        feats = feats_vae.relu(feats_vae.bn1(feats))\n",
        "        if all_feats is None:      \n",
        "          all_feats = f.create_dataset('all_feats', [max_count] + list(feats.size()[1:]) , dtype='f')\n",
        "        all_feats[count:count+feats.size(0)] = feats.data.cpu().numpy()\n",
        "        all_labels[count:count+feats.size(0)] = np.array([label]*ind_count)\n",
        "        count = count + feats.size(0)\n",
        "    count_var = f.create_dataset('count', (1,), dtype='i')\n",
        "    count_var[0] = count\n",
        "\n",
        "    f.close()\n",
        "\n",
        "\n",
        "def visualize_feats(feats_dir):\n",
        "    visual_feats = []\n",
        "    attr_feats = []\n",
        "    visual_labels = []\n",
        "    attr_labels = []\n",
        "    cl_data_file = os.path.join(feats_dir, 'test.hdf5')\n",
        "    cl_data_file = feat_loader.init_loader(cl_data_file)\n",
        "    vae_data_file = os.path.join(feats_dir, 'test_attr_ood.hdf5')\n",
        "    vae_data_file = feat_loader.init_loader(vae_data_file)\n",
        "    pdb.set_trace()\n",
        "    #labels = [51, 3, 179, 7, 11, 175] \n",
        "    #labels = [15,6,17,8,9]\n",
        "    labels = [85, 86, 87, 88, 89]\n",
        "    #labels = [13, 17, 21, 29, 33, 37]\n",
        "    tsne = TSNE(n_components=2, random_state=0)\n",
        "    for idx in range(5):\n",
        "        label = labels[idx]\n",
        "        visual_feats.extend(cl_data_file[label-80][:100])\n",
        "        #attr_feats.extend((vae_data_file[label][:300]))\n",
        "        #attr_feats.extend(np.mean(np.array(vae_data_file[label]), 0, keepdims=True))\n",
        "        visual_labels.extend([idx]*len(cl_data_file[label-80][:100]))\n",
        "        #attr_labels.extend([idx]*len(vae_data_file[label][:300]))\n",
        "        #attr_labels.extend([idx])\n",
        "    visual_feats = np.array(visual_feats)\n",
        "    #attr_feats = np.array(attr_feats)\n",
        "    #all_feats = np.concatenate((visual_feats, attr_feats), 0)\n",
        "    pdb.set_trace()\n",
        "    all_labels = visual_labels \n",
        "    all_feats = visual_feats\n",
        "    all_feats_2D = tsne.fit_transform(all_feats)\n",
        "    #all_feats_2D = tsne.fit_transform(visual_feats)\n",
        "    #all_labels = visual_labels\n",
        "    colors = np.array(['r', 'g', 'b', 'c', 'm', 'y', 'k',  'orange', 'purple'])      \n",
        "    for idx in range(all_feats_2D.shape[0]):\n",
        "        feat = all_feats_2D[idx]\n",
        "        #if feat[0] < -30 or feat[1] < -30:\n",
        "        #  continue\n",
        "        label = all_labels[idx]\n",
        "        color = colors[label]\n",
        "        if idx < visual_feats.shape[0]:\n",
        "          marker = '*'\n",
        "          #continue\n",
        "        else:\n",
        "          marker = 'o'\n",
        "          #continue\n",
        "        plt.scatter(feat[0], feat[1], c=color, marker=marker) \n",
        "    plt.savefig('features_base_mini.png')\n",
        "\n",
        "def save_vae_features(out_file, attr_out_dir):\n",
        "    cl_data_file = feat_loader.init_loader(out_file)\n",
        "    cl_data_file = remove_feats(cl_data_file)\n",
        "    feature_dataset = FeatureDataset(cl_data_file)\n",
        "    feature_loader = torch.utils.data.DataLoader(feature_dataset, shuffle=True, pin_memory=True, drop_last=False, batch_size=256) \n",
        "    attributes = np.load('./mini_attr.npy')\n",
        "    feats_vae = FeatsVAE(512, 512).cuda()\n",
        "    feats_vae = train_vae(feature_loader, feats_vae, attributes)\n",
        "    #feats_vae.load_state_dict(torch.load('feats_vae_mini.pth')['state'])\n",
        "    #torch.save({'state': feats_vae.state_dict()}, 'feats_vae_mini.pth') \n",
        "    generate_feats(feats_vae, attributes, os.path.join(attr_out_dir, 'train_attr.hdf5'), np.arange(0, 64))\n",
        "    generate_feats(feats_vae, attributes, os.path.join(attr_out_dir, 'test_attr.hdf5'), np.arange(80, 100))\n",
        "    #return feats_vae\n",
        "\n"
      ],
      "metadata": {
        "id": "xn3pYo2fpYek"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#/content/fsl-rsvae/configs/test_few_shot.yaml\n",
        "config = yaml.load(open(args.config, 'r'), Loader=yaml.FullLoader)\n",
        "out_dir = os.path.dirname(config['load_encoder'])\n",
        "out_file = os.path.join(out_dir, 'features', 'test.hdf5')\n",
        "cl_data_file = feat_loader.init_loader(out_file)\n",
        "feature_dataset = FeatureDataset(cl_data_file)\n",
        "feature_loader = torch.utils.data.DataLoader(feature_dataset, shuffle=True, pin_memory=True, drop_last=False, batch_size=256)\n",
        "\n",
        "#attributes = np.load('./mini_attr.npy')\n",
        "feats_vae = FeatsVAE(512, 512).cuda()\n",
        "train_vae(feature_loader, feats_vae, attributes)\n",
        "#generate_feats(feats_vae, attributes, os.path.join(out_dir, 'features', 'test_attr.hdf5'), np.arange(80, 100))\n",
        "#save_vae_features(out_file, out_dir)\n",
        "\n",
        "#vae_feats_file = os.path.join(out_dir, 'features', 'test_attr.hdf5')\n",
        "#vae_data_file = feat_loader.init_loader(vae_feats_file)\n",
        "#visualize_feats(cl_data_file, vae_data_file)\n"
      ],
      "metadata": {
        "id": "TcagUsiDDFXB",
        "outputId": "58989d8e-476d-42d4-d085-82d2e08cbe9b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 235
        }
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-7-a4aa3263d68d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m#/content/fsl-rsvae/configs/test_few_shot.yaml\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mconfig\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0myaml\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'r'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mLoader\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0myaml\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mFullLoader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mout_dir\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdirname\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'load_encoder'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mout_file\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'features'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'test.hdf5'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mcl_data_file\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfeat_loader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minit_loader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout_file\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'args' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import scipy.io\n",
        "#features\n",
        "data_train = scipy.io.loadmat('/content/fsl-rsvae/datasets/AWA1/seen_train.mat')\n",
        "data_train = data_train['feature']\n",
        "#data_train = np.transpose(data_train)\n",
        "\n",
        "\n",
        "# labels\n",
        "label_train = scipy.io.loadmat('/content/fsl-rsvae/datasets/AWA1/seen_train_label.mat')\n",
        "data_train_label = label_train['label'][0]\n",
        "\n",
        "\n",
        "# attr\n",
        "tmp = scipy.io.loadmat('/content/fsl-rsvae/datasets/AWA1/seen_attribute.mat')\n",
        "attr = tmp['seen_attribute']\n",
        "#attr = np.transpose(attr)"
      ],
      "metadata": {
        "id": "KWmLvTptFmf9"
      },
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class FeatureDataset(Dataset):\n",
        "\n",
        "    def __init__(self, features, labels, attr):\n",
        "        self.labels = labels\n",
        "        self.features = features\n",
        "        self.attr = attr\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(data_train)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        return self.features[idx], self.labels[idx]\n",
        "\n",
        "feature_dataset = FeatureDataset(data_train, data_train_label, attr)\n",
        "feature_loader = torch.utils.data.DataLoader(feature_dataset, shuffle=True, pin_memory=True, drop_last=False, batch_size=256) "
      ],
      "metadata": {
        "id": "OiH7f_bqFb3i"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class FeatsVAE(nn.Module):\n",
        "    def __init__(self, x_dim, latent_dim):\n",
        "        super(FeatsVAE, self).__init__()\n",
        "\n",
        "        self.x_dim = x_dim\n",
        "        self.latent_dim = latent_dim\n",
        "        self.bn1 = nn.BatchNorm1d(x_dim)\n",
        "        self.relu = nn.ReLU(inplace=True)\n",
        "        self.z_dist = normal.Normal(0, 1)\n",
        "        self.init_weights()\n",
        "\n",
        "        self.linear = nn.Sequential(\n",
        "            nn.Linear(self.x_dim+self.latent_dim, 128),\n",
        "            #nn.LeakyReLU(),\n",
        "            #nn.Linear(1096, 2096),\n",
        "            nn.LeakyReLU())\n",
        "        self.linear_mu =  nn.Sequential(\n",
        "            nn.Linear(128, latent_dim),\n",
        "            nn.ReLU())\n",
        "        self.linear_logvar =  nn.Sequential(\n",
        "            nn.Linear(128, latent_dim),\n",
        "            nn.ReLU())\n",
        "        self.model = nn.Sequential(\n",
        "            nn.Linear(2*latent_dim, 128),\n",
        "            nn.LeakyReLU(),\n",
        "            #nn.Linear(4096, 4096),\n",
        "            #nn.LeakyReLU(),\n",
        "            nn.Linear(128, x_dim),\n",
        "            #nn.Sigmoid(),\n",
        "        )\n",
        "        \n",
        "\n",
        "\n",
        "\n",
        "    def reparameterize(self, mu, logvar):\n",
        "        std = torch.exp(0.5*logvar)  \n",
        "        eps = torch.randn_like(std)\n",
        "        # remove abnormal points\n",
        "        return mu + eps*std\n",
        "\n",
        "    def init_weights(self):\n",
        "        for m in self.modules():\n",
        "          if isinstance(m, nn.Linear):\n",
        "              m.weight.data.normal_(0, 0.02)\n",
        "              m.bias.data.normal_(0, 0.02)\n",
        "\n",
        "    def forward(self, x, attr):\n",
        "        #print(x.size())\n",
        "        #print(attr.size())\n",
        "\n",
        "        x = torch.cat((x, attr), dim=1).to(torch.float32)\n",
        "        #print(x.size())\n",
        "        #print(self.x_dim+self.latent_dim)\n",
        "        \n",
        "        x = self.linear(x)\n",
        "        #print(x.size())\n",
        "        mu = self.linear_mu(x)\n",
        "        #print(x)\n",
        "        logvar = self.linear_logvar(x)\n",
        "        #print(logvar)\n",
        "        latent_feats = self.reparameterize(mu, logvar)\n",
        "        #Z = self.z_dist.sample(attr.shape).cuda() \n",
        "        concat_feats = torch.cat((latent_feats, attr), dim=1)\n",
        "        recon_feats = self.model(concat_feats)\n",
        "        recon_feats = self.relu(self.bn1(recon_feats))\n",
        "        return mu, logvar, recon_feats\n",
        "\n",
        "feats_vae = FeatsVAE(x_dim=2048, latent_dim=85) # latent dim = attribute dim"
      ],
      "metadata": {
        "id": "QR8I-FHnK1gq"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train_vae(feature_loader, feats_vae, attributes):\n",
        "    optimizer = torch.optim.Adam(feats_vae.parameters(), lr=0.001)\n",
        "    #for ep in range(10):\n",
        "    for ep in range(60):\n",
        "      loss_recon_all = 0\n",
        "      loss_kl_all = 0\n",
        "      for idx, (data, label) in enumerate(feature_loader):\n",
        "        print(\"training loop...\")\n",
        "        data = data\n",
        "        #weight = weight.cuda() / torch.sum(weight)\n",
        "        attr = torch.from_numpy(attributes[label]).float()\n",
        "        mu, logvar, recon_feats = feats_vae(data, attr)\n",
        "        recon_loss = ((recon_feats - data)**2).mean(1)\n",
        "        recon_loss = torch.mean(recon_loss)\n",
        "        #kl_loss = -0.5*torch.sum(1+logvar-logvar.exp()-mu.pow(2)) / data.shape[0]\n",
        "        kl_loss = (1+logvar-logvar.exp()-mu.pow(2)).sum(1)\n",
        "        kl_loss = -0.5*torch.mean(kl_loss)\n",
        "        L_vae = recon_loss+kl_loss\n",
        "        optimizer.zero_grad()\n",
        "        L_vae.backward()   \n",
        "        optimizer.step()\n",
        "        loss_recon_all += recon_loss.item()\n",
        "        loss_kl_all += kl_loss.item()\n",
        "        break\n",
        "      print('Ep: %d   Recon Loss: %f   KL Loss: %f'%(ep, loss_recon_all/(idx+1), loss_kl_all/(idx+1)))\n",
        "      print(recon_feats.shape)\n",
        "    return feats_vae\n",
        "    #torch.save({'state': feats_vae.state_dict()}, 'feats_vae_mini.pth') \n",
        "\n",
        "feats_vae = train_vae(feature_loader, feats_vae, attr)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JN9RRAsJNhzB",
        "outputId": "33638c3a-67ad-4a00-c99c-3c1d939ec461"
      },
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "training loop...\n",
            "Ep: 0   Recon Loss: 0.373244   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 1   Recon Loss: 0.420070   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 2   Recon Loss: 0.411942   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 3   Recon Loss: 0.397392   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 4   Recon Loss: 0.403918   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 5   Recon Loss: 0.378431   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 6   Recon Loss: 0.406871   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 7   Recon Loss: 0.394780   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 8   Recon Loss: 0.380155   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 9   Recon Loss: 0.395631   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 10   Recon Loss: 0.402913   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 11   Recon Loss: 0.408981   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 12   Recon Loss: 0.410628   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 13   Recon Loss: 0.395924   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 14   Recon Loss: 0.418347   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 15   Recon Loss: 0.391542   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 16   Recon Loss: 0.400138   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 17   Recon Loss: 0.376265   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 18   Recon Loss: 0.390529   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 19   Recon Loss: 0.405946   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 20   Recon Loss: 0.396560   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 21   Recon Loss: 0.390900   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 22   Recon Loss: 0.401459   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 23   Recon Loss: 0.399450   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 24   Recon Loss: 0.375191   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 25   Recon Loss: 0.397552   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 26   Recon Loss: 0.440605   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 27   Recon Loss: 0.403762   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 28   Recon Loss: 0.385411   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 29   Recon Loss: 0.381234   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 30   Recon Loss: 0.408055   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 31   Recon Loss: 0.379709   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 32   Recon Loss: 0.395357   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 33   Recon Loss: 0.398232   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 34   Recon Loss: 0.407908   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 35   Recon Loss: 0.394688   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 36   Recon Loss: 0.378788   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 37   Recon Loss: 0.401318   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 38   Recon Loss: 0.381208   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 39   Recon Loss: 0.395383   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 40   Recon Loss: 0.406811   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 41   Recon Loss: 0.398241   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 42   Recon Loss: 0.391522   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 43   Recon Loss: 0.393369   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 44   Recon Loss: 0.387850   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 45   Recon Loss: 0.393530   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 46   Recon Loss: 0.389259   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 47   Recon Loss: 0.405912   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 48   Recon Loss: 0.404159   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 49   Recon Loss: 0.389704   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 50   Recon Loss: 0.407463   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 51   Recon Loss: 0.410339   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 52   Recon Loss: 0.412951   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 53   Recon Loss: 0.402786   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 54   Recon Loss: 0.380281   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 55   Recon Loss: 0.396440   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 56   Recon Loss: 0.410873   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 57   Recon Loss: 0.392152   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 58   Recon Loss: 0.399633   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n",
            "training loop...\n",
            "Ep: 59   Recon Loss: 0.392710   KL Loss: 0.000000\n",
            "torch.Size([256, 2048])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "def generate_feats(feats_vae, attr ):\n",
        "\n",
        "  for label in label_list:\n",
        "      attr = torch.from_numpy(attr[label]).float().cuda() # get W2V tensor for a label\n",
        "      attr = attr.repeat(ind_count, 1) # w2v\n",
        "      Z = z_dist.sample((ind_count, 512)).cuda() # noise\n",
        "      print(Z.size())\n",
        "      concat_feats = torch.cat((Z.cuda(), attr.cuda()), dim=1) # w2v + noise\n",
        "      feats = feats_vae.model(concat_feats.cuda())\n",
        "      feats = feats_vae.relu(feats_vae.bn1(feats)) # why?\n",
        "      #if all_feats is None:      \n",
        "        #all_feats = f.create_dataset('all_feats', [max_count] + list(feats.size()[1:]) , dtype='f')\n",
        "      all_feats[count:count+feats.size(0)] = feats.data.cpu().numpy()\n",
        "      all_labels[count:count+feats.size(0)] = np.array([label]*ind_count)\n",
        "      count = count + feats.size(0)\n",
        "    count_var = f.create_dataset('count', (1,), dtype='i')\n",
        "    count_var[0] = count\n",
        "generate_feats(feats_vae, attr)"
      ],
      "metadata": {
        "id": "nHyD_-z0ONRN",
        "outputId": "7a885655-1b04-4ba9-cadf-c7cf31347bf6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 397
        }
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Normal(loc: 0.0, scale: 1.0)\n",
            "torch.Size([500, 512])\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-24-ac602dc66dfd>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     31\u001b[0m     \u001b[0mcount_var\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreate_dataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'count'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'i'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m     \u001b[0mcount_var\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcount\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 33\u001b[0;31m \u001b[0mgenerate_feats\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeats_vae\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-24-ac602dc66dfd>\u001b[0m in \u001b[0;36mgenerate_feats\u001b[0;34m(feats_vae, attr, label_list)\u001b[0m\n\u001b[1;32m     22\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mZ\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m         \u001b[0mconcat_feats\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mZ\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m         \u001b[0mfeats\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfeats_vae\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconcat_feats\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     25\u001b[0m         \u001b[0mfeats\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfeats_vae\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeats_vae\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbn1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeats\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mall_feats\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1128\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1129\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1130\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1131\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1132\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/container.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    137\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    138\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 139\u001b[0;31m             \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    140\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    141\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1128\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1129\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1130\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1131\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1132\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/linear.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    112\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    113\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 114\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    115\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    116\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mextra_repr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: Expected all tensors to be on the same device, but found at least two devices, cpu and cuda:0! (when checking argument for argument mat1 in method wrapper_addmm)"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data_unseen_test = scipy.io.loadmat('/content/fsl-rsvae/datasets/AWA1/unseen_test.mat')\n",
        "data_unseen_test = data_unseen_test['feature']\n",
        "#data_train = np.transpose(data_train)\n",
        "\n",
        "\n",
        "# labels\n",
        "label_unseen_test = scipy.io.loadmat('/content/fsl-rsvae/datasets/AWA1/unseen_test_label.mat')\n",
        "label_unseen_test = label_unseen_test['label'][0]\n",
        "\n",
        "\n",
        "# attr\n",
        "unseen_attr = scipy.io.loadmat('/content/fsl-rsvae/datasets/AWA1/unseen_attribute.mat')\n",
        "unseen_attr = unseen_attr['unseen_attribute']\n",
        "\n",
        "#/content/fsl-rsvae/datasets/AWA1/unseen_attribute.mat"
      ],
      "metadata": {
        "id": "vWAa8HEplB2t"
      },
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "feature_un_dataset = FeatureDataset(data_unseen_test, label_unseen_test, unseen_attr)\n",
        "feature_un_loader = torch.utils.data.DataLoader(feature_dataset, shuffle=False, pin_memory=True, drop_last=False, batch_size=len(feature_un_dataset)) "
      ],
      "metadata": {
        "id": "jLAB7R1SqVqE"
      },
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def save_unseen(feature_loader, feats_vae, attributes):\n",
        "    #optimizer = torch.optim.Adam(feats_vae.parameters(), lr=0.001)\n",
        "    #for ep in range(10):\n",
        "    for ep in range(60):\n",
        "      #loss_recon_all = 0\n",
        "      #loss_kl_all = 0\n",
        "      for idx, (data, label) in enumerate(feature_loader):\n",
        "        print(\"inferencing loop...\")\n",
        "        data = data\n",
        "        #weight = weight.cuda() / torch.sum(weight)\n",
        "        attr = torch.from_numpy(attributes[label]).float()\n",
        "        mu, logvar, recon_feats = feats_vae(data, attr)\n",
        "        #recon_loss = ((recon_feats - data)**2).mean(1)\n",
        "        #recon_loss = torch.mean(recon_loss)\n",
        "        #kl_loss = -0.5*torch.sum(1+logvar-logvar.exp()-mu.pow(2)) / data.shape[0]\n",
        "        #kl_loss = (1+logvar-logvar.exp()-mu.pow(2)).sum(1)\n",
        "        #kl_loss = -0.5*torch.mean(kl_loss)\n",
        "        #L_vae = recon_loss+kl_loss\n",
        "        #optimizer.zero_grad()\n",
        "        #L_vae.backward()   \n",
        "        #optimizer.step()\n",
        "        #loss_recon_all += recon_loss.item()\n",
        "        #loss_kl_all += kl_loss.item()\n",
        "        break\n",
        "      print('Ep: %d   Recon Loss: %f   KL Loss: %f'%(ep, loss_recon_all/(idx+1), loss_kl_all/(idx+1)))\n",
        "      print(recon_feats.shape)\n",
        "    return recon_feats\n",
        "feats_vae = save_unseen(feature_un_loader, feats_vae, unseen_attr)"
      ],
      "metadata": {
        "id": "8oRQq_iOH5EV",
        "outputId": "108a016a-5150-4d78-8a37-eb06f2ebd3a2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 339
        }
      },
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "inferencing loop...\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "IndexError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-67-db140dd47030>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     26\u001b[0m       \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrecon_feats\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mrecon_feats\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 28\u001b[0;31m \u001b[0mfeats_vae\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msave_unseen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeature_un_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeats_vae\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0munseen_attr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-67-db140dd47030>\u001b[0m in \u001b[0;36msave_unseen\u001b[0;34m(feature_loader, feats_vae, attributes)\u001b[0m\n\u001b[1;32m      9\u001b[0m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m         \u001b[0;31m#weight = weight.cuda() / torch.sum(weight)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m         \u001b[0mattr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_numpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mattributes\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlabel\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m         \u001b[0mmu\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogvar\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrecon_feats\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfeats_vae\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m         \u001b[0;31m#recon_loss = ((recon_feats - data)**2).mean(1)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mIndexError\u001b[0m: index 31 is out of bounds for axis 0 with size 10"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(feature_un_dataset)"
      ],
      "metadata": {
        "id": "vcL8pL22IOPs",
        "outputId": "49d3f66c-f3ea-4c4f-b2ca-e7db308989cb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "19832"
            ]
          },
          "metadata": {},
          "execution_count": 64
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "feature_un_loader"
      ],
      "metadata": {
        "id": "1Ofh8JLcKSMA",
        "outputId": "565cc2db-0ae1-4ef8-b8dc-aa6dc4ffb6b2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 68,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<torch.utils.data.dataloader.DataLoader at 0x7f04be47ac50>"
            ]
          },
          "metadata": {},
          "execution_count": 68
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "j8HQf0ksKzmO"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}